#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‡Ø±Ù…ÙŠ Ø§Ù„Ø´Ø¨ÙƒÙŠ Ø§Ù„Ù…Ø¨Ø³Ø· - Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø¯ÙˆÙ† NetworkX
==================================================

Ù‡Ø°Ø§ Ø¥ØµØ¯Ø§Ø± Ù…Ø¨Ø³Ø· Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‡Ø±Ù…ÙŠ ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ù…ÙƒØªØ¨Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ©
Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙˆØ§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©.
"""
# pylint: disable=invalid-name,too-few-public-methods,too-many-instance-attributes,line-too-long


import time
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Union
from enum import Enum
from abc import ABC, abstractmethod

# ============== Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ==============


class AnalysisLevel(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‡Ø±Ù…ÙŠ"""

    PHONEME_HARAKAH = 1
    SYLLABLE_PATTERN = 2
    MORPHEME_MAPPER = 3
    WORD_TRACER = 7


@dataclass
class EngineOutput:
    """Ù…Ø®Ø±Ø¬Ø§Øª Ù…ÙˆØ­Ø¯Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª"""

    level: AnalysisLevel
    vector: List[float]
    graph_node: Dict[str, Any]
    confidence: float
    processing_time: float
    metadata: Dict[str, Any] = field(default_factory=dict)


# ============== Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ==============


@dataclass
class PhonemeHarakahData:
    phonemes: List[str]
    harakaat: List[str]
    positions: List[int]
    ipa_representation: str


@dataclass
class SyllablePatternData:
    syllabic_units: List[str]
    cv_patterns: List[str]
    stress_positions: List[int]


@dataclass
class MorphemeMapperData:
    root: str
    pattern: str
    prefixes: List[str]
    suffixes: List[str]


# ============== Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ==============


class BaseHierarchicalEngine(ABC):
    """Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù‡Ø±Ù…ÙŠØ©"""

    def __init__(self, level: AnalysisLevel):
        self.level = level

    @abstractmethod
    def process(
        self, input_data: Any, context: Optional[Dict[str, Any]] = None
    ) -> EngineOutput:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø©"""
        pass

    @abstractmethod
    def generate_vector(self, analysis_data: Any) -> List[float]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡ Ø§Ù„Ø±Ù‚Ù…ÙŠ"""
        pass

    @abstractmethod
    def create_graph_node(self, analysis_data: Any) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø´Ø¨ÙƒØ©"""
        pass


# ============== Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…Ø¨Ø³Ø·Ø© ==============


class PhonemeHarakahEngine(BaseHierarchicalEngine):
    """Ù…Ø­Ø±Ùƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª - Ù…Ø¨Ø³Ø·"""

    def __init__(self):
        super().__init__(AnalysisLevel.PHONEME_HARAKAH)

    def process(
        self, input_data: str, context: Optional[Dict[str, Any]] = None
    ) -> EngineOutput:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª"""
        start_time = time.time()

        # ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø³Ø·
        analysis_data = PhonemeHarakahData(
            phonemes=list(input_data),
            harakaat=[],
            positions=list(range(len(input_data))),
            ipa_representation=input_data,
        )

        vector = self.generate_vector(analysis_data)
        graph_node = self.create_graph_node(analysis_data)

        processing_time = time.time() - start_time

        return EngineOutput(
            level=self.level,
            vector=vector,
            graph_node=graph_node,
            confidence=0.95,
            processing_time=processing_time,
            metadata={"analysis_data": analysis_data},
        )

    def generate_vector(self, analysis_data: PhonemeHarakahData) -> List[float]:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª"""
        return [
            float(len(analysis_data.phonemes)),
            float(len(analysis_data.harakaat)),
            float(len(analysis_data.ipa_representation)),
        ]

    def create_graph_node(self, analysis_data: PhonemeHarakahData) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù‚Ø¯Ø© Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª"""
        return {
            "type": "phoneme_harakah",
            "level": 1,
            "phonemes": analysis_data.phonemes,
            "features": {
                "phoneme_count": len(analysis_data.phonemes),
                "has_harakaat": len(analysis_data.harakaat) > 0,
            },
        }


class SyllablePatternEngine(BaseHierarchicalEngine):
    """Ù…Ø­Ø±Ùƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ - Ù…Ø¨Ø³Ø·"""

    def __init__(self):
        super().__init__(AnalysisLevel.SYLLABLE_PATTERN)

    def process(
        self, input_data: PhonemeHarakahData, context: Optional[Dict[str, Any]] = None
    ) -> EngineOutput:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""
        start_time = time.time()

        # ØªØ­Ù„ÙŠÙ„ Ù…Ø¨Ø³Ø· - ÙƒÙ„ 2 Ø£Ø­Ø±Ù = Ù…Ù‚Ø·Ø¹
        phonemes = input_data.phonemes
        syllabic_units = []
        cv_patterns = []

        for i in range(0, len(phonemes), 2):
            syllable = "".join(phonemes[i : i + 2])
            syllabic_units.append(syllable)
            cv_patterns.append("CV")

        analysis_data = SyllablePatternData(
            syllabic_units=syllabic_units,
            cv_patterns=cv_patterns,
            stress_positions=[0] if syllabic_units else [],
        )

        vector = self.generate_vector(analysis_data)
        graph_node = self.create_graph_node(analysis_data)

        processing_time = time.time() - start_time

        return EngineOutput(
            level=self.level,
            vector=vector,
            graph_node=graph_node,
            confidence=0.88,
            processing_time=processing_time,
            metadata={"analysis_data": analysis_data},
        )

    def generate_vector(self, analysis_data: SyllablePatternData) -> List[float]:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""
        return [
            float(len(analysis_data.syllabic_units)),
            float(len(analysis_data.cv_patterns)),
            float(len(analysis_data.stress_positions)),
        ]

    def create_graph_node(self, analysis_data: SyllablePatternData) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù‚Ø¯Ø© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""
        return {
            "type": "syllable_pattern",
            "level": 2,
            "syllabic_units": analysis_data.syllabic_units,
            "features": {
                "syllable_count": len(analysis_data.syllabic_units),
                "has_stress": len(analysis_data.stress_positions) > 0,
            },
        }


class MorphemeMapperEngine(BaseHierarchicalEngine):
    """Ù…Ø­Ø±Ùƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ±ÙÙŠØ© - Ù…Ø¨Ø³Ø·"""

    def __init__(self):
        super().__init__(AnalysisLevel.MORPHEME_MAPPER)
        self.simple_roots = {"ÙƒØªØ¨": "write", "Ø¯Ø±Ø³": "study", "Ù‚Ø±Ø£": "read"}

    def process(
        self, input_data: SyllablePatternData, context: Optional[Dict[str, Any]] = None
    ) -> EngineOutput:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ±ÙÙŠØ©"""
        start_time = time.time()

        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø°Ø± Ø¨Ø³ÙŠØ·
        word = "".join(input_data.syllabic_units)
        root = self._extract_simple_root(word)

        analysis_data = MorphemeMapperData(
            root=root,
            pattern="ÙØ¹Ù„" if root in self.simple_roots else "unknown",
            prefixes=[],
            suffixes=[],
        )

        vector = self.generate_vector(analysis_data)
        graph_node = self.create_graph_node(analysis_data)

        processing_time = time.time() - start_time

        return EngineOutput(
            level=self.level,
            vector=vector,
            graph_node=graph_node,
            confidence=0.75,
            processing_time=processing_time,
            metadata={"analysis_data": analysis_data},
        )

    def _extract_simple_root(self, word: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø°Ø± Ø¨Ø³ÙŠØ·"""
        # Ø¥Ø²Ø§Ù„Ø© Ø£Ø­Ø±Ù Ø¨Ø³ÙŠØ·Ø©
        clean_word = word.replace("Ø§Ù„", "").replace("Ø©", "")

        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
        for root in self.simple_roots:
            if root in clean_word:
                return root

        return clean_word[:3] if len(clean_word) >= 3 else clean_word

    def generate_vector(self, analysis_data: MorphemeMapperData) -> List[float]:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ±ÙÙŠØ©"""
        return [
            float(len(analysis_data.root)),
            1.0 if analysis_data.root in self.simple_roots else 0.0,
            float(len(analysis_data.prefixes)),
            float(len(analysis_data.suffixes)),
        ]

    def create_graph_node(self, analysis_data: MorphemeMapperData) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ±ÙÙŠØ©"""
        return {
            "type": "morpheme_mapper",
            "level": 3,
            "root": analysis_data.root,
            "pattern": analysis_data.pattern,
            "features": {
                "has_root": bool(analysis_data.root),
                "root_known": analysis_data.root in self.simple_roots,
                "has_affixes": len(analysis_data.prefixes) + len(analysis_data.suffixes)
                > 0,
            },
        }


class WordTraceGraph(BaseHierarchicalEngine):
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ - Ù…Ø¨Ø³Ø·"""

    def __init__(self):
        super().__init__(AnalysisLevel.WORD_TRACER)

    def process(
        self, input_data: Dict[str, Any], context: Optional[Dict[str, Any]] = None
    ) -> EngineOutput:
        """Ø¥Ù†Ø´Ø§Ø¡ ØªØªØ¨Ø¹ Ø´Ø§Ù…Ù„"""
        start_time = time.time()

        # ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        trace_data = {
            "word": input_data.get("original_word", ""),
            "analysis_levels": {},
            "final_summary": {},
        }

        # Ø¬Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
        total_confidence = 0.0
        level_count = 0

        for level_name, result in input_data.items():
            if isinstance(result, dict) and "vector" in result:
                trace_data["analysis_levels"][level_name] = result
                total_confidence += result.get("confidence", 0.0)
                level_count += 1

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        trace_data["final_summary"] = {
            "overall_confidence": (
                total_confidence / level_count if level_count > 0 else 0.0
            ),
            "completed_levels": level_count,
            "analysis_complete": level_count >= 3,
        }

        vector = self.generate_vector(trace_data)
        graph_node = self.create_graph_node(trace_data)

        processing_time = time.time() - start_time

        return EngineOutput(
            level=self.level,
            vector=vector,
            graph_node=graph_node,
            confidence=0.90,
            processing_time=processing_time,
            metadata={"trace_data": trace_data},
        )

    def generate_vector(self, analysis_data: Dict[str, Any]) -> List[float]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡ Ø§Ù„Ø´Ø§Ù…Ù„"""
        final_summary = analysis_data["final_summary"]
        return [
            final_summary["overall_confidence"],
            float(final_summary["completed_levels"]),
            1.0 if final_summary["analysis_complete"] else 0.0,
        ]

    def create_graph_node(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"""
        return {
            "type": "word_trace",
            "level": 7,
            "word": analysis_data["word"],
            "final_summary": analysis_data["final_summary"],
            "features": {
                "is_complete": analysis_data["final_summary"]["analysis_complete"],
                "high_confidence": analysis_data["final_summary"]["overall_confidence"]
                > 0.8,
            },
        }


# ============== Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø§Ù„Ù…Ø¨Ø³Ø· ==============


class SimpleHierarchicalSystem:
    """Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‡Ø±Ù…ÙŠ Ø§Ù„Ù…Ø¨Ø³Ø·"""

    def __init__(self):
        self.engines = {
            AnalysisLevel.PHONEME_HARAKAH: PhonemeHarakahEngine(),
            AnalysisLevel.SYLLABLE_PATTERN: SyllablePatternEngine(),
            AnalysisLevel.MORPHEME_MAPPER: MorphemeMapperEngine(),
            AnalysisLevel.WORD_TRACER: WordTraceGraph(),
        }

    def analyze_word(self, word: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„ÙƒÙ„Ù…Ø©"""
        results: Dict[str, Any] = {"original_word": word}

        print(f"ğŸ” Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø©: '{word}'")

        # Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 1: Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª
        print("   1ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª...")
        phoneme_result = self.engines[AnalysisLevel.PHONEME_HARAKAH].process(word)
        results["phoneme_harakah"] = {
            "vector": phoneme_result.vector,
            "confidence": phoneme_result.confidence,
            "processing_time": phoneme_result.processing_time,
            "graph_node": phoneme_result.graph_node,
        }

        # Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 2: Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
        print("   2ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹...")
        syllable_result = self.engines[AnalysisLevel.SYLLABLE_PATTERN].process(
            phoneme_result.metadata.get("analysis_data")
        )
        results["syllable_pattern"] = {
            "vector": syllable_result.vector,
            "confidence": syllable_result.confidence,
            "processing_time": syllable_result.processing_time,
            "graph_node": syllable_result.graph_node,
        }

        # Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 3: Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ±ÙÙŠØ©
        print("   3ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ±ÙÙŠØ©...")
        morpheme_result = self.engines[AnalysisLevel.MORPHEME_MAPPER].process(
            syllable_result.metadata.get("analysis_data")
        )
        results["morpheme_mapper"] = {
            "vector": morpheme_result.vector,
            "confidence": morpheme_result.confidence,
            "processing_time": morpheme_result.processing_time,
            "graph_node": morpheme_result.graph_node,
        }

        # Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 7: Ø§Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        print("   7ï¸âƒ£ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬...")
        trace_result = self.engines[AnalysisLevel.WORD_TRACER].process(results)
        results["word_tracer"] = {
            "vector": trace_result.vector,
            "confidence": trace_result.confidence,
            "processing_time": trace_result.processing_time,
            "graph_node": trace_result.graph_node,
        }

        print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„!")
        return results

    def print_analysis_summary(self, results: Dict[str, Any]):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        print(f"\nğŸ“Š Ù…Ù„Ø®Øµ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø©: '{results['original_word']}'")
        print("=" * 50)

        for level_name, result in results.items():
            if level_name != "original_word" and isinstance(result, dict):
                print(f"ğŸ”¸ {level_name}:")
                print(f"   Ø«Ù‚Ø©: {result['confidence']:.1%}")
                print(f"   ÙˆÙ‚Øª: {result['processing_time']:.4f}s")
                print(f"   Ù…ØªØ¬Ù‡: {len(result['vector'])} Ø¹Ù†ØµØ±")

                features = result["graph_node"].get("features", {})
                if features:
                    print(f"   Ø®ØµØ§Ø¦Øµ: {list(features.keys())}")

        # Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        if "word_tracer" in results:
            final_summary = results["word_tracer"]["graph_node"]["final_summary"]
            print(f"\nğŸ† Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
            print(f"   Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {final_summary['overall_confidence']:.1%}")
            print(f"   Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©: {final_summary['completed_levels']}")
            print(
                f"   Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…ÙƒØªÙ…Ù„: {'Ù†Ø¹Ù…' if final_summary['analysis_complete'] else 'Ù„Ø§'}"
            )


# ============== Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ==============


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    print(
        """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‡Ø±Ù…ÙŠ Ø§Ù„Ø´Ø¨ÙƒÙŠ Ø§Ù„Ù…Ø¨Ø³Ø· - Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±                  â•‘
â•‘                    Simple Hierarchical Graph Engine                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    )

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…
    system = SimpleHierarchicalSystem()
    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ {len(system.engines)} Ù…Ø­Ø±ÙƒØ§Øª")

    # Ø§Ø®ØªØ¨Ø§Ø± ÙƒÙ„Ù…Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø©
    test_words = ["ÙƒØªØ§Ø¨", "Ù…Ø¯Ø±Ø³Ø©", "ÙŠÙƒØªØ¨", "Ù…ÙƒØªÙˆØ¨"]

    for word in test_words:
        print(f"\n{'-'*60}")

        try:
            start_time = time.time()
            results = system.analyze_word(word)
            total_time = time.time() - start_time

            system.print_analysis_summary(results)
            print(f"\nâ±ï¸  Ø¥Ø¬Ù…Ø§Ù„ÙŠ ÙˆÙ‚Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„: {total_time:.4f} Ø«Ø§Ù†ÙŠØ©")

        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ '{word}': {e}")
            import traceback

            traceback.print_exc()

        print(f"{'-'*60}")

    print("\nğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø¨Ø³Ø·!")


if __name__ == "__main__":
    main()
