#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…,
    Advanced Arabic Proper Names Generator,
    ÙŠØ³ØªØ®Ø¯Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ© (22,218 Ù…Ù‚Ø·Ø¹) Ù„ØªÙˆÙ„ÙŠØ¯:
- Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ø®Ø§Øµ (Ø°ÙƒÙˆØ± ÙˆØ¥Ù†Ø§Ø«)
- Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† (Ù…Ø¯Ù†ØŒ Ø¯ÙˆÙ„ØŒ Ù…Ø¹Ø§Ù„Ù… Ø·Ø¨ÙŠØ¹ÙŠØ©)
- Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØ§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© ÙˆØ§Ù„Ø«Ù‚Ø§ÙÙŠØ©,
    Ø§Ù„Ù…Ø·ÙˆØ±: Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠ,
    Developer: Arabic AI System,
    Ø§Ù„ØªØ§Ø±ÙŠØ®: 2025,
    Date: 2025
"""

import re
    import random
    from typing import Dict, List, Optional, Any
    from dataclasses import dataclass, field
    from enum import Enum
    import logging

# Configure logging,
    logging.basicConfig()
    level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROPER NAMES CLASSIFICATION SYSTEM - Ù†Ø¸Ø§Ù… ØªØµÙ†ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ø§Ù…
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ProperNameCategory(Enum):
    """ÙØ¦Ø§Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ø§Ù…"""

    PERSON_MALE = "person_male"  # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø°ÙƒÙˆØ±,
    PERSON_FEMALE = "person_female"  # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ù†Ø§Ø«,
    PLACE_CITY = "place_city"  # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù†,
    PLACE_COUNTRY = "place_country"  # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¯ÙˆÙ„,
    PLACE_NATURAL = "place_natural"  # Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©,
    PLACE_REGION = "place_region"  # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚,
    class NamePattern(Enum):
    """Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØµÙˆØªÙŠØ©"""

    CV = "CV"  # ØµØ§Ù…Øª + ØµØ§Ø¦Øª,
    CVC = "CVC"  # ØµØ§Ù…Øª + ØµØ§Ø¦Øª + ØµØ§Ù…Øª,
    CVCV = "CVCV"  # ØµØ§Ù…Øª + ØµØ§Ø¦Øª + ØµØ§Ù…Øª + ØµØ§Ø¦Øª,
    CVCVC = "CVCVC"  # ÙØ¹Ù„Ø§Ù†ØŒ Ù…Ø­Ù…Ø¯,
    CVVCV = "CVVCV"  # ÙØ§Ø¹Ù„ØŒ Ø³Ø§Ù…ÙŠ,
    CVCVCV = "CVCVCV"  # ÙØ¹Ù„Ø©ØŒ Ø³Ù…ÙŠØ±Ø©,
    CVCCVC = "CVCCVC"  # ÙØ¹Ù„Ø§Ù†ØŒ Ø¹Ø«Ù…Ø§Ù†,
    CVVCVC = "CVVCVC"  # ÙØ§Ø¹Ù„Ø©ØŒ Ø¹Ø§Ø¦Ø´Ø©


@dataclass,
    class NameTemplate:
    """Ù‚Ø§Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡"""

    category: ProperNameCategory,
    pattern: NamePattern,
    syllable_structure: List[str]
    phonetic_constraints: Dict[str, Any]
    semantic_features: List[str]
    frequency: float = 1.0,
    cultural_significance: str = "common"


@dataclass,
    class GeneratedName:
    """Ø§Ø³Ù… Ù…ÙˆÙ„Ø¯"""

    name: str,
    category: ProperNameCategory,
    pattern: NamePattern,
    syllables: List[str]
    phonetic_analysis: Dict[str, Any]
    semantic_meaning: str,
    cultural_context: str,
    authenticity_score: float,
    historical_template: Optional[str] = None,
    examples: List[str] = field(default_factory=list)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARABIC ONOMASTICS ANALYZER - Ù…Ø­Ù„Ù„ Ø¹Ù„Ù… Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ArabicOnomastics:
    """Ù…Ø­Ù„Ù„ Ø¹Ù„Ù… Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""

    def __init__(self):

        # ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø¹Ù„Ù… Ø§Ù„Ø£Ø³Ù…Ø§Ø¡,
    self._load_name_roots()
    self._load_semantic_patterns()
    self._load_phonetic_rules()
    self._load_cultural_templates()

    def _load_name_roots(self):
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ø°ÙˆØ± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""

    self.name_roots = {
            # Ø¬Ø°ÙˆØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø°ÙƒÙˆØ±
    'male_roots': {
    'Ø­Ù…Ø¯': {
    'meaning': 'Ø§Ù„Ø´ÙƒØ± ÙˆØ§Ù„Ø«Ù†Ø§Ø¡',
    'derivatives': ['Ø£Ø­Ù…Ø¯', 'Ù…Ø­Ù…Ø¯', 'Ø­Ù…Ø¯Ø§Ù†', 'Ø­Ø§Ù…Ø¯'],
    },
    'Ø¹Ø¨Ø¯': {
    'meaning': 'Ø§Ù„Ø¹Ø¨Ø§Ø¯Ø© ÙˆØ§Ù„Ø®Ø¶ÙˆØ¹',
    'derivatives': ['Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡', 'Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø­Ù…Ù†', 'Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ²'],
    },
    'Ù†ØµØ±': {
    'meaning': 'Ø§Ù„Ø§Ù†ØªØµØ§Ø± ÙˆØ§Ù„ØºÙ„Ø¨Ø©',
    'derivatives': ['Ù†ØµØ±', 'Ù†Ø§ØµØ±', 'Ù†ØµÙŠØ±', 'Ù…Ù†ØµÙˆØ±'],
    },
    'ÙƒØ±Ù…': {
    'meaning': 'Ø§Ù„Ø¬ÙˆØ¯ ÙˆØ§Ù„Ø³Ø®Ø§Ø¡',
    'derivatives': ['ÙƒØ±ÙŠÙ…', 'Ø£ÙƒØ±Ù…', 'ÙƒØ±Ø§Ù…'],
    },
    'Ø¹Ù„Ù…': {
    'meaning': 'Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙˆØ§Ù„Ø­ÙƒÙ…Ø©',
    'derivatives': ['Ø¹Ù„ÙŠ', 'Ø£Ø¹Ù„Ù…', 'Ø¹Ø§Ù„Ù…', 'Ø¹Ù„Ø§Ù…'],
    },
    'ØµØ¨Ø±': {
    'meaning': 'Ø§Ù„ØªØ­Ù…Ù„ ÙˆØ§Ù„Ø«Ø¨Ø§Øª',
    'derivatives': ['ØµØ§Ø¨Ø±', 'ØµØ¨ÙˆØ±', 'Ù…ØµØ¨ÙˆØ±'],
    },
    'Ø´Ø¬Ø¹': {
    'meaning': 'Ø§Ù„Ø¥Ù‚Ø¯Ø§Ù… ÙˆØ§Ù„Ø¨Ø³Ø§Ù„Ø©',
    'derivatives': ['Ø´Ø¬Ø§Ø¹', 'Ø´Ø¬Ø¹Ø§Ù†', 'Ø£Ø´Ø¬Ø¹'],
    },
    'Ø³Ù„Ù…': {
    'meaning': 'Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ø³ÙƒÙŠÙ†Ø©',
    'derivatives': ['Ø³Ø§Ù„Ù…', 'Ø³Ù„ÙŠÙ…', 'Ù…Ø³Ù„Ù…', 'Ø³Ù„Ø§Ù…Ø©'],
    },
    },
            # Ø¬Ø°ÙˆØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ù†Ø§Ø«
    'female_roots': {
    'ÙØ·Ù…': {
    'meaning': 'Ø§Ù„Ø°ÙƒØ§Ø¡ ÙˆØ§Ù„Ø­ÙƒÙ…Ø©',
    'derivatives': ['ÙØ§Ø·Ù…Ø©', 'ÙØ·ÙˆÙ…', 'ÙØ·ÙŠÙ…Ø©'],
    },
    'Ø¹ÙŠØ´': {
    'meaning': 'Ø§Ù„Ø­ÙŠØ§Ø© ÙˆØ§Ù„Ø³Ø¹Ø§Ø¯Ø©',
    'derivatives': ['Ø¹Ø§Ø¦Ø´Ø©', 'Ø¹ÙŠØ´Ø©', 'Ù…Ø¹ÙŠØ´Ø©'],
    },
    'Ø®Ø¯Ø¬': {'meaning': 'Ø§Ù„Ø¨ÙƒØ± ÙˆØ§Ù„Ø·Ù‡Ø§Ø±Ø©', 'derivatives': ['Ø®Ø¯ÙŠØ¬Ø©', 'Ø®Ø§Ø¯Ø¬Ø©']},
    'Ø²ÙŠÙ†': {
    'meaning': 'Ø§Ù„Ø¬Ù…Ø§Ù„ ÙˆØ§Ù„Ø­Ø³Ù†',
    'derivatives': ['Ø²ÙŠÙ†Ø¨', 'Ø²ÙŠÙ†Ø©', 'Ø²ÙŠÙ†'],
    },
    'Ø£Ù…Ù†': {
    'meaning': 'Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ø·Ù…Ø£Ù†ÙŠÙ†Ø©',
    'derivatives': ['Ø¢Ù…Ù†Ø©', 'Ø£Ù…ÙŠÙ†Ø©', 'Ø£Ù…Ø§Ù†'],
    },
    'Ø±Ø­Ù…': {
    'meaning': 'Ø§Ù„Ø±Ø£ÙØ© ÙˆØ§Ù„Ø­Ù†Ø§Ù†',
    'derivatives': ['Ø±Ø­Ù…Ø©', 'Ø±Ø§Ø­Ù…Ø©', 'Ø±Ø­ÙŠÙ…Ø©'],
    },
    'Ø³Ø¹Ø¯': {
    'meaning': 'Ø§Ù„ÙØ±Ø­ ÙˆØ§Ù„Ø¨Ù‡Ø¬Ø©',
    'derivatives': ['Ø³Ø¹Ø§Ø¯', 'Ø³Ø¹Ø¯Ø©', 'Ø³Ø¹ÙŠØ¯Ø©'],
    },
    'ØµÙÙˆ': {
    'meaning': 'Ø§Ù„Ù†Ù‚Ø§Ø¡ ÙˆØ§Ù„ØµÙØ§Ø¡',
    'derivatives': ['ØµÙÙŠØ©', 'ØµØ§ÙÙŠØ©', 'ØµÙØ§Ø¡'],
    },
    },
            # Ø¬Ø°ÙˆØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ù…Ø§ÙƒÙ†
    'place_roots': {
    'Ù‚Ø¯Ø³': {
    'meaning': 'Ø§Ù„Ø·Ù‡Ø§Ø±Ø© ÙˆØ§Ù„ØªÙ‚Ø¯ÙŠØ³',
    'derivatives': ['Ø§Ù„Ù‚Ø¯Ø³', 'Ø§Ù„Ù…Ù‚Ø¯Ø³'],
    },
    'Ø´Ø±Ù‚': {
    'meaning': 'Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø´Ø±Ù‚ÙŠ',
    'derivatives': ['Ø§Ù„Ø´Ø±Ù‚', 'Ù…Ø´Ø±Ù‚', 'Ø´Ø±Ù‚ÙŠØ©'],
    },
    'Ù†Ø¬Ø¯': {
    'meaning': 'Ø§Ù„Ù…Ø±ØªÙØ¹ Ù…Ù† Ø§Ù„Ø£Ø±Ø¶',
    'derivatives': ['Ù†Ø¬Ø¯', 'Ø§Ù„Ù†Ø¬ÙˆØ¯'],
    },
    'Ø­Ø¬Ø²': {
    'meaning': 'Ø§Ù„Ù…Ø§Ù†Ø¹ ÙˆØ§Ù„Ø­Ø§Ø¬Ø²',
    'derivatives': ['Ø§Ù„Ø­Ø¬Ø§Ø²', 'Ø­Ø¬Ø§Ø²ÙŠØ©'],
    },
    'ÙŠÙ…Ù†': {'meaning': 'Ø§Ù„Ø¨Ø±ÙƒØ© ÙˆØ§Ù„ÙŠÙ…Ù†', 'derivatives': ['Ø§Ù„ÙŠÙ…Ù†', 'ÙŠÙ…Ù†ÙŠØ©']},
    'Ø±ÙØ­': {'meaning': 'Ø§Ù„Ø±ÙØ¹Ø© ÙˆØ§Ù„Ø¹Ù„Ùˆ', 'derivatives': ['Ø±ÙØ­', 'Ø§Ù„Ø±Ø§ÙØ­Ø©']},
    'Ø¨ØµØ±': {
    'meaning': 'Ø§Ù„Ø¥Ø¨ØµØ§Ø± ÙˆØ§Ù„Ù†Ø¸Ø±',
    'derivatives': ['Ø§Ù„Ø¨ØµØ±Ø©', 'Ø¨ØµØ±Ø§ÙˆÙŠØ©'],
    },
    'ÙƒÙˆÙ': {
    'meaning': 'Ø§Ù„ØªØ¬Ù…Ø¹ ÙˆØ§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹',
    'derivatives': ['Ø§Ù„ÙƒÙˆÙØ©', 'ÙƒÙˆÙÙŠØ©'],
    },
    },
    }

    def _load_semantic_patterns(self):
    """ØªØ­Ù…ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©"""

    self.semantic_patterns = {
    'theophoric': {  # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø«Ù†Ø§Ø¡ ÙˆØ§Ù„ØªØ¹Ø¨Ø¯
    'patterns': [
    'Ø¹Ø¨Ø¯ + {divine_name}',
    '{virtue} + Ø§Ù„Ø¯ÙŠÙ†',
    '{virtue} + Ø§Ù„Ù„Ù‡',
    ],
    'divine_names': [
    'Ø§Ù„Ø±Ø­Ù…Ù†',
    'Ø§Ù„Ø±Ø­ÙŠÙ…',
    'Ø§Ù„ÙƒØ±ÙŠÙ…',
    'Ø§Ù„Ø±Ø¤ÙˆÙ',
    'Ø§Ù„ÙˆØ¯ÙˆØ¯',
    'Ø§Ù„ØµØ¨ÙˆØ±',
    ],
    'virtues': ['Ù†ÙˆØ±', 'Ø¨Ù‡Ø§Ø¡', 'Ø¬Ù…Ø§Ù„', 'ÙƒÙ…Ø§Ù„', 'ØµÙ„Ø§Ø­', 'ÙÙ„Ø§Ø­'],
    },
    'descriptive': {  # Ø£Ø³Ù…Ø§Ø¡ ÙˆØµÙÙŠØ©
    'male_descriptors': ['Ø´Ø¬Ø§Ø¹', 'ÙƒØ±ÙŠÙ…', 'Ø­ÙƒÙŠÙ…', 'Ø±Ø¤ÙˆÙ', 'ØµØ¨ÙˆØ±', 'Ø­Ù„ÙŠÙ…'],
    'female_descriptors': [
    'Ø¬Ù…ÙŠÙ„Ø©',
    'Ø­Ø³Ù†Ø§Ø¡',
    'Ø±Ù‚ÙŠÙ‚Ø©',
    'Ù„Ø·ÙŠÙØ©',
    'Ø±Ø­ÙŠÙ…Ø©',
    'Ø­Ù†ÙˆÙ†Ø©',
    ],
    'place_descriptors': [
    'Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©',
    'Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©',
    'Ø§Ù„ÙƒØ¨Ø±Ù‰',
    'Ø§Ù„ØµØºØ±Ù‰',
    'Ø§Ù„Ø¹Ù„ÙŠØ§',
    'Ø§Ù„Ø³ÙÙ„Ù‰',
    ],
    },
    'nature_based': {  # Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªÙˆØ­Ø§Ø© Ù…Ù† Ø§Ù„Ø·Ø¨ÙŠØ¹Ø©
    'natural_elements': ['Ù†Ù‡Ø±', 'Ø¨Ø­Ø±', 'Ø¬Ø¨Ù„', 'ÙˆØ§Ø¯ÙŠ', 'ØµØ­Ø±Ø§Ø¡', 'ÙˆØ§Ø­Ø©'],
    'celestial': ['Ù†Ø¬Ù…', 'Ù‚Ù…Ø±', 'Ø´Ù…Ø³', 'ÙƒÙˆÙƒØ¨', 'ÙØ¬Ø±', 'Ø¶Ø­Ù‰'],
    'plants': ['ÙˆØ±Ø¯Ø©', 'ÙŠØ§Ø³Ù…ÙŠÙ†', 'Ø²Ù‡Ø±Ø©', 'Ù†Ø±Ø¬Ø³', 'Ø±ÙŠØ­Ø§Ù†', 'Ø£Ø²Ù‡Ø§Ø±'],
    },
    }

    def _load_phonetic_rules(self):
    """ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ØµÙˆØªÙŠ"""

    self.phonetic_rules = {
    'consonant_clusters': {
    'allowed': ['Ù†Øª', 'Ù†Ùƒ', 'Ù…Ø¨', 'Ù„Ø¬', 'Ø±Ø³', 'Ø´Ø±', 'Ù‚Øª'],
    'difficult': ['Ù‚Ù', 'Ø·Ø¹', 'Ø­Ø®', 'Ø®Ø­', 'Ø¸Øµ', 'Ø¶Ø·'],
    'forbidden': ['Ø¡Ø¡', 'Ø¬Ø¬Ø¹', 'Ø­Ø­Ø®'],
    },
    'vowel_patterns': {
    'male_endings': ['Ù', 'Ù', 'Ù', 'Ø§Ù†', 'ÙŠÙ†'],  # Ù…ÙØªÙˆØ­Ø© Ø£Ùˆ Ù…ÙƒØ³ÙˆØ±Ø©
    'female_endings': ['Ø©', 'Ø§Ø¡', 'Ù‰', 'Ø§Ù†'],  # ØªØ§Ø¡ Ù…Ø±Ø¨ÙˆØ·Ø©ØŒ Ø£Ù„Ù Ù…Ù…Ø¯ÙˆØ¯Ø©
    'place_endings': ['Ø©', 'ÙŠØ©', 'Ø§Ù†', 'Ø³ØªØ§Ù†'],  # ØªØ§Ø¡ Ù…Ø±Ø¨ÙˆØ·Ø©ØŒ ÙŠØ§Ø¡ Ø§Ù„Ù†Ø³Ø¨Ø©
    },
    'stress_patterns': {
    'penultimate_stress': [
    'CV-CV CV',
    'CVC-CV CV',
    ],  # Ø§Ù„Ù†Ø¨Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø£Ø®ÙŠØ±
    'ultimate_stress': ['CV-CV CVC', 'CV-CVC CVC'],  # Ø§Ù„Ù†Ø¨Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®ÙŠØ±
    'antepenultimate_stress': [
    'CV-CV-CV CV'
    ],  # Ø§Ù„Ù†Ø¨Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø§ Ù‚Ø¨Ù„ Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø£Ø®ÙŠØ±
    },
    }

    def _load_cultural_templates(self):
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ©"""

    self.cultural_templates = {
    'classical_arabic': {
    'male_patterns': ['ÙØ§Ø¹Ù„', 'ÙØ¹ÙŠÙ„', 'ÙØ¹Ø§Ù„', 'ÙØ¹Ù„Ø§Ù†', 'Ù…ÙØ¹ÙˆÙ„'],
    'female_patterns': ['ÙØ§Ø¹Ù„Ø©', 'ÙØ¹ÙŠÙ„Ø©', 'ÙØ¹Ø§Ù„', 'ÙØ¹Ù„Ù‰', 'Ù…ÙØ¹ÙˆÙ„Ø©'],
    'examples': {
    'ÙØ§Ø¹Ù„': ['Ø¹Ø§Ù…Ø±', 'Ø³Ø§Ù…Ø±', 'ÙƒØ§Ù…Ù„', 'Ù†Ø§ØµØ±'],
    'ÙØ¹ÙŠÙ„': ['ÙƒØ±ÙŠÙ…', 'Ø­Ù„ÙŠÙ…', 'Ø±Ø­ÙŠÙ…', 'Ø¹Ù„ÙŠÙ…'],
    },
    },
    'geographical_patterns': {
    'arabian_peninsula': ['Ù†Ø¬Ø¯', 'Ø­Ø¬Ø§Ø²', 'ØªÙ‡Ø§Ù…Ø©', 'Ø¹Ø³ÙŠØ±'],
    'mesopotamian': ['Ø¨ØºØ¯Ø§Ø¯', 'Ø§Ù„Ø¨ØµØ±Ø©', 'Ø§Ù„ÙƒÙˆÙØ©', 'Ø³Ø§Ù…Ø±Ø§Ø¡'],
    'levantine': ['Ø¯Ù…Ø´Ù‚', 'Ø­Ù„Ø¨', 'Ø­Ù…Øµ', 'Ø§Ù„Ù„Ø§Ø°Ù‚ÙŠØ©'],
    'maghrebi': ['ÙØ§Ø³', 'Ù…Ø±Ø§ÙƒØ´', 'ØªÙˆÙ†Ø³', 'Ø§Ù„Ù‚ÙŠØ±ÙˆØ§Ù†'],
    },
    'tribal_names': {
    'noble_tribes': ['Ù‚Ø±ÙŠØ´', 'Ù‡Ø§Ø´Ù…', 'Ø£Ù…ÙŠØ©', 'ØªÙ…ÙŠÙ…'],
    'geographical_tribes': ['Ø­Ø¬Ø§Ø²ÙŠ', 'Ù†Ø¬Ø¯ÙŠ', 'Ø´Ø§Ù…ÙŠ', 'Ø¹Ø±Ø§Ù‚ÙŠ'],
    },
    }

    def derive_meaning(self, name: str, category: ProperNameCategory) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø§Ø³Ù…"""

        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ø°ÙˆØ± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡,
    if category in [ProperNameCategory.PERSON_MALE]:
            for root, info in self.name_roots['male_roots'].items():
                if root in name or any(deriv in name for deriv in info['derivatives']):
    return info['meaning']

        elif category in [ProperNameCategory.PERSON_FEMALE]:
            for root, info in self.name_roots['female_roots'].items():
                if root in name or any(deriv in name for deriv in info['derivatives']):
    return info['meaning']

        elif category.value.startswith('place_'):
            for root, info in self.name_roots['place_roots'].items():
                if root in name or any(deriv in name for deriv in info['derivatives']):
    return info['meaning']

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©,
    if 'Ø¹Ø¨Ø¯' in name:
    return 'Ø§Ù„ØªØ¹Ø¨Ø¯ ÙˆØ§Ù„Ø®Ø¶ÙˆØ¹ Ù„Ù„Ù‡'
        elif name.endswith('ÙŠØ©'):
    return 'Ø§Ù„Ù†Ø³Ø¨Ø© ÙˆØ§Ù„Ø§Ù†ØªÙ…Ø§Ø¡'
        elif name.endswith('Ø§Ù†'):
    return 'Ø§Ù„Ù…ÙƒØ§Ù† Ø£Ùˆ Ø§Ù„Ø²Ù…Ø§Ù†'

    return 'Ø§Ø³Ù… Ø¹Ø±Ø¨ÙŠ Ø£ØµÙŠÙ„'

    def analyze_phonetic_structure(self, name: str) -> Dict[str, Any]:
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµÙˆØªÙŠØ© Ù„Ù„Ø§Ø³Ù…"""

    analysis = {
    'length': len(name),
    'syllable_count': self._count_syllables(name),
    'stress_pattern': self._identify_stress_pattern(name),
    'consonant_clusters': self._find_consonant_clusters(name),
    'vowel_pattern': self._extract_vowel_pattern(name),
    'phonetic_difficulty': self._assess_phonetic_difficulty(name),
    'euphony_score': self._calculate_euphony_score(name),
    }

    return analysis,
    def _count_syllables(self, name: str) -> int:
    """Ø¹Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ©"""
        # ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙƒØ§Øª,
    vowels = ['Ù', 'Ù', 'Ù', 'Ø§', 'Ùˆ', 'ÙŠ']
    return max(1, len([c for c in name if c in vowels]))

    def _identify_stress_pattern(self, name: str) -> str:
    """ØªØ­Ø¯ÙŠØ¯ Ù†Ù…Ø· Ø§Ù„Ù†Ø¨Ø±Ø©"""
    syllable_count = self._count_syllables(name)

        if syllable_count <= 2:
    return 'ultimate'  # Ø§Ù„Ù†Ø¨Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ø£Ø®ÙŠØ±,
    elif syllable_count == 3:
    return 'penultimate'  # Ø§Ù„Ù†Ø¨Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø£Ø®ÙŠØ±,
    else:
    return 'antepenultimate'  # Ø§Ù„Ù†Ø¨Ø±Ø© Ø¹Ù„Ù‰ Ù…Ø§ Ù‚Ø¨Ù„ Ù…Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø£Ø®ÙŠØ±,
    def _find_consonant_clusters(self, name: str) -> List[str]:
    """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªØ¬Ù…Ø¹Ø§Øª Ø§Ù„ØµÙˆØ§Ù…Øª"""
    clusters = []
    consonants = 'Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠØ¡'

        for i in range(len(name) - 1):
            if name[i] in consonants and name[i + 1] in consonants:
    clusters.append(name[i : i + 2])

    return clusters,
    def _extract_vowel_pattern(self, name: str) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ù…Ø· Ø§Ù„Ø­Ø±ÙƒØ§Øª"""
    vowels = {'Ù': 'a', 'Ù': 'i', 'Ù': 'u', 'Ø§': 'aa', 'ÙŠ': 'ii', 'Ùˆ': 'uu'}
    pattern = []

        for char in name:
            if char in vowels:
    pattern.append(vowels[char])

    return ' '.join(pattern)

    def _assess_phonetic_difficulty(self, name: str) -> float:
    """ØªÙ‚ÙŠÙŠÙ… ØµØ¹ÙˆØ¨Ø© Ø§Ù„Ù†Ø·Ù‚"""
    difficulty = 0.0

        # ÙØ­Øµ Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª Ø§Ù„ØµØ¹Ø¨Ø©,
    clusters = self._find_consonant_clusters(name)
        for cluster in clusters:
            if cluster in self.phonetic_rules['consonant_clusters']['difficult']:
    difficulty += 0.3,
    elif cluster in self.phonetic_rules['consonant_clusters']['forbidden']:
    difficulty += 0.5

        # ÙØ­Øµ Ø§Ù„Ø·ÙˆÙ„,
    if len(name) > 10:
    difficulty += 0.2,
    return min(1.0, difficulty)

    def _calculate_euphony_score(self, name: str) -> float:
    """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø¬Ù…Ø§Ù„ Ø§Ù„ØµÙˆØª"""
    euphony = 1.0

        # ØªÙ†ÙˆØ¹ Ø§Ù„Ø£ØµÙˆØ§Øª,
    unique_sounds = len(set(name))
    variety_bonus = min(0.3, unique_sounds / len(name) * 0.5)
    euphony += variety_bonus

        # ØªÙˆØ§Ø²Ù† Ø§Ù„ØµÙˆØ§Ù…Øª ÙˆØ§Ù„ØµÙˆØ§Ø¦Øª,
    consonants = len([c for c in name if c in 'Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠØ¡'])
    vowels = len([c for c in name if c in 'ÙÙÙØ§ÙˆÙŠÙ‹'])

        if vowels > 0:
    balance = 1 - abs(consonants - vowels) / max(consonants, vowels)
    euphony += balance * 0.2

        # Ø®ØµÙ… Ø§Ù„ØµØ¹ÙˆØ¨Ø©,
    difficulty = self._assess_phonetic_difficulty(name)
    euphony -= difficulty * 0.3,
    return max(0.0, min(2.0, euphony))

    def has_negative_connotation(self, name: str) -> bool:
    """ÙØ­Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ©"""
    negative_roots = {
    'Ù…ÙˆØª',
    'Ù‚ØªÙ„',
    'Ø­Ø±Ø¨',
    'Ù…Ø±Ø¶',
    'ÙÙ‚Ø±',
    'Ø­Ø²Ù†',
    'Ø¶Ø¹Ù',
    'Ø°Ù„',
    'Ø®Ø³Ø±',
    'Ù‡Ø²Ù…',
    'ÙƒØ³Ø±',
    'ØªØ¹Ø¨',
    'Ø¶ÙŠÙ‚',
    'Ø¸Ù„Ù…',
    'ØºØ¶Ø¨',
    }

        for root in negative_roots:
            if root in name:
    return True,
    return False,
    def suggest_similar_authentic_names()
    self, name: str, category: ProperNameCategory
    ) -> List[str]:
    """Ø§Ù‚ØªØ±Ø§Ø­ Ø£Ø³Ù…Ø§Ø¡ Ø£ØµÙŠÙ„Ø© Ù…Ø´Ø§Ø¨Ù‡Ø©"""

    authentic_names = {
    ProperNameCategory.PERSON_MALE: [
    'Ù…Ø­Ù…Ø¯',
    'Ø£Ø­Ù…Ø¯',
    'Ø¹Ù„ÙŠ',
    'Ø­Ø³Ù†',
    'Ø­Ø³ÙŠÙ†',
    'Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡',
    'Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø­Ù…Ù†',
    'Ø¹Ù…Ø±',
    'Ø¹Ø«Ù…Ø§Ù†',
    'Ø®Ø§Ù„Ø¯',
    'Ø³Ø¹Ø¯',
    'ÙÙŠØµÙ„',
    'Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ²',
    ],
    ProperNameCategory.PERSON_FEMALE: [
    'ÙØ§Ø·Ù…Ø©',
    'Ø¹Ø§Ø¦Ø´Ø©',
    'Ø®Ø¯ÙŠØ¬Ø©',
    'Ø²ÙŠÙ†Ø¨',
    'Ø±Ù‚ÙŠØ©',
    'Ø£Ù… ÙƒÙ„Ø«ÙˆÙ…',
    'ØµÙÙŠØ©',
    'Ù…Ø±ÙŠÙ…',
    'Ø¢Ù…Ù†Ø©',
    'Ø³Ø§Ø±Ø©',
    'Ù„ÙŠÙ„Ù‰',
    'Ø³Ø¹Ø§Ø¯',
    'Ù†ÙˆØ±Ø§',
    ],
    ProperNameCategory.PLACE_CITY: [
    'Ù…ÙƒØ©',
    'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©',
    'Ø§Ù„Ø±ÙŠØ§Ø¶',
    'Ø¬Ø¯Ø©',
    'Ø§Ù„Ø¯Ù…Ø§Ù…',
    'Ø§Ù„Ø·Ø§Ø¦Ù',
    'Ø£Ø¨Ù‡Ø§',
    'Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©',
    'Ø¯Ù…Ø´Ù‚',
    'Ø¨ØºØ¯Ø§Ø¯',
    'Ø¨ÙŠØ±ÙˆØª',
    'ØªÙˆÙ†Ø³',
    'Ø§Ù„Ø±Ø¨Ø§Ø·',
    ],
    }

    candidates = authentic_names.get(category, [])
    similar_names = []

        for candidate in candidates:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„ØµÙˆØªÙŠ,
    similarity = self._calculate_phonetic_similarity(name, candidate)
            if similarity > 0.5:
    similar_names.append((candidate, similarity))

        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø£ÙØ¶Ù„ 5,
    similar_names.sort(key=lambda x: x[1], reverse=True)
    return [name for name, _ in similar_names[:5]]

    def _calculate_phonetic_similarity(self, name1: str, name2: str) -> float:
    """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„ØµÙˆØªÙŠ"""
        # Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙÙŠ Ø§Ù„Ø·ÙˆÙ„,
    len_sim = 1 - abs(len(name1) - len(name2)) / max(len(name1), len(name2), 1)

        # Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙÙŠ Ø§Ù„Ø£Ø­Ø±Ù,
    set1, set2 = set(name1), set(name2)
    char_sim = len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0

        # Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©,
    start_sim = 1 if name1[:1] == name2[:1] else 0,
    end_sim = 1 if name1[-1:] == name2[-1:] else 0

        # Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¬Ø­,
    similarity = 0.3 * len_sim + 0.4 * char_sim + 0.15 * start_sim + 0.15 * end_sim,
    return similarity


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADVANCED PROPER NAMES GENERATOR - Ù…ÙˆÙ„Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class AdvancedArabicProperNamesGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""

    def __init__(self, syllables_database: Optional[List[Dict]] = None):

    self.syllables_db = syllables_database or self._load_syllables_database()
    self.onomastics = ArabicOnomastics()

        # ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡,
    self._load_name_templates()

    logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.syllables_db)} Ù…Ù‚Ø·Ø¹ ØµÙˆØªÙŠ")
    logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.name_templates)} Ù‚Ø§Ù„Ø¨ Ø§Ø³Ù…")

    def _load_syllables_database(self) -> List[Dict]:
    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""

        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„
    from comprehensive_arabic_verb_syllable_generator import ()
    ComprehensiveArabicVerbSyllableGenerator)

    syllable_generator = ComprehensiveArabicVerbSyllableGenerator()
    logger.info("ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„...")

            # ØªÙˆÙ„ÙŠØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©,
    syllable_database = ()
    syllable_generator.generate_comprehensive_syllable_database()
    )

    logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(syllable_database)} Ù…Ù‚Ø·Ø¹ Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„")
    return syllable_database,
    except ImportError:
    logger.warning("Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„ ØºÙŠØ± Ù…ØªØ§Ø­ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©")
    return self._create_enhanced_syllable_database()

    def _create_enhanced_syllable_database(self) -> List[Dict]:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‚Ø§Ø·Ø¹ Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø£Ø³Ù…Ø§Ø¡"""

    syllables = []

        # Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ ØªØµÙ†ÙŠÙÙ‡Ø§,
    consonants = {
    'common': [
    'Ø¨',
    'Øª',
    'Ø¬',
    'Ø¯',
    'Ø±',
    'Ø³',
    'Ø¹',
    'Ù',
    'Ùƒ',
    'Ù„',
    'Ù…',
    'Ù†',
    'Ù‡',
    'Ùˆ',
    'ÙŠ',
    ],
    'emphatic': ['Øµ', 'Ø¶', 'Ø·', 'Ø¸'],
    'uvular': ['Ù‚', 'Øº', 'Ø®'],
    'pharyngeal': ['Ø­', 'Ø¹'],
    'fricative': ['Ø«', 'Ø°', 'Ø´', 'Ø²'],
    'glottal': ['Ø¡', 'Ù‡'],
    }

        # Ø§Ù„Ø­Ø±ÙƒØ§Øª Ù…Ø¹ ØªØµÙ†ÙŠÙÙ‡Ø§,
    vowels = {
    'short': ['Ù', 'Ù', 'Ù'],
    'long': ['Ø§', 'ÙŠ', 'Ùˆ'],
    'diphthongs': ['Ø§ÙŠ', 'Ø§Ùˆ', 'ÙˆÙŠ'],
    }

        # ØªÙˆÙ„ÙŠØ¯ Ù…Ù‚Ø§Ø·Ø¹ CV,
    for category, cons_list in consonants.items():
            for consonant in cons_list:
                for vowel in vowels['short']:
    syllables.append()
    {
    'syllable': consonant + vowel,
    'pattern': 'CV',
    'consonants': [consonant],
    'vowels': [vowel],
    'consonant_type': category,
    'weight': 'light',
    'name_suitable': True,
    'frequency': 0.8 if category == 'common' else 0.5,
    }
    )

        # ØªÙˆÙ„ÙŠØ¯ Ù…Ù‚Ø§Ø·Ø¹ CVC,
    end_consonants = ['Ù†', 'Ù„', 'Ø±', 'Ù…', 'Øª', 'Ø¯', 'Ø³', 'Ùƒ', 'ÙŠ', 'Ø¨']
        for category, cons_list in consonants.items():
            for c1 in cons_list[:8]:  # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø¯Ø¯,
    for vowel in vowels['short']:
                    for c2 in end_consonants:
    syllables.append()
    {
    'syllable': c1 + vowel + c2,
    'pattern': 'CVC',
    'consonants': [c1, c2],
    'vowels': [vowel],
    'consonant_type': category,
    'weight': 'medium',
    'name_suitable': True,
    'frequency': 0.6 if category == 'common' else 0.3,
    }
    )

        # ØªÙˆÙ„ÙŠØ¯ Ù…Ù‚Ø§Ø·Ø¹ Ø·ÙˆÙŠÙ„Ø© CVV,
    for category, cons_list in consonants.items():
            for consonant in cons_list[:10]:
                for long_vowel in vowels['long']:
    syllables.append()
    {
    'syllable': consonant + long_vowel,
    'pattern': 'CVV',
    'consonants': [consonant],
    'vowels': [long_vowel],
    'consonant_type': category,
    'weight': 'heavy',
    'name_suitable': True,
    'frequency': 0.4 if category == 'common' else 0.2,
    }
    )

        # Ù…Ù‚Ø§Ø·Ø¹ Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡,
    name_specific_syllables = [
            # Ù…Ù‚Ø§Ø·Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø°ÙƒÙˆØ±
    {
    'syllable': 'Ù…Ø­',
    'pattern': 'CVC',
    'name_type': 'male',
    'meaning': 'Ù…Ø­Ùˆ/Ø·Ù‡Ø§Ø±Ø©',
    },
    {
    'syllable': 'Ø£Ø­',
    'pattern': 'CVC',
    'name_type': 'male',
    'meaning': 'Ø§Ù„Ø­Ù…Ø¯',
    },
    {
    'syllable': 'Ø¹Ø¨Ø¯',
    'pattern': 'CVCC',
    'name_type': 'male',
    'meaning': 'Ø§Ù„Ø¹Ø¨Ø§Ø¯Ø©',
    },
    {
    'syllable': 'Ø®Ø§',
    'pattern': 'CV',
    'name_type': 'male',
    'meaning': 'Ø§Ù„Ø®ÙŠØ±',
    },
    {
    'syllable': 'Ù†Ø§',
    'pattern': 'CV',
    'name_type': 'male',
    'meaning': 'Ø§Ù„Ù†ÙŠÙ„',
    },
            # Ù…Ù‚Ø§Ø·Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø¥Ù†Ø§Ø«
    {
    'syllable': 'ÙØ§',
    'pattern': 'CV',
    'name_type': 'female',
    'meaning': 'Ø§Ù„Ø¹Ø¸Ù…Ø©',
    },
    {
    'syllable': 'Ø¹Ø§',
    'pattern': 'CV',
    'name_type': 'female',
    'meaning': 'Ø§Ù„Ø­ÙŠØ§Ø©',
    },
    {
    'syllable': 'Ø²ÙŠ',
    'pattern': 'CV',
    'name_type': 'female',
    'meaning': 'Ø§Ù„Ø²ÙŠÙ†Ø©',
    },
    {
    'syllable': 'Ø®Ø¯ÙŠ',
    'pattern': 'CCV',
    'name_type': 'female',
    'meaning': 'Ø§Ù„Ø¨ÙƒØ§Ø±Ø©',
    },
    {
    'syllable': 'Ù…Ø©',
    'pattern': 'CV',
    'name_type': 'female',
    'meaning': 'Ø§Ù„ØªØ£Ù†ÙŠØ«',
    },
            # Ù…Ù‚Ø§Ø·Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø£Ù…Ø§ÙƒÙ†
    {
    'syllable': 'Ù…Ùƒ',
    'pattern': 'CVC',
    'name_type': 'place',
    'meaning': 'Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ù‚Ø¯Ø³',
    },
    {
    'syllable': 'Ø¨Øº',
    'pattern': 'CVC',
    'name_type': 'place',
    'meaning': 'Ø§Ù„Ø¹Ø·Ø§Ø¡',
    },
    {
    'syllable': 'Ø¯Ù…',
    'pattern': 'CVC',
    'name_type': 'place',
    'meaning': 'Ø§Ù„Ù‚Ø¯Ù…/Ø§Ù„Ø¹Ø±Ø§Ù‚Ø©',
    },
    {
    'syllable': 'Ù‚Ø¯',
    'pattern': 'CVC',
    'name_type': 'place',
    'meaning': 'Ø§Ù„ØªÙ‚Ø¯ÙŠØ³',
    },
    ]

        for special in name_specific_syllables:
    special.update()
    {
    'weight': 'light',
    'frequency': 1.0,
    'name_suitable': True,
    'is_authentic': True,
    }
    )
    syllables.append(special)

    logger.info(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(syllables)} Ù…Ù‚Ø·Ø¹ ØµÙˆØªÙŠ Ù…Ø­Ø³Ù† Ù„Ù„Ø£Ø³Ù…Ø§Ø¡")
    return syllables,
    def _load_name_templates(self):
    """ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡"""

    self.name_templates = {
            # Ù‚ÙˆØ§Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø°ÙƒÙˆØ±,
    ProperNameCategory.PERSON_MALE: [
    NameTemplate()
    category=ProperNameCategory.PERSON_MALE,
    pattern=NamePattern.CVCVC,
    syllable_structure=['CVC', 'CVC'],
    phonetic_constraints={
    'max_syllables': 3,
    'min_syllables': 2,
    'preferred_endings': ['Ù', 'Ù', 'Ø§Ù†', 'ÙŠÙ†'],
    'avoid_feminine_endings': True,
    },
    semantic_features=['masculine', 'strength', 'honor'],
    frequency=1.0,
    cultural_significance='classical'),
    NameTemplate()
    category=ProperNameCategory.PERSON_MALE,
    pattern=NamePattern.CVVCV,
    syllable_structure=['CVV', 'CV'],
    phonetic_constraints={
    'max_syllables': 3,
    'preferred_patterns': ['ÙØ§Ø¹Ù„', 'ÙƒØ§ØªØ¨', 'Ø¹Ø§Ù…Ø±'],
    'long_vowel_position': 'medial',
    },
    semantic_features=['descriptive', 'active', 'professional'],
    frequency=0.8,
    cultural_significance='descriptive'),
    ],
            # Ù‚ÙˆØ§Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ù†Ø§Ø«,
    ProperNameCategory.PERSON_FEMALE: [
    NameTemplate()
    category=ProperNameCategory.PERSON_FEMALE,
    pattern=NamePattern.CVCVCV,
    syllable_structure=['CV', 'CV', 'CV'],
    phonetic_constraints={
    'max_syllables': 4,
    'min_syllables': 2,
    'required_endings': ['Ø©', 'Ø§Ø¡', 'Ù‰'],
    'feminine_markers': True,
    },
    semantic_features=['feminine', 'beauty', 'grace'],
    frequency=1.0,
    cultural_significance='traditional'),
    NameTemplate()
    category=ProperNameCategory.PERSON_FEMALE,
    pattern=NamePattern.CVVCVC,
    syllable_structure=['CVV', 'CVC'],
    phonetic_constraints={
    'max_syllables': 3,
    'preferred_patterns': ['ÙØ§Ø¹Ù„Ø©', 'ÙƒØ§ØªØ¨Ø©'],
    'long_vowel_position': 'initial',
    },
    semantic_features=['descriptive', 'noble', 'virtue'],
    frequency=0.7,
    cultural_significance='aristocratic'),
    ],
            # Ù‚ÙˆØ§Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù†,
    ProperNameCategory.PLACE_CITY: [
    NameTemplate()
    category=ProperNameCategory.PLACE_CITY,
    pattern=NamePattern.CVCVC,
    syllable_structure=['CVC', 'CVC'],
    phonetic_constraints={
    'max_syllables': 3,
    'geographical_indicators': True,
    'common_city_endings': ['Ø©', 'Ø§Ø¯', 'Ø§Ù†'],
    },
    semantic_features=['urban', 'settlement', 'commerce'],
    frequency=1.0,
    cultural_significance='geographical'),
    NameTemplate()
    category=ProperNameCategory.PLACE_CITY,
    pattern=NamePattern.CVVCV,
    syllable_structure=['CVV', 'CV'],
    phonetic_constraints={
    'max_syllables': 3,
    'historical_patterns': True,
    },
    semantic_features=['ancient', 'cultural', 'trading'],
    frequency=0.6,
    cultural_significance='historical'),
    ],
            # Ù‚ÙˆØ§Ù„Ø¨ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¯ÙˆÙ„,
    ProperNameCategory.PLACE_COUNTRY: [
    NameTemplate()
    category=ProperNameCategory.PLACE_COUNTRY,
    pattern=NamePattern.CVCVCV,
    syllable_structure=['CV', 'CV', 'CV'],
    phonetic_constraints={
    'max_syllables': 4,
    'min_syllables': 3,
    'country_suffixes': ['Ø³ØªØ§Ù†', 'ÙŠØ©', 'Ø§Ù†'],
    'formal_tone': True,
    },
    semantic_features=['nation', 'sovereignty', 'territory'],
    frequency=1.0,
    cultural_significance='political'),
    ],
            # Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©,
    ProperNameCategory.PLACE_NATURAL: [
    NameTemplate()
    category=ProperNameCategory.PLACE_NATURAL,
    pattern=NamePattern.CVCV,
    syllable_structure=['CV', 'CV'],
    phonetic_constraints={
    'max_syllables': 3,
    'nature_indicators': True,
    'descriptive_elements': ['ÙˆØ§Ø¯ÙŠ', 'Ø¬Ø¨Ù„', 'Ù†Ù‡Ø±'],
    },
    semantic_features=['natural', 'landscape', 'geographical'],
    frequency=1.0,
    cultural_significance='environmental'),
    ],
    }

    def generate_names()
    self,
    category: ProperNameCategory,
    count: int = 20,
    specific_meaning: Optional[str] = None) -> List[GeneratedName]:
    """ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø£Ø¹Ù„Ø§Ù… Ù„ÙØ¦Ø© Ù…Ø­Ø¯Ø¯Ø©"""

    logger.info(f"Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ {count} Ø§Ø³Ù… Ù…Ù† ÙØ¦Ø© {category.value}")

    templates = self.name_templates.get(category, [])
        if not templates:
    logger.warning(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙˆØ§Ù„Ø¨ Ù„Ù„ÙØ¦Ø© {category.value}")
    return []

    generated_names = []
    attempts = 0,
    max_attempts = count * 15,
    while len(generated_names) < count and attempts < max_attempts:
    attempts += 1

            # Ø§Ø®ØªÙŠØ§Ø± Ù‚Ø§Ù„Ø¨ Ø¹Ø´ÙˆØ§Ø¦ÙŠ,
    template = random.choice(templates)

            # ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ù…Ø±Ø´Ø­,
    candidate_name = self._generate_candidate_name(template)

            if candidate_name:
                # ØªØ­Ù„ÙŠÙ„ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³Ù…,
    generated_name = self._evaluate_and_create_name()
    candidate_name, template, specific_meaning
    )

                if generated_name and generated_name.authenticity_score >= 0.4:
                    # ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±,
    if not any()
    gn.name == generated_name.name for gn in generated_names
    ):
    generated_names.append(generated_name)

                        if len(generated_names) % 5 == 0:
    logger.info(f"ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(generated_names)} Ø§Ø³Ù…...")

        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡,
    generated_names.sort(key=lambda x: x.authenticity_score, reverse=True)

    logger.info()
    f"ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† ØªÙˆÙ„ÙŠØ¯ {len(generated_names)} Ø§Ø³Ù… Ù…Ù† ÙØ¦Ø© {category.value}"
    )
    return generated_names,
    def _generate_candidate_name(self, template: NameTemplate) -> Optional[str]:
    """ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ù…Ø±Ø´Ø­ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø§Ù„Ø¨"""

    syllable_structure = template.syllable_structure

        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©,
    name_syllables = []
        for i, syllable_pattern in enumerate(syllable_structure):

            # ØªØµÙÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©,
    suitable_syllables = self._filter_suitable_syllables()
    syllable_pattern, template, i == 0, i == len(syllable_structure) - 1
    )

            if not suitable_syllables:
    return None,
    chosen_syllable = random.choice(suitable_syllables)
    name_syllables.append(chosen_syllable['syllable'])

        if not name_syllables:
    return None

        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³Ù…,
    candidate_name = ''.join(name_syllables)

        # ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙˆØ§Ø¹Ø¯ ØªØ§Ø±ÙŠØ®ÙŠØ© ÙˆØ«Ù‚Ø§ÙÙŠØ©,
    candidate_name = self._apply_cultural_modifications(candidate_name, template)

        # ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙˆØ§Ø¹Ø¯ ØµÙˆØªÙŠØ©,
    candidate_name = self._apply_phonetic_rules(candidate_name, template)

    return candidate_name,
    def _filter_suitable_syllables()
    self, pattern: str, template: NameTemplate, is_first: bool, is_last: bool
    ) -> List[Dict]:
    """ØªØµÙÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù†Ù…Ø· ÙˆØ§Ù„Ù‚Ø§Ù„Ø¨"""

    suitable = []
    constraints = template.phonetic_constraints,
    for syllable in self.syllables_db:
            # ÙØ­Øµ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ,
    if syllable.get('pattern') != pattern:
    continue

            # ÙØ­Øµ Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø© Ù„Ù„Ø£Ø³Ù…Ø§Ø¡,
    if not syllable.get('name_suitable', True):
    continue

            # Ù‚ÙŠÙˆØ¯ Ø§Ù„Ù…ÙˆÙ‚Ø¹ (Ø£ÙˆÙ„/Ø£Ø®ÙŠØ±)
            if is_first and 'preferred_initials' in constraints:
    syl_text = syllable['syllable']
                if syl_text and syl_text[0] not in constraints['preferred_initials']:
    continue,
    if is_last and 'required_endings' in constraints:
    syl_text = syllable['syllable']
                if not any()
    syl_text.endswith(ending)
                    for ending in constraints['required_endings']
    ):
    continue

            # Ù‚ÙŠÙˆØ¯ Ø§Ù„Ù†ÙˆØ¹ (Ø°ÙƒØ±/Ø£Ù†Ø«Ù‰)
            if template.category == ProperNameCategory.PERSON_FEMALE:
                if constraints.get('feminine_markers') and is_last:
    syl_text = syllable['syllable']
                    if not any()
    syl_text.endswith(marker) for marker in ['Ø©', 'Ø§Ø¡', 'Ù‰', 'Ø§Ù†']
    ):
    continue,
    elif template.category == ProperNameCategory.PERSON_MALE:
                if constraints.get('avoid_feminine_endings') and is_last:
    syl_text = syllable['syllable']
                    if any(syl_text.endswith(marker) for marker in ['Ø©', 'Ø§Ø¡']):
    continue

            # Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø£Ù…Ø§ÙƒÙ†,
    elif template.category.value.startswith('place_'):
                if 'geographical_indicators' in constraints and is_last:
                    # ØªÙØ¶ÙŠÙ„ Ù†Ù‡Ø§ÙŠØ§Øª Ø¬ØºØ±Ø§ÙÙŠØ©,
    pass

    suitable.append(syllable)

    return suitable,
    def _apply_cultural_modifications(self, name: str, template: NameTemplate) -> str:
    """ØªØ·Ø¨ÙŠÙ‚ ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø«Ù‚Ø§ÙÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù…"""

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©,
    if ()
    template.category == ProperNameCategory.PERSON_MALE,
    and random.random() < 0.3
    ):
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø«Ù†Ø§Ø¡ (Ø¹Ø¨Ø¯ + ØµÙØ© Ø¥Ù„Ù‡ÙŠØ©)
            if len(name) <= 4:
    divine_names = ['Ø§Ù„Ø±Ø­Ù…Ù†', 'Ø§Ù„Ø±Ø­ÙŠÙ…', 'Ø§Ù„ÙƒØ±ÙŠÙ…', 'Ø§Ù„ÙˆØ¯ÙˆØ¯']
    divine_name = random.choice(divine_names)
    return f"Ø¹Ø¨Ø¯{divine_name}"

            # Ø£Ø³Ù…Ø§Ø¡ Ù…Ø±ÙƒØ¨Ø© Ø¯ÙŠÙ†ÙŠØ©,
    elif random.random() < 0.5:
    religious_prefixes = ['Ù†ÙˆØ±', 'Ø¨Ù‡Ø§Ø¡', 'Ø¬Ù…Ø§Ù„']
    religious_suffixes = ['Ø§Ù„Ø¯ÙŠÙ†', 'Ø§Ù„Ø¥Ø³Ù„Ø§Ù…']
                if random.random() < 0.5:
    prefix = random.choice(religious_prefixes)
    suffix = random.choice(religious_suffixes)
    return f"{prefix {suffix}}"

        # ØªØ·Ø¨ÙŠÙ‚ Ù„ÙˆØ§Ø­Ù‚ Ø§Ù„Ø£Ù…Ø§ÙƒÙ†,
    elif ()
    template.category == ProperNameCategory.PLACE_CITY and random.random() < 0.4
    ):
    city_suffixes = ['ÙŠØ©', 'Ø§Ù†', 'Ø§Ø¨Ø§Ø¯']
    suffix = random.choice(city_suffixes)
    return name + suffix,
    elif ()
    template.category == ProperNameCategory.PLACE_COUNTRY,
    and random.random() < 0.6
    ):
    country_suffixes = ['Ø³ØªØ§Ù†', 'ÙŠØ©', 'Ø§Ù†']
    suffix = random.choice(country_suffixes)
    return name + suffix,
    elif ()
    template.category == ProperNameCategory.PLACE_NATURAL,
    and random.random() < 0.5
    ):
    nature_prefixes = ['ÙˆØ§Ø¯ÙŠ', 'Ø¬Ø¨Ù„', 'Ù†Ù‡Ø±', 'Ø¨Ø­Ø±']
    prefix = random.choice(nature_prefixes)
    return f"{prefix {name}}"

    return name,
    def _apply_phonetic_rules(self, name: str, template: NameTemplate) -> str:
    """ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙˆØ§Ø¹Ø¯ ØµÙˆØªÙŠØ© Ù„Ù„ØªØ­Ø³ÙŠÙ†"""

        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØ±Ø·Ø©,
    name = re.sub(r'(.)\1{2,}', r'\1\1', name)

        # ØªØ¨Ø³ÙŠØ· Ø§Ù„ØªØ¬Ù…Ø¹Ø§Øª Ø§Ù„ØµØ¹Ø¨Ø©,
    difficult_clusters = ['Ù‚Ù', 'Ø·Ø¹', 'Ø­Ø®', 'Ø®Ø­']
        for cluster in difficult_clusters:
            if cluster in name:
                # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø¨ØªØ¬Ù…Ø¹ Ø£Ø³Ù‡Ù„,
    easier_alternatives = {'Ù‚Ù': 'Ù‚Ø¯', 'Ø·Ø¹': 'Ø·Ø±', 'Ø­Ø®': 'Ø­Ø±', 'Ø®Ø­': 'Ø®Ø±'}
    name = name.replace()
    cluster, easier_alternatives.get(cluster, cluster[0])
    )

        # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¯ÙÙ‚ Ø§Ù„ØµÙˆØªÙŠ,
    name = self._improve_euphony(name)

    return name,
    def _improve_euphony(self, name: str) -> str:
    """ØªØ­Ø³ÙŠÙ† Ø¬Ù…Ø§Ù„ Ø§Ù„ØµÙˆØª"""

        # Ø¥Ø¶Ø§ÙØ© Ø­Ø±ÙƒØ§Øª Ù„Ù„ØªÙˆØ¶ÙŠØ­,
    if len(name) >= 3 and not any(c in name for c in 'ÙÙÙØ§ÙˆÙŠÙ‹'):
            # Ø¥Ø¶Ø§ÙØ© Ø­Ø±ÙƒØ© ÙÙŠ Ø§Ù„ÙˆØ³Ø·,
    mid_pos = len(name) // 2,
    vowels = ['Ù', 'Ù', 'Ù']
    name = name[:mid_pos] + random.choice(vowels) + name[mid_pos:]

    return name,
    def _evaluate_and_create_name()
    self, name: str, template: NameTemplate, specific_meaning: Optional[str] = None
    ) -> Optional[GeneratedName]:
    """ØªÙ‚ÙŠÙŠÙ… ÙˆØ¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ„Ø¯"""

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©,
    if not self._validate_basic_constraints(name, template):
    return None

        # ÙØ­Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ©,
    if self.onomastics.has_negative_connotation(name):
    return None

        # ØªØ­Ù„ÙŠÙ„ ØµÙˆØªÙŠ Ø´Ø§Ù…Ù„,
    phonetic_analysis = self.onomastics.analyze_phonetic_structure(name)

        # ÙØ­Øµ Ø§Ù„ØµØ¹ÙˆØ¨Ø© Ø§Ù„ØµÙˆØªÙŠØ©,
    if phonetic_analysis['phonetic_difficulty'] > 0.6:
    return None

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù†Ù‰,
    semantic_meaning = self.onomastics.derive_meaning(name, template.category)
        if specific_meaning and specific_meaning not in semantic_meaning:
    semantic_meaning = f"{semantic_meaning} - {specific_meaning}}"

        # Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„Ø£ØµØ§Ù„Ø©,
    authenticity_score = self._calculate_authenticity_score()
    name, template, phonetic_analysis
    )

        # Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† Ø§Ù„Ø§Ø³Ù…,
    generated_name = GeneratedName()
    name=name,
    category=template.category,
    pattern=template.pattern,
    syllables=self._breakdown_name_syllables(name),
    phonetic_analysis=phonetic_analysis,
    semantic_meaning=semantic_meaning,
    cultural_context=template.cultural_significance,
    authenticity_score=authenticity_score,
    historical_template=self._identify_historical_template(name),
    examples=self.onomastics.suggest_similar_authentic_names()
    name, template.category
    ))

    return generated_name,
    def _validate_basic_constraints(self, name: str, template: NameTemplate) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""

    constraints = template.phonetic_constraints

        # ÙØ­Øµ Ø§Ù„Ø·ÙˆÙ„,
    if len(name) < 2 or len(len(name) -> 15) > 15:
    return False

        # ÙØ­Øµ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹,
    syllable_count = self.onomastics._count_syllables(name)
    max_syllables = constraints.get('max_syllables', 4)
    min_syllables = constraints.get('min_syllables', 1)

        if syllable_count > max_syllables or syllable_count < min_syllables:
    return False

        # ÙØ­Øµ Ø§Ù„Ù†Ù‡Ø§ÙŠØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©,
    if 'required_endings' in constraints:
            if not any()
    name.endswith(ending) for ending in constraints['required_endings']
    ):
    return False,
    return True,
    def _calculate_authenticity_score()
    self, name: str, template: NameTemplate, phonetic_analysis: Dict[str, Any]
    ) -> float:
    """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„Ø£ØµØ§Ù„Ø© ÙˆØ§Ù„Ø¬ÙˆØ¯Ø©"""

    score = 0.5  # Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©

        # Ù†Ù‚Ø§Ø· Ø§Ù„Ø¬Ù…Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ,
    euphony_score = phonetic_analysis.get('euphony_score', 1.0)
    score += euphony_score * 0.3

        # Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£ØµÙŠÙ„Ø©,
    similar_names = self.onomastics.suggest_similar_authentic_names()
    name, template.category
    )
        if similar_names:
    similarity_bonus = len(similar_names) * 0.1,
    score += min(0.3, similarity_bonus)

        # Ù†Ù‚Ø§Ø· Ø§Ù„Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„ØµÙˆØªÙŠØ©,
    difficulty = phonetic_analysis.get('phonetic_difficulty', 0.0)
    score += (1.0 - difficulty) * 0.2

        # Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø«Ù‚Ø§ÙÙŠØ©,
    if template.cultural_significance in ['classical', 'traditional']:
    score += 0.1,
    elif template.cultural_significance in ['historical', 'religious']:
    score += 0.15

        # Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„ØµÙˆØªÙŠ,
    if phonetic_analysis.get('syllable_count', 1) in [2, 3]:  # Ø·ÙˆÙ„ Ù…Ø«Ø§Ù„ÙŠ,
    score += 0.1,
    return min(1.0, max(0.0, score))

    def _breakdown_name_syllables(self, name: str) -> List[str]:
    """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø§Ø³Ù… Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹"""

    syllables = []
    current_syllable = ""

    vowels = {'Ù', 'Ù', 'Ù', 'Ø§', 'ÙŠ', 'Ùˆ', 'Ù‹', 'ÙŒ', 'Ù'}
    consonants = {
    'Ø¨',
    'Øª',
    'Ø«',
    'Ø¬',
    'Ø­',
    'Ø®',
    'Ø¯',
    'Ø°',
    'Ø±',
    'Ø²',
    'Ø³',
    'Ø´',
    'Øµ',
    'Ø¶',
    'Ø·',
    'Ø¸',
    'Ø¹',
    'Øº',
    'Ù',
    'Ù‚',
    'Ùƒ',
    'Ù„',
    'Ù…',
    'Ù†',
    'Ù‡',
    'Ùˆ',
    'ÙŠ',
    'Ø¡',
    }

        for i, char in enumerate(name):
    current_syllable += char

            # Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø¹Ù†Ø¯ Ø§Ù„ÙˆØµÙˆÙ„ Ù„ØµØ§Ø¦Øª ÙŠÙ„ÙŠÙ‡ ØµØ§Ù…Øª,
    if char in vowels and i < len(name) - 1:
    next_char = name[i + 1]
                if next_char in consonants:
    syllables.append(current_syllable)
    current_syllable = ""

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ø£Ø®ÙŠØ±,
    if current_syllable:
    syllables.append(current_syllable)

    return syllables if syllables else [name]

    def _identify_historical_template(self, name: str) -> Optional[str]:
    """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ Ù„Ù„Ø§Ø³Ù…"""

        if name.startswith('Ø¹Ø¨Ø¯'):
    return 'theophoric'  # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø«Ù†Ø§Ø¡,
    elif ' Ø§Ù„Ø¯ÙŠÙ†' in name or ' Ø§Ù„Ø¥Ø³Ù„Ø§Ù…' in name:
    return 'religious_compound'  # Ù…Ø±ÙƒØ¨Ø§Øª Ø¯ÙŠÙ†ÙŠØ©,
    elif name.startswith(('ÙˆØ§Ø¯ÙŠ', 'Ø¬Ø¨Ù„', 'Ù†Ù‡Ø±', 'Ø¨Ø­Ø±')):
    return 'geographical_descriptive'  # ÙˆØµÙÙŠØ© Ø¬ØºØ±Ø§ÙÙŠØ©,
    elif name.endswith(('Ø³ØªØ§Ù†', 'Ø§Ø¨Ø§Ø¯')):
    return 'persian_influence'  # ØªØ£Ø«ÙŠØ± ÙØ§Ø±Ø³ÙŠ,
    elif re.search(r'(Ø§Ù†|ÙŠÙ†|ÙŠØ©)$', name):
    return 'nisba_form'  # ØµÙŠØºØ© Ø§Ù„Ù†Ø³Ø¨,
    return None,
    def generate_by_meaning()
    self, meaning: str, category: ProperNameCategory, count: int = 10
    ) -> List[GeneratedName]:
    """ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø¨Ù…Ø¹Ù†Ù‰ Ù…Ø­Ø¯Ø¯"""

    logger.info(f"ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø¨Ù…Ø¹Ù†Ù‰ '{meaning' Ù…Ù†} ÙØ¦Ø© {category.value}}")

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ø°ÙˆØ± Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù…Ø¹Ù†Ù‰,
    relevant_roots = self._find_meaning_related_roots(meaning, category)

        if not relevant_roots:
    logger.warning(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ø°ÙˆØ± Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù…Ø¹Ù†Ù‰ '{meaning}")
    return self.generate_names(category, count, meaning)

        # ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø³ØªÙ‡Ø¯ÙØ©,
    targeted_names = []
    attempts = 0,
    max_attempts = count * 20,
    while len(targeted_names) < count and attempts < max_attempts:
    attempts += 1

            # Ø§Ø®ØªÙŠØ§Ø± Ø¬Ø°Ø± Ù…Ù†Ø§Ø³Ø¨,
    root = random.choice(relevant_roots)

            # ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø°Ø±,
    targeted_name = self._generate_name_from_root(root, category, meaning)

            if targeted_name and targeted_name.authenticity_score >= 0.5:
                # ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±,
    if not any(tn.name == targeted_name.name for tn in targeted_names):
    targeted_names.append(targeted_name)

    logger.info(f"ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(targeted_names)} Ø§Ø³Ù… Ø¨Ù…Ø¹Ù†Ù‰ '{meaning}")
    return targeted_names,
    def _find_meaning_related_roots()
    self, meaning: str, category: ProperNameCategory
    ) -> List[Dict]:
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ø°ÙˆØ± Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ù…Ø¹Ù†Ù‰"""

        # Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ Ù„Ù„Ø¬Ø°ÙˆØ±,
    meaning_map = {
    'Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©': ['Ø´Ø¬Ø¹', 'Ø¨Ø·Ù„', 'Ù‚ÙˆÙŠ', 'Ø¹Ø²'],
    'Ø§Ù„Ø­ÙƒÙ…Ø©': ['Ø­ÙƒÙ…', 'Ø¹Ù„Ù…', 'ÙÙ‡Ù…', 'Ø¹Ù‚Ù„'],
    'Ø§Ù„Ø¬Ù…Ø§Ù„': ['Ø¬Ù…Ù„', 'Ø­Ø³Ù†', 'Ø²ÙŠÙ†', 'Ø¨Ù‡ÙŠ'],
    'Ø§Ù„Ø±Ø­Ù…Ø©': ['Ø±Ø­Ù…', 'Ø±Ø£Ù', 'Ø­Ù†Ù†', 'Ø¹Ø·Ù'],
    'Ø§Ù„Ù‚ÙˆØ©': ['Ù‚ÙˆÙŠ', 'Ø¹Ø²', 'ØºÙ„Ø¨', 'Ù‚Ø¯Ø±'],
    'Ø§Ù„Ø³Ù„Ø§Ù…': ['Ø³Ù„Ù…', 'Ø£Ù…Ù†', 'Ø·Ù…Ù†', 'Ø³ÙƒÙ†'],
    'Ø§Ù„Ù†ÙˆØ±': ['Ù†ÙˆØ±', 'Ø¶ÙˆØ¡', 'Ø´Ø±Ù‚', 'Ø£Ø´Ø±Ù‚'],
    'Ø§Ù„Ù…Ø§Ø¡': ['Ù…Ùˆ', 'Ù†Ù‡Ø±', 'Ø¨Ø­Ø±', 'Ø¹ÙŠÙ†'],
    'Ø§Ù„Ø¬Ø¨Ù„': ['Ø¬Ø¨Ù„', 'Ø·ÙˆØ¯', 'Ø¹Ù„Ùˆ', 'Ø±ÙØ¹'],
    }

    relevant_roots = []

        # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø±,
    for concept, roots in meaning_map.items():
            if meaning in concept or concept in meaning:
                for root in roots:
    relevant_roots.append({'root': root, 'meaning': concept})

        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø°ÙˆØ±,
    if category == ProperNameCategory.PERSON_MALE:
            for root, info in self.onomastics.name_roots['male_roots'].items():
                if meaning in info['meaning'] or any()
    meaning in deriv for deriv in info['derivatives']
    ):
    relevant_roots.append({'root': root, 'meaning': info['meaning']})

        elif category == ProperNameCategory.PERSON_FEMALE:
            for root, info in self.onomastics.name_roots['female_roots'].items():
                if meaning in info['meaning'] or any()
    meaning in deriv for deriv in info['derivatives']
    ):
    relevant_roots.append({'root': root, 'meaning': info['meaning']})

    return relevant_roots,
    def _generate_name_from_root()
    self, root_info: Dict, category: ProperNameCategory, meaning: str
    ) -> Optional[GeneratedName]:
    """ØªÙˆÙ„ÙŠØ¯ Ø§Ø³Ù… Ù…Ù† Ø¬Ø°Ø± Ù…Ø­Ø¯Ø¯"""

    root = root_info['root']

        # Ø§Ø®ØªÙŠØ§Ø± Ù‚Ø§Ù„Ø¨ Ù…Ù†Ø§Ø³Ø¨,
    templates = self.name_templates.get(category, [])
        if not templates:
    return None,
    template = random.choice(templates)

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù‚Ø§Ø·Ø¹ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø°Ø±,
    root_syllables = [
    syl,
    for syl in self.syllables_db,
    if root in syl.get('syllable', '')
    or any(root_char in syl.get('syllable', '') for root_char in root)
    ]

        if not root_syllables:
    return None

        # Ø¨Ù†Ø§Ø¡ Ø§Ø³Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬Ø°Ø±,
    chosen_root_syllable = random.choice(root_syllables)

        # Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø§Ø³Ù… Ø¨Ù…Ù‚Ø§Ø·Ø¹ Ù…ÙƒÙ…Ù„Ø©,
    remaining_structure = ()
    template.syllable_structure[1:]
            if len(template.syllable_structure) > 1,
    else []
    )

    name_syllables = [chosen_root_syllable['syllable']]

        for syllable_pattern in remaining_structure:
    suitable_syllables = self._filter_suitable_syllables()
    syllable_pattern,
    template,
    False,
    syllable_pattern == remaining_structure[ 1])

            if suitable_syllables:
    chosen_syllable = random.choice(suitable_syllables)
    name_syllables.append(chosen_syllable['syllable'])

        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³Ù…,
    candidate_name = ''.join(name_syllables)

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª,
    candidate_name = self._apply_cultural_modifications(candidate_name, template)
    candidate_name = self._apply_phonetic_rules(candidate_name, template)

        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³Ù…,
    return self._evaluate_and_create_name(candidate_name, template, meaning)

    def generate_comprehensive_analysis()
    self) -> Dict[ProperNameCategory, List[GeneratedName]]:
    """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ ÙØ¦Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡"""

    results = {}

    categories_to_analyze = [
    ProperNameCategory.PERSON_MALE,
    ProperNameCategory.PERSON_FEMALE,
    ProperNameCategory.PLACE_CITY,
    ProperNameCategory.PLACE_COUNTRY,
    ProperNameCategory.PLACE_NATURAL,
    ]

        for category in categories_to_analyze:
    logger.info(f"ØªØ­Ù„ÙŠÙ„ ÙØ¦Ø© {category.value...}")
    category_results = self.generate_names(category, count=15)
    results[category] = category_results,
    return results,
    def print_comprehensive_report()
    self, results: Dict[ProperNameCategory, List[GeneratedName]]
    ):
    """Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ù„Ù„Ù†ØªØ§Ø¦Ø¬"""

    print("\n" + "â•" * 80)
    print("ğŸ¯ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    print("â•" * 80)

    total_generated = sum(len(names) for names in results.values())
    total_authentic = sum()
    len([n for n in names if n.authenticity_score > 0.7])
            for names in results.values()
    )

    print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©:")
    print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©: {total_generated}")
    print(f"   â€¢ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©: {total_authentic}")
    print(f"   â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¬ÙˆØ¯Ø©: {total_authentic/total_generated*100:.1f}%")

        for category, names in results.items():
            if not names:
    continue,
    print(f"\nâ–¶ {category.value.upper().replace('_',} ' ')} ({len(names) Ø§Ø³Ù…):}")
    print(" " * 60)

            # ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ø¬ÙˆØ¯Ø©,
    high_quality = [n for n in names if n.authenticity_score > 0.7]
    medium_quality = [n for n in names if 0.5 <= n.authenticity_score <= 0.7]

    print(f"   ğŸ¥‡ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø©: {len(high_quality)}")
    print(f"   ğŸ¥ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¬ÙˆØ¯Ø©: {len(medium_quality)}")

            # Ø£ÙØ¶Ù„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡,
    top_names = sorted(names, key=lambda x: x.authenticity_score, reverse=True)[
    :8
    ]

    print("\n   ğŸŒŸ Ø£ÙØ¶Ù„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©:")
            for i, name in enumerate(top_names, 1):
    quality_indicator = ()
    "ğŸ¥‡"
                    if name.authenticity_score > 0.7,
    else "ğŸ¥ˆ" if name.authenticity_score > 0.5 else "ğŸ¥‰"
    )

    print()
    f"      {i}. {name.name:12} {quality_indicator} Ø¬ÙˆØ¯Ø©: {name.authenticity_score:.2f}"
    )
    print(f"         ğŸ“ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: {'} + '.join(name.syllables)}")
    print(f"         ğŸ”¤ Ø§Ù„Ù†Ù…Ø·: {name.pattern.value}")
    print(f"         ğŸ’­ Ø§Ù„Ù…Ø¹Ù†Ù‰: {name.semantic_meaning}")

                if name.historical_template:
    print(f"         ğŸ›ï¸  Ø§Ù„Ù‚Ø§Ù„Ø¨: {name.historical_template}")

                if name.examples:
    print(f"         ğŸ¯ Ø£Ø³Ù…Ø§Ø¡ Ù…Ø´Ø§Ø¨Ù‡Ø©: {', '.join(name.examples[:3])}")

    print()

    print("â•" * 80)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEMO AND TESTING FUNCTIONS - ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def demo_proper_names_generation():
    """Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ø´Ø§Ù…Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ø§Ù…"""

    print("ğŸš€ Ù…ÙˆÙ„Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    print("Advanced Arabic Proper Names Generator")
    print("=" * 70)

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆÙ„Ø¯,
    generator = AdvancedArabicProperNamesGenerator()

    # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„,
    results = generator.generate_comprehensive_analysis()

    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„,
    generator.print_comprehensive_report(results)

    # Ø¹Ø±Ø¶ Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù…Ø¹Ø§Ù†ÙŠ Ù…Ø­Ø¯Ø¯Ø©,
    print("\n" + "â•" * 70)
    print("ğŸ¯ Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù…Ø¹Ø§Ù†ÙŠ Ù…Ø­Ø¯Ø¯Ø©")
    print("â•" * 70)

    specific_meanings = [
    ('Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©', ProperNameCategory.PERSON_MALE),
    ('Ø§Ù„Ø¬Ù…Ø§Ù„', ProperNameCategory.PERSON_FEMALE),
    ('Ø§Ù„Ù…Ø§Ø¡', ProperNameCategory.PLACE_NATURAL),
    ]

    for meaning, category in specific_meanings:
    print(f"\nğŸ” ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø¨Ù…Ø¹Ù†Ù‰ '{meaning}' - ÙØ¦Ø© {category.value}:")

    targeted_names = generator.generate_by_meaning(meaning, category, 5)

        for i, name in enumerate(targeted_names, 1):
    print(f"   {i}. {name.name} - Ø¬ÙˆØ¯Ø©: {name.authenticity_score:.2f}")
    print(f"      Ù…Ø¹Ù†Ù‰: {name.semantic_meaning}")

    return generator, results,
    if __name__ == "__main__":
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ,
    demo_proper_names_generation()

