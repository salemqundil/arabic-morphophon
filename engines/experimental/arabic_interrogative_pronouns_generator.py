#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Arabic Interrogative Pronouns Generation System
==============================================
Ù†Ø¸Ø§Ù… ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ©,
    Advanced system for generating Arabic interrogative pronouns (question words)

Author: Arabic NLP Expert Team - GitHub Copilot,
    Version: 1.0.0 - INTERROGATIVE PRONOUNS GENERATOR,
    Date: 2025-07-24,
    Encoding: UTF 8
"""
# pylint: disable=broad-except,unused-variable,too-many-arguments
# pylint: disable=too-few-public-methods,invalid-name,unused-argument
# flake8: noqa: E501,F401,F821,A001,F403
# mypy: disable-error-code=no-untyped-def,misc
    import logging  # noqa: F401
    import json  # noqa: F401
    import yaml  # noqa: F401
    import numpy as np  # noqa: F401
    from datetime import datetime  # noqa: F401
    from typing import Dict, List, Any, Optional, Tuple
    from dataclasses import dataclass, asdict  # noqa: F401
    from enum import Enum  # noqa: F401
    from pathlib import Path  # noqa: F401
    import re  # noqa: F401

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª,
    logging.basicConfig(
    level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTERROGATIVE PRONOUNS CATEGORIES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class InterrogativeCategory(Enum):
    """ÙØ¦Ø§Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…"""

    PERSON = "Ø´Ø®Øµ"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø£Ø´Ø®Ø§Øµ,
    THING = "Ø´ÙŠØ¡"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø£Ø´ÙŠØ§Ø¡,
    TIME = "Ø²Ù…Ø§Ù†"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø²Ù…Ù†,
    PLACE = "Ù…ÙƒØ§Ù†"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ù…ÙƒØ§Ù†,
    MANNER = "ÙƒÙŠÙÙŠØ©"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©,
    QUANTITY = "ÙƒÙ…ÙŠØ©"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„ÙƒÙ…ÙŠØ©,
    CHOICE = "Ø§Ø®ØªÙŠØ§Ø±"  # Ù„Ù„Ø§Ø®ØªÙŠØ§Ø±,
    REASON = "Ø³Ø¨Ø¨"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø³Ø¨Ø¨,
    STATE = "Ø­Ø§Ù„"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø­Ø§Ù„,
    POSSESSION = "Ù…Ù„ÙƒÙŠØ©"  # Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ù…Ù„ÙƒÙŠØ©


@dataclass,
    class InterrogativePronoun:
    """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø³Ù… Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…"""

    text: str,
    category: InterrogativeCategory,
    syllables: List[str]
    phonemes: List[str]
    frequency_score: float,
    usage_contexts: List[str]
    grammatical_cases: List[str]
    semantic_features: Dict[str, Any]

    def to_dict(self) -> Dict[str, Any]:
    """ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³"""
    return {
    'text': self.text,
    'category': self.category.value,
    'syllables': self.syllables,
    'phonemes': self.phonemes,
    'frequency_score': self.frequency_score,
    'usage_contexts': self.usage_contexts,
    'grammatical_cases': self.grammatical_cases,
    'semantic_features': self.semantic_features,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTERROGATIVE PRONOUNS DATABASE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class InterrogativePronounsDatabase:
    """Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""

    def __init__(self):  # type: ignore[no-untyped def]
    """TODO: Add docstring."""
    self.interrogative_pronouns: List[InterrogativePronoun] = []
    self.syllable_patterns: Dict[str, List[str]] = {}
    self.phoneme_patterns: Dict[str, List[str]] = {}
    self._initialize_database()

    def _initialize_database(self):  # type: ignore[no-untyped def]
    """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…"""

    interrogatives_data = [
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ù† Ø§Ù„Ø£Ø´Ø®Ø§Øµ
    {
    'text': 'Ù…ÙÙ†',
    'category': InterrogativeCategory.PERSON,
    'syllables': ['Ù…ÙÙ†Ù’'],
    'phonemes': ['Ù…', 'Ù', 'Ù†', 'Ù’'],
    'frequency_score': 0.95,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø£Ø´Ø®Ø§Øµ', 'Ø§Ù„Ù‡ÙˆÙŠØ©', 'Ø§Ù„ÙØ§Ø¹Ù„'],
    'grammatical_cases': ['Ù…Ø±ÙÙˆØ¹', 'Ù…Ù†ØµÙˆØ¨', 'Ù…Ø¬Ø±ÙˆØ±'],
    'semantic_features': {
    'animacy': 'Ø­ÙŠ',
    'specificity': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
    'formality': 'ÙØµÙŠØ­',
    },
    },
    {
    'text': 'Ù…ÙÙ†Ù’ Ø°ÙØ§',
    'category': InterrogativeCategory.PERSON,
    'syllables': ['Ù…ÙÙ†Ù’', 'Ø°ÙØ§'],
    'phonemes': ['Ù…', 'Ù', 'Ù†', 'Ù’', 'Ø°', 'Ù', 'Ø§'],
    'frequency_score': 0.65,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø£Ø´Ø®Ø§Øµ Ø¨ØªØ£ÙƒÙŠØ¯', 'Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø§Ù„Ù…Ø¤ÙƒØ¯'],
    'grammatical_cases': ['Ù…Ø±ÙÙˆØ¹', 'Ù…Ù†ØµÙˆØ¨'],
    'semantic_features': {
    'animacy': 'Ø­ÙŠ',
    'specificity': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
    'emphasis': 'Ù…Ø¤ÙƒØ¯',
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ù† Ø§Ù„Ø£Ø´ÙŠØ§Ø¡
    {
    'text': 'Ù…ÙØ§',
    'category': InterrogativeCategory.THING,
    'syllables': ['Ù…ÙØ§'],
    'phonemes': ['Ù…', 'Ù', 'Ø§'],
    'frequency_score': 0.98,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø£Ø´ÙŠØ§Ø¡', 'Ø§Ù„Ù…ÙØ¹ÙˆÙ„', 'Ø§Ù„ØªØ¹Ø±ÙŠÙ'],
    'grammatical_cases': ['Ù…Ø±ÙÙˆØ¹', 'Ù…Ù†ØµÙˆØ¨', 'Ù…Ø¬Ø±ÙˆØ±'],
    'semantic_features': {
    'animacy': 'ØºÙŠØ± Ø­ÙŠ',
    'specificity': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
    'scope': 'ÙˆØ§Ø³Ø¹',
    },
    },
    {
    'text': 'Ù…ÙØ§Ø°ÙØ§',
    'category': InterrogativeCategory.THING,
    'syllables': ['Ù…ÙØ§', 'Ø°ÙØ§'],
    'phonemes': ['Ù…', 'Ù', 'Ø§', 'Ø°', 'Ù', 'Ø§'],
    'frequency_score': 0.85,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø£Ø´ÙŠØ§Ø¡', 'Ø§Ù„Ù…ÙØ¹ÙˆÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±'],
    'grammatical_cases': ['Ù…Ù†ØµÙˆØ¨'],
    'semantic_features': {
    'animacy': 'ØºÙŠØ± Ø­ÙŠ',
    'specificity': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
    'directness': 'Ù…Ø¨Ø§Ø´Ø±',
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ù† Ø§Ù„Ø²Ù…Ø§Ù†
    {
    'text': 'Ù…ÙØªÙÙ‰',
    'category': InterrogativeCategory.TIME,
    'syllables': ['Ù…Ù', 'ØªÙÙ‰'],
    'phonemes': ['Ù…', 'Ù', 'Øª', 'Ù', 'Ù‰'],
    'frequency_score': 0.92,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø²Ù…Ù†', 'Ø§Ù„ØªÙˆÙ‚ÙŠØª', 'Ø§Ù„Ø£Ø­Ø¯Ø§Ø«'],
    'grammatical_cases': ['Ø¸Ø±Ù Ø²Ù…Ø§Ù†'],
    'semantic_features': {
    'temporal': True,
    'specificity': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
    'tense': 'Ù…ÙØªÙˆØ­',
    },
    },
    {
    'text': 'Ø£ÙÙŠÙÙ‘Ø§Ù†Ù',
    'category': InterrogativeCategory.TIME,
    'syllables': ['Ø£ÙÙŠÙ’', 'ÙŠÙØ§', 'Ù†Ù'],
    'phonemes': ['Ø£', 'Ù', 'ÙŠ', 'Ù’', 'ÙŠ', 'Ù', 'Ø§', 'Ù†', 'Ù'],
    'frequency_score': 0.45,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø²Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ', 'Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ù‡Ù…Ø©'],
    'grammatical_cases': ['Ø¸Ø±Ù Ø²Ù…Ø§Ù†'],
    'semantic_features': {
    'temporal': True,
    'formality': 'ÙØµÙŠØ­ Ø¬Ø¯Ø§Ù‹',
    'future_oriented': True,
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ù† Ø§Ù„Ù…ÙƒØ§Ù†
    {
    'text': 'Ø£ÙÙŠÙ’Ù†Ù',
    'category': InterrogativeCategory.PLACE,
    'syllables': ['Ø£ÙÙŠÙ’', 'Ù†Ù'],
    'phonemes': ['Ø£', 'Ù', 'ÙŠ', 'Ù’', 'Ù†', 'Ù'],
    'frequency_score': 0.94,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ù…ÙƒØ§Ù†', 'Ø§Ù„Ù…ÙˆÙ‚Ø¹', 'Ø§Ù„Ø¬Ù‡Ø©'],
    'grammatical_cases': ['Ø¸Ø±Ù Ù…ÙƒØ§Ù†'],
    'semantic_features': {
    'spatial': True,
    'specificity': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
    'dimensionality': 'Ù…ÙƒØ§Ù†ÙŠ',
    },
    },
    {
    'text': 'Ø£ÙÙ†ÙÙ‘Ù‰',
    'category': InterrogativeCategory.PLACE,
    'syllables': ['Ø£ÙÙ†Ù’', 'Ù†ÙÙ‰'],
    'phonemes': ['Ø£', 'Ù', 'Ù†', 'Ù’', 'Ù†', 'Ù', 'Ù‰'],
    'frequency_score': 0.55,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ù…ÙƒØ§Ù† ÙˆØ§Ù„Ø·Ø±ÙŠÙ‚Ø©', 'Ø§Ù„ÙƒÙŠÙÙŠØ© Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ©'],
    'grammatical_cases': ['Ø¸Ø±Ù Ù…ÙƒØ§Ù†', 'Ø¸Ø±Ù Ø­Ø§Ù„'],
    'semantic_features': {
    'spatial': True,
    'manner': True,
    'complexity': 'Ù…Ø±ÙƒØ¨',
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ù† Ø§Ù„ÙƒÙŠÙÙŠØ©
    {
    'text': 'ÙƒÙÙŠÙ’ÙÙ',
    'category': InterrogativeCategory.MANNER,
    'syllables': ['ÙƒÙÙŠÙ’', 'ÙÙ'],
    'phonemes': ['Ùƒ', 'Ù', 'ÙŠ', 'Ù’', 'Ù', 'Ù'],
    'frequency_score': 0.96,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©', 'Ø§Ù„Ø­Ø§Ù„', 'Ø§Ù„ÙƒÙŠÙÙŠØ©'],
    'grammatical_cases': ['Ø¸Ø±Ù Ø­Ø§Ù„'],
    'semantic_features': {'manner': True, 'state': True, 'method': True},
    },
    {
    'text': 'ÙƒÙÙŠÙ’ÙÙÙ…ÙØ§',
    'category': InterrogativeCategory.MANNER,
    'syllables': ['ÙƒÙÙŠÙ’', 'ÙÙ', 'Ù…ÙØ§'],
    'phonemes': ['Ùƒ', 'Ù', 'ÙŠ', 'Ù’', 'Ù', 'Ù', 'Ù…', 'Ù', 'Ø§'],
    'frequency_score': 0.35,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø£ÙŠ Ø·Ø±ÙŠÙ‚Ø©', 'Ø§Ù„Ø´Ù…ÙˆÙ„ÙŠØ©'],
    'grammatical_cases': ['Ø¸Ø±Ù Ø­Ø§Ù„'],
    'semantic_features': {
    'manner': True,
    'universality': 'Ø´Ø§Ù…Ù„',
    'indefiniteness': 'Ù…Ø·Ù„Ù‚',
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ù† Ø§Ù„ÙƒÙ…ÙŠØ©
    {
    'text': 'ÙƒÙÙ…Ù’',
    'category': InterrogativeCategory.QUANTITY,
    'syllables': ['ÙƒÙÙ…Ù’'],
    'phonemes': ['Ùƒ', 'Ù', 'Ù…', 'Ù’'],
    'frequency_score': 0.89,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø¹Ø¯Ø¯', 'Ø§Ù„ÙƒÙ…ÙŠØ©', 'Ø§Ù„Ù…Ù‚Ø¯Ø§Ø±'],
    'grammatical_cases': ['Ù…Ø¨Ù†ÙŠ'],
    'semantic_features': {
    'quantitative': True,
    'numerical': True,
    'measure': True,
    },
    },
    {
    'text': 'ÙƒÙØ£ÙÙŠÙÙ‘Ù†Ù’',
    'category': InterrogativeCategory.QUANTITY,
    'syllables': ['ÙƒÙØ£ÙÙŠÙ’', 'ÙŠÙÙ†Ù’'],
    'phonemes': ['Ùƒ', 'Ù', 'Ø£', 'Ù', 'ÙŠ', 'Ù’', 'ÙŠ', 'Ù', 'Ù†', 'Ù’'],
    'frequency_score': 0.25,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙƒØ«ÙŠØ±', 'Ø§Ù„ØªØ¹Ø¬Ø¨ Ù…Ù† Ø§Ù„ÙƒØ«Ø±Ø©'],
    'grammatical_cases': ['Ù…Ø¨Ù†ÙŠ'],
    'semantic_features': {
    'quantitative': True,
    'abundance': True,
    'exclamatory': True,
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ù„Ù„Ø§Ø®ØªÙŠØ§Ø±
    {
    'text': 'Ø£ÙÙŠÙ‘',
    'category': InterrogativeCategory.CHOICE,
    'syllables': ['Ø£ÙÙŠÙ‘'],
    'phonemes': ['Ø£', 'Ù', 'ÙŠ', 'Ù‘'],
    'frequency_score': 0.88,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ¯', 'Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±', 'Ø§Ù„ØªÙ…ÙŠÙŠØ²'],
    'grammatical_cases': ['Ù…Ø¹Ø±Ø¨'],
    'semantic_features': {
    'selective': True,
    'determinative': True,
    'variable': 'Ù…ØªØºÙŠØ±',
    },
    },
    {
    'text': 'Ø£ÙÙŠÙÙ‘Ù‡ÙØ§',
    'category': InterrogativeCategory.CHOICE,
    'syllables': ['Ø£ÙÙŠÙ’', 'ÙŠÙ', 'Ù‡ÙØ§'],
    'phonemes': ['Ø£', 'Ù', 'ÙŠ', 'Ù’', 'ÙŠ', 'Ù', 'Ù‡', 'Ù', 'Ø§'],
    'frequency_score': 0.65,
    'usage_contexts': ['Ø§Ù„Ù†Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…ÙŠ', 'Ø§Ù„ØªØ¹ÙŠÙŠÙ†'],
    'grammatical_cases': ['Ù…Ù†Ø§Ø¯Ù‰'],
    'semantic_features': {
    'selective': True,
    'vocative': True,
    'formal': 'Ø±Ø³Ù…ÙŠ',
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ù† Ø§Ù„Ø³Ø¨Ø¨
    {
    'text': 'Ù„ÙÙ…ÙØ§Ø°ÙØ§',
    'category': InterrogativeCategory.REASON,
    'syllables': ['Ù„Ù', 'Ù…ÙØ§', 'Ø°ÙØ§'],
    'phonemes': ['Ù„', 'Ù', 'Ù…', 'Ù', 'Ø§', 'Ø°', 'Ù', 'Ø§'],
    'frequency_score': 0.93,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø³Ø¨Ø¨', 'Ø§Ù„Ø¹Ù„Ø©', 'Ø§Ù„ØºØ±Ø¶'],
    'grammatical_cases': ['Ø¬Ø§Ø± ÙˆÙ…Ø¬Ø±ÙˆØ±'],
    'semantic_features': {
    'causal': True,
    'explanatory': True,
    'purpose': 'ØºØ±Ø¶ÙŠ',
    },
    },
    {
    'text': 'Ù„ÙÙ…Ù',
    'category': InterrogativeCategory.REASON,
    'syllables': ['Ù„ÙÙ…Ù'],
    'phonemes': ['Ù„', 'Ù', 'Ù…', 'Ù'],
    'frequency_score': 0.75,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ù…Ø®ØªØµØ±', 'Ø§Ù„Ø¹Ù„Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©'],
    'grammatical_cases': ['Ø¬Ø§Ø± ÙˆÙ…Ø¬Ø±ÙˆØ±'],
    'semantic_features': {
    'causal': True,
    'concise': True,
    'direct': 'Ù…Ø¨Ø§Ø´Ø±',
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ù† Ø§Ù„Ø­Ø§Ù„
    {
    'text': 'ÙƒÙÙŠÙ’ÙÙÙ…ÙØ§',
    'category': InterrogativeCategory.STATE,
    'syllables': ['ÙƒÙÙŠÙ’', 'ÙÙ', 'Ù…ÙØ§'],
    'phonemes': ['Ùƒ', 'Ù', 'ÙŠ', 'Ù’', 'Ù', 'Ù', 'Ù…', 'Ù', 'Ø§'],
    'frequency_score': 0.40,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø£ÙŠ Ø­Ø§Ù„', 'Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©'],
    'grammatical_cases': ['Ø¸Ø±Ù Ø­Ø§Ù„'],
    'semantic_features': {
    'state': True,
    'condition': True,
    'general': 'Ø¹Ø§Ù…',
    },
    },
            # Ø£Ø³Ù…Ø§Ø¡ Ø§Ø³ØªÙÙ‡Ø§Ù… Ù…Ø±ÙƒØ¨Ø© ÙˆÙ…ØªØ®ØµØµØ©
    {
    'text': 'Ø£ÙÙŠÙ’Ù†ÙÙ…ÙØ§',
    'category': InterrogativeCategory.PLACE,
    'syllables': ['Ø£ÙÙŠÙ’', 'Ù†Ù', 'Ù…ÙØ§'],
    'phonemes': ['Ø£', 'Ù', 'ÙŠ', 'Ù’', 'Ù†', 'Ù', 'Ù…', 'Ù', 'Ø§'],
    'frequency_score': 0.45,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø£ÙŠ Ù…ÙƒØ§Ù†', 'Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø¹Ø§Ù…'],
    'grammatical_cases': ['Ø¸Ø±Ù Ù…ÙƒØ§Ù†'],
    'semantic_features': {
    'spatial': True,
    'universal': 'Ø´Ø§Ù…Ù„',
    'indefinite': 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯',
    },
    },
    {
    'text': 'Ù…ÙÙ‡Ù’Ù…ÙØ§',
    'category': InterrogativeCategory.THING,
    'syllables': ['Ù…ÙÙ‡Ù’', 'Ù…ÙØ§'],
    'phonemes': ['Ù…', 'Ù', 'Ù‡', 'Ù’', 'Ù…', 'Ù', 'Ø§'],
    'frequency_score': 0.70,
    'usage_contexts': ['Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡', 'Ø§Ù„Ø´Ù…ÙˆÙ„ÙŠØ©'],
    'grammatical_cases': ['Ø´Ø±Ø·ÙŠØ©'],
    'semantic_features': {
    'conditional': True,
    'universal': 'Ø´Ø§Ù…Ù„',
    'indefinite': 'Ù…Ø·Ù„Ù‚',
    },
    },
    ]

        # Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù†Ø§Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…,
    for data in interrogatives_data:
    pronoun = InterrogativePronoun(
    text=data['text'],
    category=data['category'],
    syllables=data['syllables'],
    phonemes=data['phonemes'],
    frequency_score=data['frequency_score'],
    usage_contexts=data['usage_contexts'],
    grammatical_cases=data['grammatical_cases'],
    semantic_features=data['semantic_features'],
    )
    self.interrogative_pronouns.append(pronoun)

        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù‚Ø·Ø¹ÙŠØ©,
    self._build_syllable_patterns()
    self._build_phoneme_patterns()

    logger.info(
    f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…: {len(self.interrogative_pronouns)} Ø§Ø³Ù… Ø§Ø³ØªÙÙ‡Ø§Ù…"
    )  # noqa: E501,
    def _build_syllable_patterns(self):  # type: ignore[no-untyped def]
    """Ø¨Ù†Ø§Ø¡ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""

        for pronoun in self.interrogative_pronouns:
    pattern = " ".join(pronoun.syllables)

            if pattern not in self.syllable_patterns:
    self.syllable_patterns[pattern] = []

    self.syllable_patterns[pattern].append(pronoun.text)

    logger.info(f"ğŸ“Š Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù‚Ø·Ø¹ÙŠØ©: {len(self.syllable_patterns)} Ù†Ù…Ø·")

    def _build_phoneme_patterns(self):  # type: ignore[no-untyped def]
    """Ø¨Ù†Ø§Ø¡ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØµÙˆØªÙŠØ§Øª"""

        for pronoun in self.interrogative_pronouns:
    pattern = " ".join(pronoun.phonemes)

            if pattern not in self.phoneme_patterns:
    self.phoneme_patterns[pattern] = []

    self.phoneme_patterns[pattern].append(pronoun.text)

    def find_by_syllables(self, syllables: List[str]) -> List[InterrogativePronoun]:
    """Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""

    results = []
    search_pattern = " ".join(syllables)

        for pronoun in self.interrogative_pronouns:
    pronoun_pattern = " ".join(pronoun.syllables)

            # Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø©,
    if pronoun_pattern == search_pattern:
    results.append(pronoun)
            # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¬Ø²Ø¦ÙŠØ©,
    elif search_pattern in pronoun_pattern or pronoun_pattern in search_pattern:
    results.append(pronoun)

    return results,
    def find_by_category(
    self, category: InterrogativeCategory
    ) -> List[InterrogativePronoun]:
    """Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙØ¦Ø©"""

    return [p for p in self.interrogative_pronouns if p.category == category]

    def get_high_frequency_pronouns(
    self, threshold: float = 0.8
    ) -> List[InterrogativePronoun]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ø§Ù„ÙŠØ© Ø§Ù„ØªÙƒØ±Ø§Ø±"""

    return [
    p for p in self.interrogative_pronouns if p.frequency_score >= threshold
    ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYLLABLE ANALYZER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class InterrogativeSyllableAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…"""

    def __init__(self, database: InterrogativePronounsDatabase):  # type: ignore[no-untyped def]
    """TODO: Add docstring."""
    self.database = database,
    self.syllable_weights = self._calculate_syllable_weights()

    def _calculate_syllable_weights(self) -> Dict[str, float]:
    """Ø­Ø³Ø§Ø¨ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø­Ø³Ø¨ Ø§Ù„Ø´ÙŠÙˆØ¹"""

    syllable_counts = {}
    len(self.database.interrogative_pronouns)

        for pronoun in self.database.interrogative_pronouns:
            for syllable in pronoun.syllables:
    syllable_counts[syllable] = (
    syllable_counts.get(syllable, 0) + pronoun.frequency_score
    )

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø£ÙˆØ²Ø§Ù†,
    weights = {}
    max_count = max(syllable_counts.values()) if syllable_counts else 1,
    for syllable, count in syllable_counts.items():
    weights[syllable] = count / max_count,
    return weights,
    def analyze_syllable_pattern(self, syllables: List[str]) -> Dict[str, Any]:
    """ØªØ­Ù„ÙŠÙ„ Ù†Ù…Ø· Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""

    analysis = {
    'syllable_count': len(syllables),
    'pattern_complexity': self._calculate_pattern_complexity(syllables),
    'similarity_scores': {},
    'weighted_score': self._calculate_weighted_score(syllables),
    'phonetic_features': self._extract_phonetic_features(syllables),
    }

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©,
    for pronoun in self.database.interrogative_pronouns:
    similarity = self._calculate_similarity(syllables, pronoun.syllables)
    analysis['similarity_scores'][pronoun.text] = similarity,
    return analysis,
    def _calculate_pattern_complexity(self, syllables: List[str]) -> float:
    """Ø­Ø³Ø§Ø¨ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù†Ù…Ø·"""

    complexity = 0.0

        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹,
    complexity += len(syllables) * 0.2

        # Ø·ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹,
    total_length = sum(len(syll) for syll in syllables)
    complexity += total_length * 0.1

        # ØªÙ†ÙˆØ¹ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹,
    unique_syllables = len(set(syllables))
        if len(syllables) > 0:
    complexity += (unique_syllables / len(syllables)) * 0.3,
    return complexity,
    def _calculate_weighted_score(self, syllables: List[str]) -> float:
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø±Ø¬Ø­Ø©"""

    total_weight = 0.0,
    for syllable in syllables:
    weight = self.syllable_weights.get(syllable, 0.1)
    total_weight += weight,
    return total_weight / len(syllables) if syllables else 0.0,
    def _extract_phonetic_features(self, syllables: List[str]) -> Dict[str, Any]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØªÙŠØ©"""

    features = {
    'vowel_count': 0,
    'consonant_count': 0,
    'long_vowels': 0,
    'short_vowels': 0,
    'common_patterns': [],
    }

    vowels = ['Ù', 'Ù', 'Ù', 'Ø§', 'Ùˆ', 'ÙŠ', 'Ù‰']
    long_vowels = ['Ø§', 'Ùˆ', 'ÙŠ', 'Ù‰']

        for syllable in syllables:
            for char in syllable:
                if char in vowels:
    features['vowel_count'] += 1,
    if char in long_vowels:
    features['long_vowels'] += 1,
    else:
    features['short_vowels'] += 1,
    else:
    features['consonant_count'] += 1

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©,
    common_interrogative_patterns = ['Ù…Ù', 'Ø£Ù', 'ÙƒÙ', 'Ù„Ù']
        for pattern in common_interrogative_patterns:
            if any(pattern in syll for syll in syllables):
    features['common_patterns'].append(pattern)

    return features,
    def _calculate_similarity(
    self, syllables1: List[str], syllables2: List[str]
    ) -> float:
    """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ† Ù…Ø¬Ù…ÙˆØ¹ØªÙŠ Ù…Ù‚Ø§Ø·Ø¹"""

        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©,
    set1 = set(syllables1)
    set2 = set(syllables2)

        # Ù…Ø¹Ø§Ù…Ù„ Jaccard,
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))

    jaccard = intersection / union if union > 0 else 0.0

        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹,
    sequence_bonus = 0.0,
    min_len = min(len(syllables1), len(syllables2))

        for i in range(min_len):
            if syllables1[i] == syllables2[i]:
    sequence_bonus += 0.1,
    return min(jaccard + sequence_bonus, 1.0)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN GENERATOR CLASS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ArabicInterrogativePronounsGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ©"""

    def __init__(self, config_path: Optional[str] = None):  # type: ignore[no-untyped def]
    """TODO: Add docstring."""
    self.config = self._load_config(config_path)
    self.interrogative_pronouns_db = InterrogativePronounsDatabase()
    self.syllable_analyzer = InterrogativeSyllableAnalyzer(
    self.interrogative_pronouns_db
    )

    logger.info("ğŸš€ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…ÙˆÙ„Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ©")

    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
    """ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""

        default_config = {
    'similarity_threshold': 0.6,
    'max_results': 5,
    'enable_phonetic_matching': True,
    'enable_fuzzy_matching': True,
    'frequency_weight': 0.3,
    'pattern_weight': 0.4,
    'similarity_weight': 0.3,
    }

        if config_path and Path(config_path).exists():
            with open(config_path, 'r', encoding='utf 8') as f:
    user_config = yaml.safe_load(f)
                default_config.update(user_config)

    return default_config,
    def generate_interrogative_pronouns_from_syllables(
    self, syllables: List[str]
    ) -> Dict[str, Any]:
    """ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""

    logger.info(f"ğŸ” Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹: {syllables}")

    result = {
    'input_syllables': syllables,
    'success': False,
    'candidates': [],
    'best_match': None,
    'analysis': {},
    'timestamp': datetime.now().isoformat(),
    }

        try:
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹,
    analysis = self.syllable_analyzer.analyze_syllable_pattern(syllables)
    result['analysis'] = analysis

            # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø¨Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹,
    direct_matches = self.interrogative_pronouns_db.find_by_syllables(syllables)

    candidates = []

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©,
    for match in direct_matches:
    confidence = 1.0  # Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø©,
    candidates.append(
    {
    'interrogative_pronoun': match.text,
    'category': match.category.value,
    'confidence': confidence,
    'match_type': 'direct',
    'frequency_score': match.frequency_score,
    'usage_contexts': match.usage_contexts,
    }
    )

            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ØªØ´Ø§Ø¨Ù‡,
    if len(candidates) == 0 or self.config['enable_fuzzy_matching']:
    similarity_matches = self._find_by_similarity(syllables, analysis)
    candidates.extend(similarity_matches)

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ†,
    candidates = self._rank_candidates(candidates, analysis)

    result['candidates'] = candidates,
    if candidates:
    result['success'] = True,
    result['best_match'] = candidates[0]

    logger.info(
    f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(candidates)} Ù…Ø±Ø´Ø­. Ø£ÙØ¶Ù„ Ù…Ø·Ø§Ø¨Ù‚Ø©: {candidates[0]['interrogative_pronoun']}"
    )
            else:
    logger.warning(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹: {syllables}")

        except Exception as e:
    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: {e}")
    result['error'] = str(e)

    return result,
    def _find_by_similarity(
    self, syllables: List[str], analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
    """Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ØªØ´Ø§Ø¨Ù‡"""

    similarity_matches = []
    threshold = self.config['similarity_threshold']

        for pronoun in self.interrogative_pronouns_db.interrogative_pronouns:
    similarity = analysis['similarity_scores'].get(pronoun.text, 0.0)

            if similarity >= threshold:
    confidence = similarity * 0.8  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„ØªØ´Ø§Ø¨Ù‡ÙŠØ©,
    similarity_matches.append(
    {
    'interrogative_pronoun': pronoun.text,
    'category': pronoun.category.value,
    'confidence': confidence,
    'match_type': 'similarity',
    'similarity_score': similarity,
    'frequency_score': pronoun.frequency_score,
    'usage_contexts': pronoun.usage_contexts,
    }
    )

    return similarity_matches,
    def _rank_candidates(
    self, candidates: List[Dict[str, Any]], analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
    """ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø­Ø³Ø¨ Ø§Ù„Ø¬ÙˆØ¯Ø©"""

        def calculate_final_score(candidate):  # type: ignore[no-untyped def]
    """TODO: Add docstring."""
    confidence = candidate.get('confidence', 0.0)
    frequency = candidate.get('frequency_score', 0.0)

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©,
    final_score = (
    confidence * self.config['similarity_weight']
    + frequency * self.config['frequency_weight']
    + analysis['weighted_score'] * self.config['pattern_weight']
    )

            # Ø¥Ø¶Ø§ÙØ© Ø¨ÙˆÙ†Øµ Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©,
    if candidate.get('match_type') == 'direct':
    final_score += 0.2,
    candidate['final_score'] = final_score,
    return final_score

        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ†,
    sorted_candidates = sorted(candidates, key=calculate_final_score, reverse=True)

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨,
    max_results = self.config['max_results']
    return sorted_candidates[:max_results]

    def get_interrogative_by_category(
    self, category: InterrogativeCategory
    ) -> List[str]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©"""

    pronouns = self.interrogative_pronouns_db.find_by_category(category)
    return [p.text for p in pronouns]

    def get_system_statistics(self) -> Dict[str, Any]:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""

    stats = {
    'total_interrogative_pronouns': len(
    self.interrogative_pronouns_db.interrogative_pronouns
    ),
    'categories': {},
    'syllable_patterns': len(self.interrogative_pronouns_db.syllable_patterns),
    'phoneme_patterns': len(self.interrogative_pronouns_db.phoneme_patterns),
    'high_frequency_pronouns': len(
    self.interrogative_pronouns_db.get_high_frequency_pronouns()
    ),
    }

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØ¦Ø§Øª,
    for category in InterrogativeCategory:
    count = len(self.interrogative_pronouns_db.find_by_category(category))
    stats['categories'][category.value] = count,
    return stats,
    def save_database(self, output_path: str = "arabic_interrogative_pronouns_database.json"):  # type: ignore[no-untyped def]
    """Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""

    database_data = {
    'metadata': {
    'version': '1.0.0',
    'creation_date': datetime.now().isoformat(),
    'total_pronouns': len(
    self.interrogative_pronouns_db.interrogative_pronouns
    ),
    'categories': [cat.value for cat in InterrogativeCategory],
    },
    'interrogative_pronouns': [
    pronoun.to_dict()
                for pronoun in self.interrogative_pronouns_db.interrogative_pronouns
    ],
    'syllable_patterns': self.interrogative_pronouns_db.syllable_patterns,
    'phoneme_patterns': self.interrogative_pronouns_db.phoneme_patterns,
    }

        with open(output_path, 'w', encoding='utf 8') as f:
    json.dump(database_data, f, ensure_ascii=False, indent=2)

    logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… ÙÙŠ: {output_path}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def main():  # type: ignore[no-untyped def]
    """Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù†Ø¸Ø§Ù…"""

    print("ğŸ§  Ù…ÙˆÙ„Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ©")
    print("=" * 60)

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆÙ„Ø¯,
    generator = ArabicInterrogativePronounsGenerator()

    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…,
    stats = generator.get_system_statistics()
    print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:")
    print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…: {stats['total_interrogative_pronouns']}")
    print(f"   Ø§Ù„ÙØ¦Ø§Øª: {len(stats['categories'])}")
    print(f"   Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù‚Ø·Ø¹ÙŠØ©: {stats['syllable_patterns']}")
    print(f"   Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… Ø¹Ø§Ù„ÙŠØ© Ø§Ù„ØªÙƒØ±Ø§Ø±: {stats['high_frequency_pronouns']}")

    print("\nğŸ·ï¸ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª:")
    for category, count in stats['categories'].items():
    print(f"   {category}: {count} Ø§Ø³Ù… Ø§Ø³ØªÙÙ‡Ø§Ù…")

    # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯,
    test_cases = [
    ["Ù…ÙÙ†Ù’"],  # Ù…ÙÙ†
    ["Ù…ÙØ§"],  # Ù…Ø§
    ["Ù…Ù", "ØªÙÙ‰"],  # Ù…ØªÙ‰
    ["Ø£ÙÙŠÙ’", "Ù†Ù"],  # Ø£ÙŠÙ†
    ["ÙƒÙÙŠÙ’", "ÙÙ"],  # ÙƒÙŠÙ
    ["ÙƒÙÙ…Ù’"],  # ÙƒÙ…
    ["Ø£ÙÙŠÙ‘"],  # Ø£ÙŠ
    ["Ù„Ù", "Ù…ÙØ§", "Ø°ÙØ§"],  # Ù„Ù…Ø§Ø°Ø§
    ["Ø£ÙÙŠÙ’", "ÙŠÙØ§", "Ù†Ù"],  # Ø£ÙŠØ§Ù†
    ["Ù…ÙØ§", "Ø°ÙØ§"],  # Ù…Ø§Ø°Ø§
    ]

    print("\nğŸ”¬ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯:")
    for i, syllables in enumerate(test_cases, 1):
    print(f"\n   Ø§Ø®ØªØ¨Ø§Ø± {i}: {syllables}")

    result = generator.generate_interrogative_pronouns_from_syllables(syllables)

        if result['success']:
    best_match = result['best_match']
    print(f"   âœ… Ø£ÙØ¶Ù„ Ù…Ø·Ø§Ø¨Ù‚Ø©: {best_match['interrogative_pronoun']}")
    print(f"      Ø§Ù„ÙØ¦Ø©: {best_match['category']}")
    print(f"      Ø§Ù„Ø«Ù‚Ø©: {best_match['confidence']:.3f}")
    print(f"      Ø§Ù„Ù†ÙˆØ¹: {best_match['match_type']}")

            if len(result['candidates']) > 1:
    print("      Ø¨Ø¯Ø§Ø¦Ù„ Ø£Ø®Ø±Ù‰:")
                for j, candidate in enumerate(result['candidates'][1:3], 2):
    print(
    f"        {j}. {candidate['interrogative_pronoun']} ({candidate['confidence']:.3f})"
    )  # noqa: E501,
    else:
    print("   âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø·Ø§Ø¨Ù‚Ø§Øª")

    # Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª,
    generator.save_database()

    print("\nâœ… Ø§ÙƒØªÙ…Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­!")


if __name__ == "__main__":
    main()
