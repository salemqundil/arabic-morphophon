#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Complex Word Analysis Example
======================================
ูุซุงู ูุชูุฏู ูุชุญููู ุงููููุงุช ุงููุนูุฏุฉ ุจุงุณุชุฎุฏุงู ุงููุธุงู ุงูุดุงูู

ุชุญููู "ูุณุชูุชุจูููุง" ููุซุงู ุนูู ุงูุชูุงููู ุงููุนูุฏุฉ:
- ุงููุฒู ุงูุนุงุดุฑ (ุงุณุชูุนู)
- ุถููุฑ ุงูุฌูุน (ูู)
- ุถููุฑ ุงููุชุตู (ูุง)
- ุงูุชูุงุนู ุงูุตูุชู ุงููุนูุฏ

Author: GitHub Copilot Arabic NLP Expert
Version: 3.0.0 - COMPLEX WORD ANALYSIS
Date: 2025-07-26
Encoding: UTF 8
"""
# pylint: disable=broad-except,unused-variable,too-many-arguments
# pylint: disable=too-few-public-methods,invalid-name,unused-argument
# flake8: noqa: E501,F401,F821,A001,F403
# mypy: disable-error-code=no-untyped def,misc


from complete_arabic_phonological_coverage import (
    CompletePhonemeCatalog,
    AdvancedSyllableAnalyzer,
    SyllableStructure,
)  # noqa: F401
from typing import Dict, List, Any
import json  # noqa: F401


class ComplexWordPhonologicalAnalyzer:
    """ูุญูู ูููููู ูุชูุฏู ูููููุงุช ุงููุนูุฏุฉ"""

    def __init__(self):  # type: ignore[no-untyped def]
        """TODO: Add docstring."""
        self.catalog = CompletePhonemeCatalog()
        self.syllable_analyzer = AdvancedSyllableAnalyzer(self.catalog)
        self.morphological_patterns = self._load_morphological_patterns()

    def _load_morphological_patterns(self) -> Dict[str, Dict]:
        """ุชุญููู ุงูุฃูุฒุงู ุงูุตุฑููุฉ ุงููุชูุฏูุฉ"""
        return {
            'trilateral_augmented': {
                'form_x': {
                    'pattern': 'ูุณุชูุนู',
                    'meaning': 'seek/request',
                    'prefix': 'ูุณุช',
                    'stem_pattern': 'ูุนู',
                    'morphemes': ['ู', 'ุณุช', 'ROOT', 'ูู', 'ูุง'],
                }
            },
            'pronouns': {'plural_masculine': 'ูู', 'attached_feminine': 'ูุง'},
        }

    def analyze_complex_word(self, word: str) -> Dict[str, Any]:
        """
        ุชุญููู ุดุงูู ููููุฉ ูุนูุฏุฉ ูุซู "ูุณุชูุชุจูููุง"

        ุงููุณุชููุงุช:
        1. ุงูุชุญููู ุงูุตูุชู (ูููููู)
        2. ุงูุชุญููู ุงูููุทุนู
        3. ุงูุชุญููู ุงูุตุฑูู
        4. ุงูุชุญููู ุงููุญูู
        5. ุงูุชุญููู ุงูุฏูุงูู
        """

        print(f"๐ฌ ุชุญููู ุดุงูู ูููููุฉ ุงููุนูุฏุฉ: {word}")
        print("=" * 50)

        analysis = {
            'input_word': word,
            'phonemic_analysis': self._analyze_phonemic_structure(word),
            'syllabic_analysis': self._analyze_syllabic_structure(word),
            'morphological_analysis': self._analyze_morphological_structure(word),
            'syntactic_analysis': self._analyze_syntactic_structure(word),
            'semantic_analysis': self._analyze_semantic_structure(word),
            'complexity_score': 0.0,
        }

        # ุญุณุงุจ ุฏุฑุฌุฉ ุงูุชุนููุฏ
        analysis['complexity_score'] = self._calculate_complexity_score(analysis)

        return analysis

    def _analyze_phonemic_structure(self, word: str) -> Dict[str, Any]:
        """ุงูุชุญููู ุงููููููู ูููููุฉ"""

        # ุชุญููู ุงููููุฉ ุฅูู ูููููุงุช
        phonemes = list(word)

        # ุชุตููู ุงููููููุงุช
        classified_phonemes = []
        for phoneme in phonemes:
            classification = self._classify_phoneme(phoneme)
            classified_phonemes.append(
                {
                    'phoneme': phoneme,
                    'type': classification['type'],
                    'features': classification['features'],
                }
            )

        # ุชุญููู ุงูุชุชุงุจุนุงุช ุงูุตูุชูุฉ
        phonotactic_analysis = self._analyze_phonotactic_sequences(phonemes)

        return {
            'total_phonemes': len(phonemes),
            'phoneme_sequence': phonemes,
            'classified_phonemes': classified_phonemes,
            'phonotactic_analysis': phonotactic_analysis,
            'phonological_processes': self._identify_phonological_processes(phonemes),
        }

    def _classify_phoneme(self, phoneme: str) -> Dict[str, Any]:
        """ุชุตููู ุงูููููู ุญุณุจ ุงููุธุงู ุงูุดุงูู"""

        # ุงูุจุญุซ ูู ุงูุตูุงูุช
        for category, consonants in self.catalog.consonants.items():
            if phoneme in consonants:
                return {
                    'type': 'consonant',
                    'features': {
                        'category': category,
                        'voice': self._get_voicing(phoneme),
                        'place': self._get_place_of_articulation(phoneme),
                        'manner': self._get_manner_of_articulation(phoneme),
                    },
                }

        # ุงูุจุญุซ ูู ุงูุตูุงุฆุช
        for vowel_type, vowels in self.catalog.vowels.items():
            if phoneme in vowels:
                return {
                    'type': 'vowel',
                    'features': (
                        vowels[phoneme]
                        if isinstance(vowels, dict)
                        else {'type': vowel_type}
                    ),
                }

        # ุงูุจุญุซ ูู ุงููููููุงุช ุงููุธูููุฉ
        for category, functions in self.catalog.functional_phonemes.items():
            if isinstance(functions, dict):
                for subcategory, items in functions.items():
                    if phoneme in items or (
                        isinstance(items, dict) and phoneme in items
                    ):
                        return {
                            'type': 'functional',
                            'features': {
                                'category': category,
                                'subcategory': subcategory,
                                'function': 'grammatical',
                            },
                        }

        return {'type': 'unknown', 'features': {'category': 'unclassified'}}

    def _get_voicing(self, phoneme: str) -> str:
        """ุชุญุฏูุฏ ุงูุฌูุฑ/ุงูููุณ"""
        voiced = [
            'ุจ',
            'ุฏ',
            'ุฌ',
            'ุฒ',
            'ุฐ',
            'ุถ',
            'ุธ',
            'ุบ',
            'ุน',
            'ู',
            'ุฑ',
            'ู',
            'ู',
            'ู',
            'ู',
        ]
        return 'voiced' if phoneme in voiced else 'voiceless'

    def _get_place_of_articulation(self, phoneme: str) -> str:
        """ุชุญุฏูุฏ ูุฎุฑุฌ ุงูุตูุช"""
        places = {
            'bilabial': ['ุจ', 'ู'],
            'dental': ['ุช', 'ุฏ', 'ุซ', 'ุฐ', 'ู'],
            'alveolar': ['ุณ', 'ุฒ', 'ู', 'ุฑ'],
            'postalveolar': ['ุด'],
            'pharyngealized': ['ุต', 'ุถ', 'ุท', 'ุธ'],
            'velar': ['ู'],
            'uvular': ['ู', 'ุบ', 'ุฎ'],
            'pharyngeal': ['ุญ', 'ุน'],
            'glottal': ['ุก', 'ู'],
        }

        for place, phonemes in places.items():
            if phoneme in phonemes:
                return place
        return 'unknown'

    def _get_manner_of_articulation(self, phoneme: str) -> str:
        """ุชุญุฏูุฏ ููููุฉ ุงููุทู"""
        manners = {
            'stop': ['ุจ', 'ุช', 'ุฏ', 'ุท', 'ู', 'ู', 'ุก'],
            'fricative': [
                'ู',
                'ุซ',
                'ุฐ',
                'ุณ',
                'ุฒ',
                'ุด',
                'ุต',
                'ุถ',
                'ุฎ',
                'ุบ',
                'ุญ',
                'ุน',
                'ู',
            ],
            'nasal': ['ู', 'ู'],
            'liquid': ['ู', 'ุฑ'],
            'approximant': ['ู', 'ู'],
        }

        for manner, phonemes in manners.items():
            if phoneme in phonemes:
                return manner
        return 'unknown'

    def _analyze_phonotactic_sequences(self, phonemes: List[str]) -> Dict[str, Any]:
        """ุชุญููู ุงูุชุชุงุจุนุงุช ุงูุตูุชูุฉ"""

        sequences = []
        constraints_violated = []

        for i in range(len(phonemes) - 1):
            current = phonemes[i]
            next_phoneme = phonemes[i + 1]

            sequence = {
                'position': i,
                'sequence': [current, next_phoneme],
                'valid': self._check_phonotactic_validity(current, next_phoneme),
                'type': self._classify_sequence_type(current, next_phoneme),
            }

            sequences.append(sequence)

            if not sequence['valid']:
                constraints_violated.append(sequence)

        return {
            'sequences': sequences,
            'total_sequences': len(sequences),
            'valid_sequences': len([s for s in sequences if s['valid']]),
            'constraints_violated': constraints_violated,
            'phonotactic_score': (
                len([s for s in sequences if s['valid']]) / len(sequences)
                if sequences
                else 1.0
            ),
        }

    def _check_phonotactic_validity(self, phoneme1: str, phoneme2: str) -> bool:
        """ูุญุต ุตุญุฉ ุงูุชุชุงุจุน ุงูุตูุชู"""

        # ููุงุนุฏ ุฃุณุงุณูุฉ ููุชุชุงุจุน ุงูุตูุชู ุงูุนุฑุจู
        forbidden_sequences = [
            ('ุก', 'ุก'),
            ('ู', 'ู'),  # ููุน ุชูุฑุงุฑ ุงูุฃุตูุงุช ุงูุญูุฌุฑูุฉ
            ('ู', 'ู'),
            ('ู', 'ู'),  # ููุน ุชุชุงุจุน ุงูุฃุตูุงุช ุงููุชุดุงุจูุฉ
        ]

        return (phoneme1, phoneme2) not in forbidden_sequences

    def _classify_sequence_type(self, phoneme1: str, phoneme2: str) -> str:
        """ุชุตููู ููุน ุงูุชุชุงุจุน"""

        consonants = [
            'ุจ',
            'ุช',
            'ุซ',
            'ุฌ',
            'ุญ',
            'ุฎ',
            'ุฏ',
            'ุฐ',
            'ุฑ',
            'ุฒ',
            'ุณ',
            'ุด',
            'ุต',
            'ุถ',
            'ุท',
            'ุธ',
            'ุน',
            'ุบ',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ุก',
        ]
        vowels = ['ู', 'ู', 'ู', 'ุง', 'ู', 'ู']

        if phoneme1 in consonants and phoneme2 in consonants:
            return 'CC'
        elif phoneme1 in consonants and phoneme2 in vowels:
            return 'CV'
        elif phoneme1 in vowels and phoneme2 in consonants:
            return 'VC'
        elif phoneme1 in vowels and phoneme2 in vowels:
            return 'VV'
        else:
            return 'unknown'

    def _identify_phonological_processes(
        self, phonemes: List[str]
    ) -> List[Dict[str, Any]]:
        """ุชุญุฏูุฏ ุงูุนูููุงุช ุงูุตูุชูุฉ"""

        processes = []

        # ุงูุจุญุซ ุนู ุงูุฅุฏุบุงู
        for i in range(len(phonemes) - 1):
            if phonemes[i] == phonemes[i + 1]:
                processes.append(
                    {
                        'type': 'gemination',
                        'position': i,
                        'phonemes': [phonemes[i], phonemes[i + 1]],
                        'description': f'ุฅุฏุบุงู {phonemes[i]}',
                    }
                )

        # ุงูุจุญุซ ุนู ุงูุฅุนูุงู
        weak_letters = ['ู', 'ู', 'ุง']
        for i, phoneme in enumerate(phonemes):
            if phoneme in weak_letters:
                processes.append(
                    {
                        'type': 'vowel_change_potential',
                        'position': i,
                        'phoneme': phoneme,
                        'description': f'ุญุฑู ุนูุฉ ูุญุชูู ุงูุฅุนูุงู: {phoneme}',
                    }
                )

        return processes

    def _analyze_syllabic_structure(self, word: str) -> Dict[str, Any]:
        """ุงูุชุญููู ุงูููุทุนู ูููููุฉ"""

        # ุชุญููู ูุจุณุท ููููุงุทุน (ูููู ุชุทููุฑู ุฃูุซุฑ)
        syllables = self._syllabify_word(word)

        syllable_analysis = []
        for i, syllable in enumerate(syllables):
            analysis = {
                'syllable': syllable,
                'position': i,
                'structure': self._determine_syllable_structure(syllable),
                'weight': self._determine_syllable_weight(syllable),
                'stress_potential': self._assess_stress_potential(
                    syllable, i, len(syllables)
                ),
            }
            syllable_analysis.append(analysis)

        return {
            'total_syllables': len(syllables),
            'syllables': syllables,
            'syllable_analysis': syllable_analysis,
            'syllabic_complexity': len(syllables) * 0.5
            + len([s for s in syllable_analysis if s['weight'] == 'heavy']) * 0.3,
        }

    def _syllabify_word(self, word: str) -> List[str]:
        """ุชูุทูุน ุงููููุฉ ุฅูู ููุงุทุน (ูุจุณุท)"""

        # ุฎูุงุฑุฒููุฉ ุชูุทูุน ูุจุณุทุฉ
        # ูู ุชุทุจูู ุญููููุ ูุญุชุงุฌ ุฎูุงุฑุฒููุฉ ุฃูุซุฑ ุชุทูุฑุงู

        syllables = []
        current_syllable = ""
        vowels = ['ู', 'ู', 'ู', 'ุง', 'ู', 'ู']

        i = 0
        while i < len(word):
            char = word[i]
            current_syllable += char

            # ุฅุฐุง ูุงู ุงูุญุฑู ุตุงุฆุชุงูุ ููุธุฑ ููุญุฑู ุงูุชุงูู
            if char in vowels:
                # ุฅุฐุง ูุงู ุงูุญุฑู ุงูุชุงูู ุตุงูุชุงูุ ูุถููู ููููู ุงูููุทุน
                if i + 1 < len(word) and word[i + 1] not in vowels:
                    current_syllable += word[i + 1]
                    i += 1

                syllables.append(current_syllable)
                current_syllable = ""

            i += 1

        if current_syllable:
            syllables.append(current_syllable)

        return syllables

    def _determine_syllable_structure(self, syllable: str) -> str:
        """ุชุญุฏูุฏ ุจููุฉ ุงูููุทุน"""

        consonants = [
            'ุจ',
            'ุช',
            'ุซ',
            'ุฌ',
            'ุญ',
            'ุฎ',
            'ุฏ',
            'ุฐ',
            'ุฑ',
            'ุฒ',
            'ุณ',
            'ุด',
            'ุต',
            'ุถ',
            'ุท',
            'ุธ',
            'ุน',
            'ุบ',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ู',
            'ุก',
        ]
        vowels = ['ู', 'ู', 'ู', 'ุง', 'ู', 'ู']

        structure = ""
        for char in syllable:
            if char in consonants:
                structure += "C"
            elif char in vowels:
                structure += "V"

        return structure

    def _determine_syllable_weight(self, syllable: str) -> str:
        """ุชุญุฏูุฏ ูุฒู ุงูููุทุน"""

        structure = self._determine_syllable_structure(syllable)

        if structure in ['CV']:
            return 'light'
        elif structure in ['CVC', 'CVV']:
            return 'heavy'
        elif structure in ['CVCC', 'CVVC']:
            return 'super_heavy'
        else:
            return 'unknown'

    def _assess_stress_potential(
        self, syllable: str, position: int, total_syllables: int
    ) -> float:
        """ุชูููู ุงุญุชูุงููุฉ ุงููุจุฑ"""

        # ููุงุนุฏ ูุจุณุทุฉ ูููุจุฑ ุงูุนุฑุจู
        weight = self._determine_syllable_weight(syllable)

        stress_score = 0.0

        # ุงูููุงุทุน ุงูุซูููุฉ ููุง ุฃููููุฉ
        if weight == 'heavy':
            stress_score += 0.6
        elif weight == 'super_heavy':
            stress_score += 0.8

        # ุงูููุทุน ุงูุฃุฎูุฑ ูู ุฃููููุฉ
        if position == total_syllables - 1:
            stress_score += 0.4

        # ุงูููุทุน ูุง ูุจู ุงูุฃุฎูุฑ
        elif position == total_syllables - 2:
            stress_score += 0.3

        return min(stress_score, 1.0)

    def _analyze_morphological_structure(self, word: str) -> Dict[str, Any]:
        """ุงูุชุญููู ุงูุตุฑูู ูููููุฉ"""

        # ุชุญููู ูุจุณุท ูููุฒู ุงูุนุงุดุฑ "ูุณุชูุชุจูููุง"
        if word == "ูุณุชูุชุจูููุง":
            return {
                'morphological_type': 'form_x_verb_with_pronouns',
                'root': 'ูุชุจ',
                'pattern': 'ูุณุชูุนู',
                'form': 'X',
                'morphemes': [
                    {
                        'morpheme': 'ู',
                        'type': 'prefix',
                        'function': 'imperfective_marker',
                    },
                    {'morpheme': 'ุณุช', 'type': 'prefix', 'function': 'form_x_marker'},
                    {'morpheme': 'ูุชุจ', 'type': 'root', 'function': 'lexical_core'},
                    {
                        'morpheme': 'ูู',
                        'type': 'suffix',
                        'function': 'plural_masculine',
                    },
                    {
                        'morpheme': 'ูุง',
                        'type': 'suffix',
                        'function': 'attached_pronoun_feminine',
                    },
                ],
                'semantic_frame': {
                    'action': 'seek_to_cause_writing',
                    'agent': 'third_person_plural_masculine',
                    'patient': 'third_person_singular_feminine',
                },
            }

        # ุชุญููู ุนุงู ููููุงุช ุฃุฎุฑู
        return {
            'morphological_type': 'complex_word',
            'analysis_confidence': 0.5,
            'morphemes': [{'morpheme': word, 'type': 'unknown', 'function': 'unknown'}],
        }

    def _analyze_syntactic_structure(self, word: str) -> Dict[str, Any]:
        """ุงูุชุญููู ุงููุญูู ูููููุฉ"""

        if word == "ูุณุชูุชุจูููุง":
            return {
                'word_class': 'verb',
                'verb_features': {
                    'tense': 'imperfective',
                    'person': '3rd',
                    'number': 'plural',
                    'gender': 'masculine',
                    'voice': 'active',
                    'mood': 'indicative',
                },
                'attached_pronouns': [
                    {
                        'pronoun': 'ูุง',
                        'person': '3rd',
                        'number': 'singular',
                        'gender': 'feminine',
                        'case': 'accusative',
                        'function': 'direct_object',
                    }
                ],
                'syntactic_complexity': 0.9,
            }

        return {'word_class': 'unknown', 'syntactic_complexity': 0.3}

    def _analyze_semantic_structure(self, word: str) -> Dict[str, Any]:
        """ุงูุชุญููู ุงูุฏูุงูู ูููููุฉ"""

        if word == "ูุณุชูุชุจูููุง":
            return {
                'semantic_field': 'communication',
                'semantic_roles': {
                    'agent': 'group_of_males',
                    'action': 'causative_writing_request',
                    'patient': 'female_entity',
                },
                'semantic_features': [
                    'causative',
                    'communicative',
                    'interpersonal',
                    'written_medium',
                ],
                'complexity_level': 'high',
                'semantic_transparency': 0.8,
            }

        return {
            'semantic_field': 'unknown',
            'complexity_level': 'medium',
            'semantic_transparency': 0.5,
        }

    def _calculate_complexity_score(self, analysis: Dict[str, Any]) -> float:
        """ุญุณุงุจ ุฏุฑุฌุฉ ุงูุชุนููุฏ ุงูุฅุฌูุงููุฉ"""

        complexity_factors = [
            analysis['phonemic_analysis']['total_phonemes'] / 10,  # ุนุฏุฏ ุงููููููุงุช
            analysis['syllabic_analysis']['syllabic_complexity'],  # ุชุนููุฏ ุงูููุงุทุน
            len(analysis['morphological_analysis']['morphemes']) / 5,  # ุนุฏุฏ ุงูููุฑูููุงุช
            analysis['syntactic_analysis'].get(
                'syntactic_complexity', 0.5
            ),  # ุงูุชุนููุฏ ุงููุญูู
            1
            - analysis['semantic_analysis'].get(
                'semantic_transparency', 0.5
            ),  # ุงูุดูุงููุฉ ุงูุฏูุงููุฉ
        ]

        return sum(complexity_factors) / len(complexity_factors)


def demonstrate_complex_analysis():  # type: ignore[no-untyped-def]
    """ุนุฑุถ ุชูุถูุญู ููุชุญููู ุงููุชูุฏู"""

    print("๐ ุนุฑุถ ุชูุถูุญู: ุชุญููู ุงููููุงุช ุงููุนูุฏุฉ")
    print("=" * 60)

    analyzer = ComplexWordPhonologicalAnalyzer()

    # ุชุญููู ุงููููุฉ ุงููุนูุฏุฉ
    complex_word = "ูุณุชูุชุจูููุง"
    analysis = analyzer.analyze_complex_word(complex_word)

    # ุนุฑุถ ุงููุชุงุฆุฌ
    print("\n๐ ูุชุงุฆุฌ ุงูุชุญููู ุงูุดุงูู:")
    print(f"   ุงููููุฉ: {analysis['input_word']}")
    print(f"   ุนุฏุฏ ุงููููููุงุช: {analysis['phonemic_analysis']['total_phonemes']}")
    print(f"   ุนุฏุฏ ุงูููุงุทุน: {analysis['syllabic_analysis']['total_syllables']}")
    print(f"   ุนุฏุฏ ุงูููุฑูููุงุช: {len(analysis['morphological_analysis']['morphemes'])}")
    print(f"   ุฏุฑุฌุฉ ุงูุชุนููุฏ: {analysis['complexity_score']:.2f}/1.0")

    print("\n๐ฌ ุงูุชุญููู ุงููููููู:")
    for phoneme_data in analysis['phonemic_analysis']['classified_phonemes']:
        print(
            f"   {phoneme_data['phoneme']}: {phoneme_data['type']} - {phoneme_data['features']}}"
        )  # noqa: E501

    print("\n๐๏ธ ุงูุชุญููู ุงูููุทุนู:")
    for syl_data in analysis['syllabic_analysis']['syllable_analysis']:
        print(
            f"   {syl_data['syllable']}: {syl_data['structure']} ({syl_data['weight']})"
        )  # noqa: E501

    print("\n๐ ุงูุชุญููู ุงูุตุฑูู:")
    for morpheme in analysis['morphological_analysis']['morphemes']:
        print(f"   {morpheme['morpheme']}: {morpheme['type']} - {morpheme['function']}}")

    print("\n๐๏ธ ุงูุชุญููู ุงููุญูู:")
    verb_features = analysis['syntactic_analysis']['verb_features']
    print(
        f"   ูุนู ูุถุงุฑุนุ {verb_features['person']}ุ {verb_features['number']}, {verb_features['gender']}"
    )  # noqa: E501

    print("\n๐ญ ุงูุชุญููู ุงูุฏูุงูู:")
    semantic = analysis['semantic_analysis']
    print(f"   ุงููุฌุงู ุงูุฏูุงูู: {semantic['semantic_field']}")
    print(f"   ุงูุฃุฏูุงุฑ: {semantic['semantic_roles']}")

    # ุญูุธ ุงูุชุญููู ุงูุชูุตููู
    with open('complex_word_analysis.json', 'w', encoding='utf 8') as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)

    print("\nโ ุชู ุญูุธ ุงูุชุญููู ุงูุชูุตููู ูู: complex_word_analysis.json")

    return analysis


if __name__ == "__main__":
    demonstrate_complex_analysis()
