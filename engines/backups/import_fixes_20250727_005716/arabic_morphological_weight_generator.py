#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Arabic Morphological Weight Generator - Complete Pattern System
==============================================================
Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØµØ±ÙÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ø§Ù…Ù„

This module generates ALL Arabic morphological weights (patterns) using
the complete syllable database built in Phase 1. Builds on 22,218 syllables
to create comprehensive morphological patterns for verbs and nouns.

Key Features:
- Complete morphological weight generation for Arabic verbs and nouns
- Syllable-based pattern construction using phonological foundation
- Phonotactic constraint application between syllables
- Enterprise-grade morphological pattern inventory
- Zero external dependencies - pure Arabic linguistic science

Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
- ØªÙˆÙ„ÙŠØ¯ Ø´Ø§Ù…Ù„ Ù„Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØµØ±ÙÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„Ø£ÙØ¹Ø§Ù„ ÙˆØ§Ù„Ø£Ø³Ù…Ø§Ø¡
- Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ØµÙˆØªÙŠØ©
- ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙŠÙˆØ¯ Ø§Ù„ØªØªØ§Ø¨Ø¹ Ø§Ù„ØµÙˆØªÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
- Ù…Ø®Ø²ÙˆÙ† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØµØ±ÙÙŠØ© Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø¤Ø³Ø³Ø§Øª
- ØµÙØ± Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª Ø®Ø§Ø±Ø¬ÙŠØ© - Ø¹Ù„Ù… Ù„ØºÙˆÙŠ Ø¹Ø±Ø¨ÙŠ Ù†Ù‚ÙŠ

Author: Arabic NLP Expert Team - GitHub Copilot
Version: 2.0.0 - MORPHOLOGICAL PATTERN GENERATION
Date: 2025-07-24
License: MIT
Encoding: UTF 8
"""

import logging
import sys
import json
from typing import List, Dict, Set, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict
import itertools

# Import our complete syllable generator
from arabic_syllable_generator import ()
    CompleteArabicSyllableGenerator,
    GeneratedSyllable)

# Configure professional logging
logging.basicConfig()
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
    logging.FileHandler('arabic_morphological_weights.log', encoding='utf 8'),
    logging.StreamHandler(sys.stdout),
    ])

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ARABIC MORPHOLOGICAL WEIGHT DEFINITIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ArabicWordType(Enum):
    """Arabic word types for morphological analysis"""

    # Verbs (Ø§Ù„Ø£ÙØ¹Ø§Ù„)
    VERB_TRILITERAL_BARE = "ÙØ¹Ù„_Ø«Ù„Ø§Ø«ÙŠ_Ù…Ø¬Ø±Ø¯"  # ÙÙØ¹ÙÙ„Ù
    VERB_TRILITERAL_AUGMENTED = "ÙØ¹Ù„_Ø«Ù„Ø§Ø«ÙŠ_Ù…Ø²ÙŠØ¯"  # Ø£ÙÙÙ’Ø¹ÙÙ„ÙØŒ Ø§Ù†Ù’ÙÙØ¹ÙÙ„Ù
    VERB_QUADRILITERAL_BARE = "ÙØ¹Ù„_Ø±Ø¨Ø§Ø¹ÙŠ_Ù…Ø¬Ø±Ø¯"  # ÙÙØ¹Ù’Ù„ÙÙ„Ù
    VERB_QUADRILITERAL_AUGMENTED = "ÙØ¹Ù„_Ø±Ø¨Ø§Ø¹ÙŠ_Ù…Ø²ÙŠØ¯"  # ØªÙÙÙØ¹Ù’Ù„ÙÙ„Ù

    # Nouns (Ø§Ù„Ø£Ø³Ù…Ø§Ø¡)
    NOUN_DERIVATIVE = "Ø§Ø³Ù…_Ù…Ø´ØªÙ‚"  # ÙÙØ§Ø¹ÙÙ„ØŒ Ù…ÙÙÙ’Ø¹ÙÙˆÙ„
    NOUN_SOURCE = "Ù…ØµØ¯Ø±"  # ÙÙØ¹Ù’Ù„ØŒ ÙÙØ¹ÙØ§Ù„ÙØ©
    NOUN_DIMINUTIVE = "ØªØµØºÙŠØ±"  # ÙÙØ¹ÙÙŠÙ’Ù„
    NOUN_PLURAL_MASCULINE = "Ø¬Ù…Ø¹_Ù…Ø°ÙƒØ±_Ø³Ø§Ù„Ù…"  # ÙÙØ§Ø¹ÙÙ„ÙÙˆÙ†
    NOUN_PLURAL_FEMININE = "Ø¬Ù…Ø¹_Ù…Ø¤Ù†Ø«_Ø³Ø§Ù„Ù…"  # ÙÙØ§Ø¹ÙÙ„ÙØ§Øª
    NOUN_PLURAL_BROKEN = "Ø¬Ù…Ø¹_ØªÙƒØ³ÙŠØ±"  # ÙÙØ¹ÙÙˆÙ„ØŒ Ø£ÙÙÙ’Ø¹ÙØ§Ù„
    NOUN_DUAL = "Ù…Ø«Ù†Ù‰"  # ÙÙØ§Ø¹ÙÙ„ÙØ§Ù†
    NOUN_FEMININE = "Ù…Ø¤Ù†Ø«"  # ÙÙØ§Ø¹ÙÙ„ÙØ©
    NOUN_PLACE = "Ø§Ø³Ù…_Ù…ÙƒØ§Ù†"  # Ù…ÙÙÙ’Ø¹ÙÙ„
    NOUN_TIME = "Ø§Ø³Ù…_Ø²Ù…Ø§Ù†"  # Ù…ÙÙÙ’Ø¹ÙÙ„
    NOUN_INSTRUMENT = "Ø§Ø³Ù…_Ø¢Ù„Ø©"  # Ù…ÙÙÙ’Ø¹ÙØ§Ù„


class MorphologicalWeightPattern(Enum):
    """Standard Arabic morphological weight patterns"""

    # Triliteral verb patterns (Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠØ©)
    FAALA = "ÙÙØ¹ÙÙ„Ù"  # CV-CV CV
    FAILA = "ÙÙØ¹ÙÙ„Ù"  # CV-CV CV
    FAULA = "ÙÙØ¹ÙÙ„Ù"  # CV-CV CV
    AFAALA = "Ø£ÙÙÙ’Ø¹ÙÙ„Ù"  # CV-CVC CV
    FAALA_II = "ÙÙØ¹ÙÙ‘Ù„Ù"  # CV-CVC CV (with gemination)
    FAATALA = "ÙÙØ§Ø¹ÙÙ„Ù"  # CVV-CV CV
    TAFAALA = "ØªÙÙÙØ§Ø¹ÙÙ„Ù"  # CV-CVV-CV CV
    INFAALA = "Ø§Ù†Ù’ÙÙØ¹ÙÙ„Ù"  # CVC-CV CV
    IFTAALA = "Ø§ÙÙ’ØªÙØ¹ÙÙ„Ù"  # CVC-CV CV
    ISTAFAALA = "Ø§Ø³Ù’ØªÙÙÙ’Ø¹ÙÙ„Ù"  # CVC-CVC-CV CV

    # Quadriliteral verb patterns (Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ø±Ø¨Ø§Ø¹ÙŠØ©)
    FAALLALA = "ÙÙØ¹Ù’Ù„ÙÙ„Ù"  # CVC-CV CV
    TAFAALLALA = "ØªÙÙÙØ¹Ù’Ù„ÙÙ„Ù"  # CV-CVC-CV CV

    # Noun patterns (Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø£Ø³Ù…Ø§Ø¡)
    FAAIL = "ÙÙØ§Ø¹ÙÙ„"  # CVV CVC (active participle)
    MAFUUL = "Ù…ÙÙÙ’Ø¹ÙÙˆÙ„"  # CV CVVC (passive participle)
    FAIL = "ÙÙØ¹ÙÙŠÙ„"  # CV CVVC (intensive adjective)
    FAAAL = "ÙÙØ¹ÙÙ‘Ø§Ù„"  # CV CVVC (intensive agent)
    AFAAL = "Ø£ÙÙÙ’Ø¹ÙØ§Ù„"  # CV CVVC (broken plural)
    FUUUL = "ÙÙØ¹ÙÙˆÙ„"  # CV CVVC (broken plural)
    FAALAH = "ÙÙØ§Ø¹ÙÙ„ÙØ©"  # CVV-CV CV (feminine active participle)
    FAALAAN = "ÙÙØ§Ø¹ÙÙ„ÙØ§Ù†"  # CVV-CVV CVC (dual)
    FAALUUN = "ÙÙØ§Ø¹ÙÙ„ÙÙˆÙ†"  # CVV-CVV CVC (masculine plural)
    FAALAAT = "ÙÙØ§Ø¹ÙÙ„ÙØ§Øª"  # CVV-CVV CVC (feminine plural)


@dataclass
class MorphologicalWeight:
    """Complete morphological weight with syllable composition"""

    pattern_name: str
    pattern_template: str
    word_type: ArabicWordType
    syllable_sequence: List[GeneratedSyllable]
    syllable_pattern: List[str]  # e.g., ["CV", "CVC", "CV"]
    phonetic_form: str
    morphological_features: Dict[str, Any] = field(default_factory=dict)
    frequency_estimate: float = 0.0
    prosodic_weight: float = 0.0
    constraints_applied: List[str] = field(default_factory=list)
    is_valid: bool = True


@dataclass
class WeightGenerationConstraints:
    """Constraints for morphological weight generation"""

    # Inter syllable constraints
    forbidden_syllable_sequences: Set[Tuple[str, str]] = field(default_factory=set)

    # Morphological constraints
    verb_constraints: Dict[str, List[str]] = field(default_factory=dict)
    noun_constraints: Dict[str, List[str]] = field(default_factory=dict)

    # Phonotactic constraints
    gemination_restrictions: Set[str] = field(default_factory=set)
    vowel_harmony_rules: Dict[str, str] = field(default_factory=dict)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPLETE ARABIC MORPHOLOGICAL WEIGHT GENERATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ArabicMorphologicalWeightGenerator:
    """
    Complete Arabic morphological weight generator using syllable database

    Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØµØ±ÙÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
    """

    def __init__()
    self, syllables_database_path: str = "complete_arabic_syllable_inventory.json"
    ):
    """Initialize with syllable database"""
    self.syllables_db = self._load_syllable_database(syllables_database_path)
    self.weights_db: List[MorphologicalWeight] = []
    self.constraints = WeightGenerationConstraints()
    self._setup_morphological_constraints()
    self._organize_syllables_by_type()
    logger.info()
    f"ArabicMorphologicalWeightGenerator initialized with {len(self.syllables_db)} syllables"
    )

    def _load_syllable_database(self, path: str) -> List[Dict[str, Any]]:
    """Load the syllable database from JSON file"""
        try:
            with open(path, 'r', encoding='utf 8') as f:
    data = json.load(f)

            # Flatten all syllable types into one list
    all_syllables = []
            for syllable_type, syllables in data.items():
                for syl_data in syllables:
    syl_data['type'] = syllable_type
    all_syllables.append(syl_data)

    logger.info(f"Loaded {len(all_syllables)} syllables from database")
    return all_syllables

        except FileNotFoundError:
    logger.warning(f"Syllable database {path} not found. Generating new one...")
            # Generate syllables if database doesn't exist'
    return self._generate_syllable_database()

    def _generate_syllable_database(self) -> List[Dict[str, Any]]:
    """Generate syllable database if not found"""
    generator = CompleteArabicSyllableGenerator()
    all_syllables = generator.generate_all_syllables()

        # Convert to database format
    syllable_list = []
        for syllable_type, syllables in all_syllables.items():
            for syllable in syllables:
    syl_data = {
    'text': syllable.syllable_text,
    'type': syllable_type,
    'onset': syllable.onset,
    'nucleus': syllable.nucleus,
    'coda': syllable.coda,
    'prosodic_weight': syllable.prosodic_weight,
    'frequency_estimate': syllable.frequency_estimate,
    'features': syllable.phonological_features,
    }
    syllable_list.append(syl_data)

    return syllable_list

    def _organize_syllables_by_type(self):
    """Organize syllables by their types for efficient access"""
    self.syllables_by_type = defaultdict(list)

        for syllable in self.syllables_db:
    self.syllables_by_type[syllable['type']].append(syllable)

    logger.info()
    f"Organized syllables: {dict((k, len(v)) for k, v} in self.syllables_by_type.items())}"
    )

    def _setup_morphological_constraints(self):
    """Setup morphological and phonotactic constraints"""

        # Forbidden syllable sequences (example constraints)
    self.constraints.forbidden_syllable_sequences.update()
    [
                # Avoid difficult consonant clusters between syllables
    ('CVCC', 'CVC'),  # Double closure difficulty
    ('CVCC', 'CVCC'),  # Triple consonant sequences
    ]
    )

        # Verb specific constraints
    self.constraints.verb_constraints = {
    'no_initial_sukun': True,  # Ù„Ø§ ÙŠØ¨Ø¯Ø£ Ø§Ù„ÙØ¹Ù„ Ø¨Ø³Ø§ÙƒÙ†
    'final_vowel_required': True,  # Ø§Ù„ÙØ¹Ù„ ÙŠØ­ØªØ§Ø¬ Ø­Ø±ÙƒØ© ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
    'max_syllables': 5,  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹
    }

        # Noun specific constraints
    self.constraints.noun_constraints = {
    'feminine_marker_compatible': True,  # ØªÙˆØ§ÙÙ‚ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ£Ù†ÙŠØ«
    'plural_patterns_valid': True,  # ØµØ­Ø© Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¬Ù…Ø¹
    'max_syllables': 6,  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹
    }

    logger.info("Morphological constraints setup complete")

    def generate_verb_weights(self) -> List[MorphologicalWeight]:
    """Generate all Arabic verb morphological weights"""

    logger.info("ğŸ”¬ Starting verb weight generation...")
    verb_weights = []

        # Triliteral bare verbs (Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ù…Ø¬Ø±Ø¯Ø©)
    verb_weights.extend(self._generate_triliteral_bare_verbs())

        # Triliteral augmented verbs (Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ù…Ø²ÙŠØ¯Ø©)
    verb_weights.extend(self._generate_triliteral_augmented_verbs())

        # Quadriliteral verbs (Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ø±Ø¨Ø§Ø¹ÙŠØ©)
    verb_weights.extend(self._generate_quadriliteral_verbs())

    logger.info(f"âœ… Generated {len(verb_weights)} verb weights")
    return verb_weights

    def _generate_triliteral_bare_verbs(self) -> List[MorphologicalWeight]:
    """Generate triliteral bare verb weights (ÙÙØ¹ÙÙ„ÙØŒ ÙÙØ¹ÙÙ„ÙØŒ ÙÙØ¹ÙÙ„Ù)"""

    weights = []
    self.syllables_by_type['CV']

        # Pattern: CV-CV CV for ÙÙØ¹ÙÙ„Ù type verbs
    patterns = [
    ('ÙÙØ¹ÙÙ„Ù', ['CV', 'CV', 'CV']),
    ('ÙÙØ¹ÙÙ„Ù', ['CV', 'CV', 'CV']),
    ('ÙÙØ¹ÙÙ„Ù', ['CV', 'CV', 'CV']),
    ]

        for pattern_name, syllable_pattern in patterns:
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name=pattern_name,
    syllable_pattern=syllable_pattern,
    word_type=ArabicWordType.VERB_TRILITERAL_BARE,
    max_combinations=1000,  # Limit for performance
    )
    weights.extend(pattern_weights)

    logger.info(f"Generated {len(weights)} triliteral bare verb weights")
    return weights

    def _generate_triliteral_augmented_verbs(self) -> List[MorphologicalWeight]:
    """Generate triliteral augmented verb weights"""

    weights = []

    patterns = [
    ('Ø£ÙÙÙ’Ø¹ÙÙ„Ù', ['CV', 'CVC', 'CV']),  # Form IV
    ('ÙÙØ¹ÙÙ‘Ù„Ù', ['CV', 'CVC', 'CV']),  # Form II (with gemination)
    ('ÙÙØ§Ø¹ÙÙ„Ù', ['CVV', 'CV', 'CV']),  # Form III
    ('Ø§Ù†Ù’ÙÙØ¹ÙÙ„Ù', ['CVC', 'CV', 'CV']),  # Form VII
    ('Ø§ÙÙ’ØªÙØ¹ÙÙ„Ù', ['CVC', 'CV', 'CV']),  # Form VIII
    ('Ø§Ø³Ù’ØªÙÙÙ’Ø¹ÙÙ„Ù', ['CVC', 'CVC', 'CV']),  # Form X
    ]

        for pattern_name, syllable_pattern in patterns:
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name=pattern_name,
    syllable_pattern=syllable_pattern,
    word_type=ArabicWordType.VERB_TRILITERAL_AUGMENTED,
    max_combinations=500,  # Smaller limit for complex patterns
    )
    weights.extend(pattern_weights)

    logger.info(f"Generated {len(weights)} triliteral augmented verb weights")
    return weights

    def _generate_quadriliteral_verbs(self) -> List[MorphologicalWeight]:
    """Generate quadriliteral verb weights"""

    weights = []

    patterns = [
    ('ÙÙØ¹Ù’Ù„ÙÙ„Ù', ['CVC', 'CV', 'CV']),  # Bare quadriliteral
    ('ØªÙÙÙØ¹Ù’Ù„ÙÙ„Ù', ['CV', 'CVC', 'CV']),  # Augmented quadriliteral
    ]

        for pattern_name, syllable_pattern in patterns:
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name=pattern_name,
    syllable_pattern=syllable_pattern,
    word_type=ArabicWordType.VERB_QUADRILITERAL_BARE,
    max_combinations=300)
    weights.extend(pattern_weights)

    logger.info(f"Generated {len(weights)} quadriliteral verb weights")
    return weights

    def generate_noun_weights(self) -> List[MorphologicalWeight]:
    """Generate all Arabic noun morphological weights"""

    logger.info("ğŸ”¬ Starting noun weight generation...")
    noun_weights = []

        # Derivative nouns (Ø§Ù„Ù…Ø´ØªÙ‚Ø§Øª)
    noun_weights.extend(self._generate_derivative_nouns())

        # Source nouns (Ø§Ù„Ù…ØµØ§Ø¯Ø±)
    noun_weights.extend(self._generate_source_nouns())

        # Plural forms (ØµÙŠØº Ø§Ù„Ø¬Ù…Ø¹)
    noun_weights.extend(self._generate_plural_nouns())

        # Dual and feminine forms (Ø§Ù„Ù…Ø«Ù†Ù‰ ÙˆØ§Ù„Ù…Ø¤Ù†Ø«)
    noun_weights.extend(self._generate_dual_and_feminine_nouns())

        # Place, time, and instrument nouns (Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙƒØ§Ù† ÙˆØ§Ù„Ø²Ù…Ø§Ù† ÙˆØ§Ù„Ø¢Ù„Ø©)
    noun_weights.extend(self._generate_specialized_nouns())

    logger.info(f"âœ… Generated {len(noun_weights)} noun weights")
    return noun_weights

    def _generate_derivative_nouns(self) -> List[MorphologicalWeight]:
    """Generate derivative noun weights (ÙÙØ§Ø¹ÙÙ„ØŒ Ù…ÙÙÙ’Ø¹ÙÙˆÙ„ØŒ etc.)"""

    weights = []

    patterns = [
    ('ÙÙØ§Ø¹ÙÙ„', ['CVV', 'CVC']),  # Active participle
    ('Ù…ÙÙÙ’Ø¹ÙÙˆÙ„', ['CV', 'CVVC']),  # Passive participle
    ('ÙÙØ¹ÙÙŠÙ„', ['CV', 'CVVC']),  # Intensive adjective
    ('ÙÙØ¹ÙÙ‘Ø§Ù„', ['CV', 'CVVC']),  # Intensive agent
    ('Ù…ÙÙÙ’Ø¹ÙØ§Ù„', ['CVC', 'CVVC']),  # Instrumental noun
    ]

        for pattern_name, syllable_pattern in patterns:
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name=pattern_name,
    syllable_pattern=syllable_pattern,
    word_type=ArabicWordType.NOUN_DERIVATIVE,
    max_combinations=800)
    weights.extend(pattern_weights)

    logger.info(f"Generated {len(weights)} derivative noun weights")
    return weights

    def _generate_source_nouns(self) -> List[MorphologicalWeight]:
    """Generate source noun weights (Ù…ØµØ§Ø¯Ø±)"""

    weights = []

    patterns = [
    ('ÙÙØ¹Ù’Ù„', ['CVC']),  # Basic source
    ('ÙÙØ¹ÙØ§Ù„ÙØ©', ['CV', 'CVV', 'CV']),  # Intensive source
    ('ØªÙÙÙ’Ø¹ÙÙŠÙ„', ['CVC', 'CVVC']),  # Form II source
    ('Ù…ÙÙÙØ§Ø¹ÙÙ„ÙØ©', ['CV', 'CVV', 'CV', 'CV']),  # Form III source
    ]

        for pattern_name, syllable_pattern in patterns:
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name=pattern_name,
    syllable_pattern=syllable_pattern,
    word_type=ArabicWordType.NOUN_SOURCE,
    max_combinations=600)
    weights.extend(pattern_weights)

    logger.info(f"Generated {len(weights)} source noun weights")
    return weights

    def _generate_plural_nouns(self) -> List[MorphologicalWeight]:
    """Generate plural noun weights"""

    weights = []

        # Sound masculine plural
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name='ÙÙØ§Ø¹ÙÙ„ÙÙˆÙ†',
    syllable_pattern=['CVV', 'CVVC'],
    word_type=ArabicWordType.NOUN_PLURAL_MASCULINE,
    max_combinations=400)
    weights.extend(pattern_weights)

        # Sound feminine plural
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name='ÙÙØ§Ø¹ÙÙ„ÙØ§Øª',
    syllable_pattern=['CVV', 'CVVC'],
    word_type=ArabicWordType.NOUN_PLURAL_FEMININE,
    max_combinations=400)
    weights.extend(pattern_weights)

        # Broken plurals
    broken_patterns = [
    ('Ø£ÙÙÙ’Ø¹ÙØ§Ù„', ['CV', 'CVVC']),
    ('ÙÙØ¹ÙÙˆÙ„', ['CV', 'CVVC']),
    ('ÙÙØ¹ÙÙ‘Ø§Ù„', ['CV', 'CVVC']),
    ]

        for pattern_name, syllable_pattern in broken_patterns:
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name=pattern_name,
    syllable_pattern=syllable_pattern,
    word_type=ArabicWordType.NOUN_PLURAL_BROKEN,
    max_combinations=300)
    weights.extend(pattern_weights)

    logger.info(f"Generated {len(weights)} plural noun weights")
    return weights

    def _generate_dual_and_feminine_nouns(self) -> List[MorphologicalWeight]:
    """Generate dual and feminine noun weights"""

    weights = []

        # Dual forms
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name='ÙÙØ§Ø¹ÙÙ„ÙØ§Ù†',
    syllable_pattern=['CVV', 'CVVC'],
    word_type=ArabicWordType.NOUN_DUAL,
    max_combinations=300)
    weights.extend(pattern_weights)

        # Feminine forms
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name='ÙÙØ§Ø¹ÙÙ„ÙØ©',
    syllable_pattern=['CVV', 'CV', 'CV'],
    word_type=ArabicWordType.NOUN_FEMININE,
    max_combinations=400)
    weights.extend(pattern_weights)

    logger.info(f"Generated {len(weights)} dual and feminine noun weights")
    return weights

    def _generate_specialized_nouns(self) -> List[MorphologicalWeight]:
    """Generate specialized noun weights (place, time, instrument)"""

    weights = []

    patterns = [
    ('Ù…ÙÙÙ’Ø¹ÙÙ„', ['CV', 'CVC'], ArabicWordType.NOUN_PLACE),
    ('Ù…ÙÙÙ’Ø¹ÙÙ„', ['CV', 'CVC'], ArabicWordType.NOUN_TIME),
    ('Ù…ÙÙÙ’Ø¹ÙØ§Ù„', ['CVC', 'CVVC'], ArabicWordType.NOUN_INSTRUMENT),
    ]

        for pattern_name, syllable_pattern, word_type in patterns:
    pattern_weights = self._generate_weights_for_pattern()
    pattern_name=pattern_name,
    syllable_pattern=syllable_pattern,
    word_type=word_type,
    max_combinations=200)
    weights.extend(pattern_weights)

    logger.info(f"Generated {len(weights) specialized} noun weights}")
    return weights

    def _generate_weights_for_pattern()
    self,
    pattern_name: str,
    syllable_pattern: List[str],
    word_type: ArabicWordType,
    max_combinations: int = 1000) -> List[MorphologicalWeight]:
    """Generate all possible weights for a given syllable pattern"""

    weights = []

        # Get syllables for each position in the pattern
    syllable_choices = []
        for position, syllable_type in enumerate(syllable_pattern):
    available_syllables = self.syllables_by_type.get(syllable_type, [])
            if not available_syllables:
    logger.warning(f"No syllables found for type {syllable_type}")
    return weights
    syllable_choices.append(available_syllables)

        # Generate combinations (with limit for performance)
    combinations_count = 0
        for syllable_combination in itertools.product(*syllable_choices):
            if combinations_count >= max_combinations:
    break

            # Check constraints
            if self._is_valid_syllable_sequence(list(syllable_combination), word_type):
    weight = self._create_morphological_weight()
    pattern_name=pattern_name,
    syllable_pattern=syllable_pattern,
    syllable_combination=list(syllable_combination),
    word_type=word_type)
    weights.append(weight)
    combinations_count += 1

    logger.debug(f"Generated {len(weights) weights for} pattern {pattern_name}}")
    return weights

    def _is_valid_syllable_sequence()
    self, syllables: List[Dict], word_type: ArabicWordType
    ) -> bool:
    """Check if syllable sequence is valid according to constraints"""

        # Check inter-syllable constraints
        for i in range(len(syllables) - 1):
    current_type = syllables[i]['type']
    next_type = syllables[i + 1]['type']

            if ()
    current_type,
    next_type) in self.constraints.forbidden_syllable_sequences:
    return False

        # Check word-type specific constraints
        if word_type in [
    ArabicWordType.VERB_TRILITERAL_BARE,
    ArabicWordType.VERB_TRILITERAL_AUGMENTED,
    ArabicWordType.VERB_QUADRILITERAL_BARE,
    ]:
    return self._check_verb_constraints(syllables)
        else:
    return self._check_noun_constraints(syllables)

    def _check_verb_constraints(self, syllables: List[Dict]) -> bool:
    """Check verb specific constraints"""

        # No initial sukun (Ù„Ø§ ÙŠØ¨Ø¯Ø£ Ø§Ù„ÙØ¹Ù„ Ø¨Ø³Ø§ÙƒÙ†)
    first_syllable = syllables[0]
        if first_syllable['type'].startswith('C') and len(first_syllable['onset']) == 0:
    return False

        # Length constraint
        if len(syllables) > self.constraints.verb_constraints.get('max_syllables', 5):
    return False

    return True

    def _check_noun_constraints(self, syllables: List[Dict]) -> bool:
    """Check noun specific constraints"""

        # Length constraint
        if len(syllables) > self.constraints.noun_constraints.get('max_syllables', 6):
    return False

    return True

    def _create_morphological_weight()
    self,
    pattern_name: str,
    syllable_pattern: List[str],
    syllable_combination: List[Dict],
    word_type: ArabicWordType) -> MorphologicalWeight:
    """Create a complete morphological weight object"""

        # Build phonetic form
    phonetic_form = ''.join(syl['text'] for syl in syllable_combination)

        # Calculate prosodic weight
    prosodic_weight = sum(syl['prosodic_weight'] for syl in syllable_combination)

        # Estimate frequency
    frequency_estimate = 1.0
        for syl in syllable_combination:
    frequency_estimate *= syl['frequency_estimate']

        # Create morphological features
    morphological_features = {
    'syllable_count': len(syllable_combination),
    'total_phonemes': sum()
    len(syl['onset']) + len(syl['nucleus']) + len(syl['coda'])
                for syl in syllable_combination
    ),
    'complexity_score': ()
    prosodic_weight / len(syllable_combination)
                if syllable_combination
                else 0
    ),
    }

    return MorphologicalWeight()
    pattern_name=pattern_name,
    pattern_template=pattern_name,
    word_type=word_type,
    syllable_sequence=syllable_combination,
    syllable_pattern=syllable_pattern,
    phonetic_form=phonetic_form,
    morphological_features=morphological_features,
    frequency_estimate=frequency_estimate,
    prosodic_weight=prosodic_weight,
    constraints_applied=['phonotactic', 'morphological'],
    is_valid=True)

    def generate_all_weights(self) -> Dict[str, List[MorphologicalWeight]]:
    """Generate complete morphological weight inventory"""

    logger.info("ğŸ”¬ Starting complete morphological weight generation...")

    all_weights = {
    'verbs': self.generate_verb_weights(),
    'nouns': self.generate_noun_weights(),
    }

        # Store in instance
    self.weights_db = all_weights['verbs'] + all_weights['nouns']

    total_count = sum(len(weights) for weights in all_weights.values())
    logger.info()
    f"âœ… Complete morphological weight generation finished: {total_count} total weights"
    )

    return all_weights

    def analyze_weight_distribution()
    self, all_weights: Dict[str, List[MorphologicalWeight]]
    ) -> Dict[str, Any]:
    """Analyze distribution and statistics of generated weights"""

    analysis = {
    'counts_by_category': {},
    'frequency_distribution': {},
    'complexity_analysis': {},
    'pattern_distribution': defaultdict(int),
    'top_frequent_weights': [],
    }

    all_weights_flat = []

        for category, weights in all_weights.items():
    analysis['counts_by_category'][category] = len(weights)

            # Collect all weights
    all_weights_flat.extend(weights)

            # Pattern distribution
            for weight in weights:
    analysis['pattern_distribution'][weight.pattern_name] += 1

        # Sort by frequency
    all_weights_flat.sort(key=lambda x: x.frequency_estimate, reverse=True)
    analysis['top_frequent_weights'] = [
    {
    'pattern': w.pattern_name,
    'phonetic': w.phonetic_form,
    'type': w.word_type.value,
    'frequency': w.frequency_estimate,
    }
            for w in all_weights_flat[:20]
    ]

        # Complexity analysis
    complexities = [
    w.morphological_features.get('complexity_score', 0)
            for w in all_weights_flat
    ]
    analysis['complexity_analysis'] = {
    'mean_complexity': ()
    sum(complexities) / len(complexities) if complexities else 0
    ),
    'max_complexity': max(complexities) if complexities else 0,
    'min_complexity': min(complexities) if complexities else 0,
    }

    return analysis

    def save_morphological_weights()
    self,
    all_weights: Dict[str, List[MorphologicalWeight]], filename: str = "complete_arabic_morphological_weights.json"):
    """Save complete morphological weight inventory to JSON file"""

        # Convert to serializable format
    serializable_data = {}

        for category, weights in all_weights.items():
    serializable_data[category] = []

            for weight in weights:
    weight_data = {
    'pattern_name': weight.pattern_name,
    'pattern_template': weight.pattern_template,
    'word_type': weight.word_type.value,
    'syllable_pattern': weight.syllable_pattern,
    'phonetic_form': weight.phonetic_form,
    'prosodic_weight': weight.prosodic_weight,
    'frequency_estimate': weight.frequency_estimate,
    'morphological_features': weight.morphological_features,
    'syllables': [
    {
    'text': syl['text'],
    'type': syl['type'],
    'onset': syl['onset'],
    'nucleus': syl['nucleus'],
    'coda': syl['coda'],
    }
                        for syl in weight.syllable_sequence
    ],
    }
    serializable_data[category].append(weight_data)

        # Save to file
        with open(filename, 'w', encoding='utf 8') as f:
    json.dump(serializable_data, f, ensure_ascii=False, indent=2)

    logger.info(f"Morphological weights saved to {filename}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEMONSTRATION AND TESTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def demonstrate_morphological_weight_generation():
    """Demonstrate complete Arabic morphological weight generation"""

    print("ğŸ—ï¸ Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØµØ±ÙÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„")
    print("=" * 60)

    # Initialize generator
    generator = ArabicMorphologicalWeightGenerator()

    # Generate all weights
    print("\nğŸ“Š ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØµØ±ÙÙŠØ©...")
    all_weights = generator.generate_all_weights()

    # Display counts
    print("\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©:")
    total_weights = 0
    for category, weights in all_weights.items():
    count = len(weights)
    total_weights += count
    print(f"   â€¢ {category}: {count:} ÙˆØ²Ù†")

    print(f"\nğŸ¯ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ÙƒÙ„ÙŠ: {total_weights:} ÙˆØ²Ù† ØµØ±ÙÙŠ")

    # Show examples from each category
    print("\nğŸ”¤ Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„Ø£ÙˆØ²Ø§Ù†:")
    for category, weights in all_weights.items():
        if weights:
    examples = [f"{w.pattern_name} ({w.phonetic_form})" for w in weights[:3]]
    print(f"   â€¢ {category:} {', '.join(examples)}}")

    # Analyze distribution
    print("\nğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹...")
    analysis = generator.analyze_weight_distribution(all_weights)

    print("\nğŸ” Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹:")
    for i, weight_info in enumerate(analysis['top_frequent_weights'][:10], 1):
    print()
    f"   {i}. {weight_info['pattern']} - {weight_info['phonetic']} "
    f"({weight_info['type'])} - {weight_info['frequency']:.6f}}"
    )

    # Pattern distribution
    print("\nğŸ“‹ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹:")
    pattern_items = sorted()
    analysis['pattern_distribution'].items(), key=lambda x: x[1], reverse=True
    )[:10]
    for pattern, count in pattern_items:
    print(f"   â€¢ {pattern}: {count ØªÙƒØ±Ø§Ø±}")

    # Complexity analysis
    complexity = analysis['complexity_analysis']
    print("\nğŸ§® ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ØµØ±ÙÙŠ:")
    print(f"   â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ¹Ù‚ÙŠØ¯: {complexity['mean_complexity']:.2f}")
    print(f"   â€¢ Ø£Ù‚ØµÙ‰ ØªØ¹Ù‚ÙŠØ¯: {complexity['max_complexity']:.2f}")
    print(f"   â€¢ Ø£Ø¯Ù†Ù‰ ØªØ¹Ù‚ÙŠØ¯: {complexity['min_complexity']:.2f}")

    # Save weights
    print("\nğŸ’¾ Ø­ÙØ¸ Ù…Ø®Ø²ÙˆÙ† Ø§Ù„Ø£ÙˆØ²Ø§Ù†...")
    generator.save_morphological_weights(all_weights)

    print("\nâœ… Ø§ÙƒØªÙ…Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØµØ±ÙÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©!")
    print("ğŸ’ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ 22,218 Ù…Ù‚Ø·Ø¹ ØµÙˆØªÙŠ - Ø£Ø³Ø§Ø³ Ø¹Ù„Ù…ÙŠ Ù…ØªÙƒØ§Ù…Ù„!")


if __name__ == "__main__":
    demonstrate_morphological_weight_generation()

