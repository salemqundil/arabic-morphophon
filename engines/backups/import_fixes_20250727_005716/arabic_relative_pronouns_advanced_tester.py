#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Arabic Relative Pronouns Advanced Testing System
===============================================
Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙˆÙ„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

Advanced testing system for comprehensive validation of the Arabic relative
pronouns generation system with edge cases and real-world scenarios.

Author: Arabic NLP Expert Team - GitHub Copilot
Version: 1.0.0 - ADVANCED TESTING
Date: 2025-07-24
Encoding: UTF 8
"""
# pylint: disable=broad-except,unused-variable,too-many-arguments
# pylint: disable=too-few-public-methods,invalid-name,unused-argument
# flake8: noqa: E501,F401,F821,A001,F403
# mypy: disable-error-code=no-untyped def,misc


import json  # noqa: F401
import time  # noqa: F401
import random  # noqa: F401
from typing import Dict, List, Any, Tuple
from arabic_relative_pronouns_generator import (
    ArabicRelativePronounsGenerator,
)  # noqa: F401
import logging  # noqa: F401

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADVANCED TEST SUITE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class AdvancedRelativePronounTester:
    """Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙˆÙ„Ø©"""

    def __init__(self):  # type: ignore[no-untyped def]
    """TODO: Add docstring."""
    self.generator = ArabicRelativePronounsGenerator()
    self.test_results = {}

    def run_precision_tests(self) -> Dict[str, Any]:
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""

    print("ðŸŽ¯ ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©...")

        # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù„ÙƒÙ„ Ø§Ø³Ù… Ù…ÙˆØµÙˆÙ„
    precision_tests = [
            # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø¶Ù…ÙˆÙ†Ø© Ø§Ù„Ù†Ø¬Ø§Ø­
    {
    'name': 'Ø§Ù„Ø°ÙŠ - Ù…Ø°ÙƒØ± Ù…ÙØ±Ø¯',
    'syllables': ["Ø§Ù„Ù’", "Ø°ÙÙŠ"],
    'expected': 'Ø§Ù„Ø°ÙŠ',
    'category': 'basic_masculine',
    },
    {
    'name': 'Ø§Ù„ØªÙŠ - Ù…Ø¤Ù†Ø« Ù…ÙØ±Ø¯',
    'syllables': ["Ø§Ù„Ù’", "ØªÙÙŠ"],
    'expected': 'Ø§Ù„ØªÙŠ',
    'category': 'basic_feminine',
    },
    {
    'name': 'Ø§Ù„Ù„Ø°Ø§Ù† - Ù…Ø°ÙƒØ± Ù…Ø«Ù†Ù‰',
    'syllables': ["Ø§Ù„Ù’", "Ù„ÙŽ", "Ø°ÙŽØ§", "Ù†Ù"],
    'expected': 'Ø§Ù„Ù„Ø°Ø§Ù†',
    'category': 'dual_masculine',
    },
    {
    'name': 'Ø§Ù„Ù„ØªØ§Ù† - Ù…Ø¤Ù†Ø« Ù…Ø«Ù†Ù‰',
    'syllables': ["Ø§Ù„Ù’", "Ù„ÙŽ", "ØªÙŽØ§", "Ù†Ù"],
    'expected': 'Ø§Ù„Ù„ØªØ§Ù†',
    'category': 'dual_feminine',
    },
    {
    'name': 'Ø§Ù„Ø°ÙŠÙ† - Ù…Ø°ÙƒØ± Ø¬Ù…Ø¹',
    'syllables': ["Ø§Ù„Ù’", "Ø°ÙÙŠ", "Ù†ÙŽ"],
    'expected': 'Ø§Ù„Ø°ÙŠÙ†',
    'category': 'plural_masculine',
    },
    {
    'name': 'Ø§Ù„Ù„Ø§ØªÙŠ - Ù…Ø¤Ù†Ø« Ø¬Ù…Ø¹',
    'syllables': ["Ø§Ù„Ù’", "Ù„ÙŽØ§", "ØªÙÙŠ"],
    'expected': 'Ø§Ù„Ù„Ø§ØªÙŠ',
    'category': 'plural_feminine',
    },
    {
    'name': 'Ù…ÙŽÙ† - Ø¹Ø§Ù…',
    'syllables': ["Ù…ÙŽÙ†Ù’"],
    'expected': 'Ù…ÙŽÙ†',
    'category': 'general',
    },
    {
    'name': 'Ù…Ø§ - Ø¹Ø§Ù…',
    'syllables': ["Ù…ÙŽØ§"],
    'expected': 'Ù…Ø§',
    'category': 'general',
    },
    {
    'name': 'Ø£ÙŠ - Ø§Ø³ØªÙÙ‡Ø§Ù…',
    'syllables': ["Ø£ÙŽÙŠÙ‘"],
    'expected': 'Ø£ÙŠ',
    'category': 'interrogative',
    },
    {
    'name': 'Ø°Ùˆ - Ù…Ø¶Ø§Ù',
    'syllables': ["Ø°ÙÙˆ"],
    'expected': 'Ø°Ùˆ',
    'category': 'possessive',
    },
    ]

    results = {
    'total_tests': len(precision_tests),
    'passed': 0,
    'failed': 0,
    'test_details': [],
    'accuracy_by_category': {},
    }

    category_stats = {}

        for test in precision_tests:
    result = self.generator.generate_relative_pronouns_from_syllables(
    test['syllables']
    )

    test_passed = False
            if result['success'] and result['best_match']:
    generated_pronoun = result['best_match']['relative_pronoun']
    test_passed = generated_pronoun == test['expected']

    test_detail = {
    'name': test['name'],
    'syllables': test['syllables'],
    'expected': test['expected'],
    'generated': (
    result['best_match']['relative_pronoun']
                    if result['success']
                    else None
    ),
    'confidence': (
    result['best_match']['confidence'] if result['success'] else 0.0
    ),
    'passed': test_passed,
    'category': test['category'],
    }

    results['test_details'].append(test_detail)

            if test_passed:
    results['passed'] += 1
            else:
    results['failed'] += 1

            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙØ¦Ø§Øª
    category = test['category']
            if category not in category_stats:
    category_stats[category] = {'total': 0, 'passed': 0}

    category_stats[category]['total'] += 1
            if test_passed:
    category_stats[category]['passed'] += 1

        # Ø­Ø³Ø§Ø¨ Ø¯Ù‚Ø© ÙƒÙ„ ÙØ¦Ø©
        for category, stats in category_stats.items():
    accuracy = (stats['passed'] / stats['total']) * 100
    results['accuracy_by_category'][category] = {
    'accuracy': accuracy,
    'passed': stats['passed'],
    'total': stats['total'],
    }

    results['overall_accuracy'] = (results['passed'] / results['total_tests']) * 100

    return results

    def run_edge_cases_tests(self) -> Dict[str, Any]:
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©"""

    print("ðŸ” ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©...")

    edge_cases = [
            # Ù…Ù‚Ø§Ø·Ø¹ ØºÙŠØ± ØµØ­ÙŠØ­Ø©
    {'name': 'Ù…Ù‚Ø§Ø·Ø¹ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©', 'syllables': ["xyz", "abc"], 'should_fail': True},
    {'name': 'Ù…Ù‚Ø§Ø·Ø¹ ÙØ§Ø±ØºØ©', 'syllables': [], 'should_fail': True},
    {'name': 'Ù…Ù‚Ø·Ø¹ ÙˆØ§Ø­Ø¯ ØºÙŠØ± ØµØ­ÙŠØ­', 'syllables': ["Ù‚Ø±Øµ"], 'should_fail': True},
            # Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø§Ù„ØªØ´ÙƒÙŠÙ„
    {
    'name': 'Ø®Ø·Ø£ ÙÙŠ ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø°ÙŠ',
    'syllables': ["Ø§Ù„Ù’", "Ø°ÙÙˆ"],
    'should_fail': True,
    },  # Ø®Ø·Ø£: Ø°ÙÙˆ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø°ÙÙŠ
    {
    'name': 'Ù†Ù‚Øµ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹',
    'syllables': ["Ø§Ù„Ù’"],
    'should_fail': True,
    },  # ØºÙŠØ± Ù…ÙƒØªÙ…Ù„
            # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØªØ­Ù…Ù„ Ø§Ù„Ø¶ØºØ·
    {
    'name': 'Ù…Ù‚Ø§Ø·Ø¹ Ø²Ø§Ø¦Ø¯Ø© ÙƒØ«ÙŠØ±Ø©',
    'syllables': ["Ø§Ù„Ù’", "Ø°ÙÙŠ", "Ù†ÙŽ", "ØªÙŽØ§", "Ù…ÙÙˆ", "Ø³ÙŽØ§", "Ù„ÙÙŠ"],
    'should_fail': True,
    },
            # ØªØ¨Ø§Ø¯ÙŠÙ„ ØµØ­ÙŠØ­Ø© ÙˆÙ„ÙƒÙ† ØºÙŠØ± Ù…Ø±ØªØ¨Ø©
    {
    'name': 'ØªØ±ØªÙŠØ¨ Ø®Ø§Ø·Ø¦ Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù„Ø°Ø§Ù†',
    'syllables': ["Ø°ÙŽØ§", "Ø§Ù„Ù’", "Ù†Ù", "Ù„ÙŽ"],  # ØªØ±ØªÙŠØ¨ Ø®Ø§Ø·Ø¦
    'should_fail': True,
    },
    ]

    results = {
    'total_tests': len(edge_cases),
    'expected_failures': 0,
    'unexpected_successes': 0,
    'expected_behaviors': 0,
    'test_details': [],
    }

        for test in edge_cases:
    result = self.generator.generate_relative_pronouns_from_syllables(
    test['syllables']
    )

    expected_to_fail = test.get('should_fail', False)
    actually_failed = not result['success']

    behavior_correct = (expected_to_fail and actually_failed) or (
    not expected_to_fail and not actually_failed
    )

    test_detail = {
    'name': test['name'],
    'syllables': test['syllables'],
    'expected_to_fail': expected_to_fail,
    'actually_failed': actually_failed,
    'behavior_correct': behavior_correct,
    'result': result,
    }

    results['test_details'].append(test_detail)

            if behavior_correct:
    results['expected_behaviors'] += 1
                if expected_to_fail:
    results['expected_failures'] += 1
            else:
                if not expected_to_fail and actually_failed:
    pass  # unexpected failure
                else:
    results['unexpected_successes'] += 1

    results['robustness_score'] = (
    results['expected_behaviors'] / results['total_tests']
    ) * 100

    return results

    def run_performance_tests(self) -> Dict[str, Any]:
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø³Ø±Ø¹Ø©"""

    print("âš¡ ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡...")

        # ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    test_syllables = [
    ["Ø§Ù„Ù’", "Ø°ÙÙŠ"],
    ["Ø§Ù„Ù’", "ØªÙÙŠ"],
    ["Ù…ÙŽÙ†Ù’"],
    ["Ù…ÙŽØ§"],
    ["Ø£ÙŽÙŠÙ‘"],
    ["Ø§Ù„Ù’", "Ù„ÙŽ", "Ø°ÙŽØ§", "Ù†Ù"],
    ["Ø§Ù„Ù’", "Ù„ÙŽ", "ØªÙŽØ§", "Ù†Ù"],
    ["Ø§Ù„Ù’", "Ø°ÙÙŠ", "Ù†ÙŽ"],
    ["Ø§Ù„Ù’", "Ù„ÙŽØ§", "ØªÙÙŠ"],
    ]

        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø³Ø±Ø¹Ø© - 100 ØªØ´ØºÙŠÙ„
    iterations = 100
    total_time = 0.0
    successful_runs = 0

    print(f"   ðŸƒ ØªØ´ØºÙŠÙ„ {iterations} Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±Ø¹Ø©...")

        for i in range(iterations):
    syllables = random.choice(test_syllables)

    start_time = time.time()
    result = self.generator.generate_relative_pronouns_from_syllables(syllables)
    end_time = time.time()

    execution_time = end_time - start_time
    total_time += execution_time

            if result['success']:
    successful_runs += 1

    average_time = total_time / iterations
    success_rate = (successful_runs / iterations) * 100

        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ø«Ù‚ÙŠÙ„
    print("   ðŸ“Š Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ø«Ù‚ÙŠÙ„...")
    heavy_load_iterations = 1000

    heavy_start = time.time()
        for _ in range(heavy_load_iterations):
    syllables = random.choice(test_syllables)
    self.generator.generate_relative_pronouns_from_syllables(syllables)
    heavy_end = time.time()

    heavy_load_time = heavy_end - heavy_start
    heavy_load_avg = heavy_load_time / heavy_load_iterations

    performance_results = {
    'speed_test': {
    'iterations': iterations,
    'total_time_seconds': total_time,
    'average_time_ms': average_time * 1000,
    'success_rate': success_rate,
    'calls_per_second': iterations / total_time if total_time > 0 else 0,
    },
    'heavy_load_test': {
    'iterations': heavy_load_iterations,
    'total_time_seconds': heavy_load_time,
    'average_time_ms': heavy_load_avg * 1000,
    'calls_per_second': (
    heavy_load_iterations / heavy_load_time
                    if heavy_load_time > 0
                    else 0
    ),
    },
    'performance_grade': self._grade_performance(average_time * 1000),
    }

    return performance_results

    def run_stress_tests(self) -> Dict[str, Any]:
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¶ØºØ· ÙˆØ§Ù„Ø«Ø¨Ø§Øª"""

    print("ðŸ’ª ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¶ØºØ·...")

    stress_results = {
    'memory_consistency': self._test_memory_consistency(),
    'repeated_calls': self._test_repeated_calls(),
    'concurrent_simulation': self._test_concurrent_simulation(),
    }

    return stress_results

    def _test_memory_consistency(self) -> Dict[str, Any]:
    """Ø§Ø®ØªØ¨Ø§Ø± Ø«Ø¨Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""

    test_syllables = ["Ø§Ù„Ù’", "Ø°ÙÙŠ"]
    results = []

        for i in range(50):
    result = self.generator.generate_relative_pronouns_from_syllables(
    test_syllables
    )
            if result['success']:
    results.append(result['best_match']['relative_pronoun'])

    unique_results = set(results)
    consistency = len(unique_results) == 1 if results else False

    return {
    'total_calls': 50,
    'successful_calls': len(results),
    'unique_results': len(unique_results),
    'consistent': consistency,
    'consistency_percentage': 100 if consistency else 0,
    }

    def _test_repeated_calls(self) -> Dict[str, Any]:
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©"""

    all_pronouns_syllables = [
    ["Ø§Ù„Ù’", "Ø°ÙÙŠ"],  # Ø§Ù„Ø°ÙŠ
    ["Ø§Ù„Ù’", "ØªÙÙŠ"],  # Ø§Ù„ØªÙŠ
    ["Ù…ÙŽÙ†Ù’"],  # Ù…Ù†
    ["Ù…ÙŽØ§"],  # Ù…Ø§
    ["Ø£ÙŽÙŠÙ‘"],  # Ø£ÙŠ
    ]

    total_calls = 0
    successful_calls = 0

        for _ in range(20):  # 20 Ø¯ÙˆØ±Ø©
            for syllables in all_pronouns_syllables:
    total_calls += 1
    result = self.generator.generate_relative_pronouns_from_syllables(
    syllables
    )
                if result['success']:
    successful_calls += 1

    return {
    'total_calls': total_calls,
    'successful_calls': successful_calls,
    'success_rate': (successful_calls / total_calls) * 100,
    'stability_score': (
    100
                if successful_calls == total_calls
                else (successful_calls / total_calls) * 100
    ),
    }

    def _test_concurrent_simulation(self) -> Dict[str, Any]:
    """Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©"""

        import threading  # noqa: F401
        import queue  # noqa: F401

    results_queue = queue.Queue()
    test_syllables = [["Ø§Ù„Ù’", "Ø°ÙÙŠ"], ["Ø§Ù„Ù’", "ØªÙÙŠ"], ["Ù…ÙŽÙ†Ù’"], ["Ù…ÙŽØ§"]]

        def worker():  # type: ignore[no-untyped def]
    """TODO: Add docstring."""
            for syllables in test_syllables:
    result = self.generator.generate_relative_pronouns_from_syllables(
    syllables
    )
    results_queue.put(result['success'])

        # ØªØ´ØºÙŠÙ„ 5 threads Ù…ØªØ²Ø§Ù…Ù†Ø©
    threads = []
        for _ in range(5):
    thread = threading.Thread(target=worker)
    threads.append(thread)
    thread.start()

        # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ threads
        for thread in threads:
    thread.join()

        # Ø¬Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    successes = 0
    total = 0

        while not results_queue.empty():
    total += 1
            if results_queue.get():
    successes += 1

    return {
    'total_concurrent_calls': total,
    'successful_concurrent_calls': successes,
    'concurrent_success_rate': (successes / total) * 100 if total > 0 else 0,
    'thread_safety_score': (
    100 if successes == total else (successes / total) * 100
    ),
    }

    def _grade_performance(self, avg_time_ms: float) -> str:
    """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡"""

        if avg_time_ms < 1.0:
    return "Ù…Ù…ØªØ§Ø² (A+)"
        elif avg_time_ms < 5.0:
    return "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹ (A)"
        elif avg_time_ms < 10.0:
    return "Ø¬ÙŠØ¯ (B)"
        elif avg_time_ms < 50.0:
    return "Ù…Ù‚Ø¨ÙˆÙ„ (C)"
        else:
    return "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† (D)"

    def run_comprehensive_tests(self) -> Dict[str, Any]:
    """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""

    print("ðŸ§ª Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙˆÙ„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    print("=" * 60)

    all_results = {
    'test_timestamp': time.time(),
    'test_date': time.strftime('%Y-%m %d %H:%M:%S'),
    'precision_tests': self.run_precision_tests(),
    'edge_cases_tests': self.run_edge_cases_tests(),
    'performance_tests': self.run_performance_tests(),
    'stress_tests': self.run_stress_tests(),
    }

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
    overall_score = self._calculate_overall_test_score(all_results)
    all_results['overall_assessment'] = overall_score

    return all_results

    def _calculate_overall_test_score(self, results: Dict[str, Any]) -> Dict[str, Any]:
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""

    precision_score = results['precision_tests']['overall_accuracy']
    robustness_score = results['edge_cases_tests']['robustness_score']

        # Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø±Ø¹Ø©
    avg_time = results['performance_tests']['speed_test']['average_time_ms']
        if avg_time < 1.0:
    performance_score = 100
        elif avg_time < 5.0:
    performance_score = 90
        elif avg_time < 10.0:
    performance_score = 80
        else:
    performance_score = 60

    stability_score = results['stress_tests']['repeated_calls']['stability_score']

    overall_score = (
    precision_score * 0.4
    + robustness_score * 0.2
    + performance_score * 0.2
    + stability_score * 0.2
    )

    return {
    'overall_score': overall_score,
    'grade': self._get_overall_grade(overall_score),
    'component_scores': {
    'precision': precision_score,
    'robustness': robustness_score,
    'performance': performance_score,
    'stability': stability_score,
    },
    'recommendations': self._get_test_recommendations(results),
    }

    def _get_overall_grade(self, score: float) -> str:
    """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ"""

        if score >= 95:
    return "Ù…Ù…ØªØ§Ø² (A+)"
        elif score >= 90:
    return "Ù…Ù…ØªØ§Ø² (A)"
        elif score >= 85:
    return "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹ (B+)"
        elif score >= 80:
    return "Ø¬ÙŠØ¯ (B)"
        elif score >= 70:
    return "Ù…Ù‚Ø¨ÙˆÙ„ (C)"
        else:
    return "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† (D)"

    def _get_test_recommendations(self, results: Dict[str, Any]) -> List[str]:
    """ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†"""

    recommendations = []

    precision_score = results['precision_tests']['overall_accuracy']
        if precision_score < 90:
    recommendations.append("ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙˆÙ„Ø©")

    performance = results['performance_tests']['speed_test']['average_time_ms']
        if performance > 10:
    recommendations.append("ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")

    robustness = results['edge_cases_tests']['robustness_score']
        if robustness < 85:
    recommendations.append("ØªØ¹Ø²ÙŠØ² Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠØ©")

        if not recommendations:
    recommendations.append("Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ¹Ù…Ù„ Ø¨ÙƒÙØ§Ø¡Ø© Ù…Ù…ØªØ§Ø²Ø©")

    return recommendations


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN TESTING EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def main():  # type: ignore[no-untyped def]
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""

    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    tester = AdvancedRelativePronounTester()

    # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    results = tester.run_comprehensive_tests()

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print("\nðŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
    print(
    f"   Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {results['overall_assessment']['overall_score']:.1f/100}"
    )  # noqa: E501
    print(f"   Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {results['overall_assessment']['grade']}")

    print("\nðŸŽ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¯Ù‚Ø©:")
    print(f"   Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {results['precision_tests']['overall_accuracy']:.1f}%")
    print(
    f"   Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {results['precision_tests']['passed']/{results['precision_tests']['total_tests']}}"
    )  # noqa: E501

    print("\nâš¡ Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡:")
    print(
    f"   Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {results['performance_tests']['speed_test']['average_time_ms']:.2f ms}"
    )  # noqa: E501
    print(f"   Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {results['performance_tests']['performance_grade']}")

    print("\nðŸ” Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø«Ø¨Ø§Øª:")
    print(f"   Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©: {results['edge_cases_tests']['robustness_score']:.1f}%")
    print(
    f"   Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±: {results['stress_tests']['repeated_calls']['stability_score']:.1f%}"
    )  # noqa: E501

    print("\nðŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
    for rec in results['overall_assessment']['recommendations']:
    print(f"   â€¢ {rec}")

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    with open(
    "arabic_relative_pronouns_advanced_test_results.json", 'w', encoding='utf 8'
    ) as f:
    json.dump(results, f, ensure_ascii=False, indent=2, default=str)

    print(
    "\nðŸ’¾ ØªÙ… Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙÙŠ: arabic_relative_pronouns_advanced_test_results.json"
    )  # noqa: E501
    print("âœ… Ø§ÙƒØªÙ…Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©!")


if __name__ == "__main__":
    main()
