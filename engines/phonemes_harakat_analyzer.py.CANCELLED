#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§± Ù…Ø­Ù„Ù„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª - Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØ§Ø¹Ù„ Ø§Ù„ØµØ±ÙÙŠ,
    Phonemes and Harakat Analyzer - Morphological Reactor Database Core
"""
# pylint: disable=broad-except,unused-variable,too-many-arguments
# pylint: disable=too-few-public-methods,invalid-name,unused-argument
# flake8: noqa: E501,F401,F821,A001,F403
# mypy: disable-error-code=no-untyped def,misc
    import json  # noqa: F401
    import logging  # noqa: F401
    from typing import Dict, List, Optional, Any
    from dataclasses import dataclass  # noqa: F401

# Setup logging,
    logger = logging.getLogger(__name__)


@dataclass,
    class Phoneme:
    """ğŸ”¤ ÙƒÙ„Ø§Ø³ Ø§Ù„ÙÙˆÙ†ÙŠÙ… (Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©)"""

    letter: str,
    type: str  # ØµØ§Ù…ØªØŒ ØµØ§Ø¦ØªØŒ ØµØ§Ø¦Øª Ø·ÙˆÙŠÙ„,
    articulation_point: str  # Ù…Ø®Ø±Ø¬,
    hardness: str  # ØµÙ„Ø§Ø¨Ø©,
    function: str  # ÙˆØ¸ÙŠÙØ© ØµØ±ÙÙŠØ©,
    morphological_weight: float = 0.0,
    frequency_score: float = 0.0


@dataclass,
    class Haraka:
    """ğŸ”¢ ÙƒÙ„Ø§Ø³ Ø§Ù„Ø­Ø±ÙƒØ©"""

    symbol: str,
    name: str,
    type: str  # Ù†ÙˆØ¹ Ø§Ù„Ø­Ø±ÙƒØ©,
    clarity: str  # ÙˆØ¶ÙˆØ­,
    role: str  # Ø¯ÙˆØ± ØµØ±ÙÙŠ,
    phonetic_weight: float = 0.0,
    grammatical_significance: float = 0.0,
    class PhonemesHarakatAnalyzer:
    """ğŸ§± Ù…Ø­Ù„Ù„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª - Ù†ÙˆØ§Ø© Ø§Ù„Ù…ÙØ§Ø¹Ù„ Ø§Ù„ØµØ±ÙÙŠ"""

    def __init__(self):  # type: ignore[no-untyped def]
        """TODO: Add docstring."""
        self.phonemes = self._initialize_phonemes()
        self.harakat = self._initialize_harakat()
        self.phoneme_combinations = self._initialize_combinations()
        self.morphological_rules = self._initialize_morphological_rules()

    def _initialize_phonemes(self) -> List[Phoneme]:
        """ğŸ”¤ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª"""
        phonemes_data = [
            {
                "letter": "Ø¨",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø´ÙÙˆÙŠ",
                "hardness": "ØµÙ„Ø¨",
                "function": "Ù…Ø¨Ù†ÙŠ Ù„Ù„Ø¬Ø°Ø±",
                "morphological_weight": 0.85,
                "frequency_score": 0.78,
            },
            {
                "letter": "Øª",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø·Ø±Ù Ø§Ù„Ù„Ø³Ø§Ù†",
                "hardness": "ØµÙ„Ø¨",
                "function": "Ù…Ø¨Ù†ÙŠ Ù„Ù„Ø¬Ø°Ø±",
                "morphological_weight": 0.88,
                "frequency_score": 0.82,
            },
            {
                "letter": "Ùƒ",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ù„Ù‡ÙˆÙŠ",
                "hardness": "ØµÙ„Ø¨",
                "function": "Ù…Ø¨Ù†ÙŠ Ù„Ù„Ø¬Ø°Ø±",
                "morphological_weight": 0.90,
                "frequency_score": 0.95,
            },
            {
                "letter": "Ø¯",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø·Ø±Ù Ø§Ù„Ù„Ø³Ø§Ù†",
                "hardness": "ØµÙ„Ø¨",
                "function": "Ù…Ø¨Ù†ÙŠ Ù„Ù„Ø¬Ø°Ø±",
                "morphological_weight": 0.83,
                "frequency_score": 0.75,
            },
            {
                "letter": "Ø³",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø£Ø³Ù†Ø§Ù†",
                "hardness": "ØµÙ„Ø¨ Ù…ØªÙˆØ³Ø·",
                "function": "Ù…Ø¨Ù†ÙŠ Ù„Ù„Ø¬Ø°Ø±",
                "morphological_weight": 0.80,
                "frequency_score": 0.72,
            },
            {
                "letter": "Ø£",
                "type": "ØµØ§Ø¦Øª",
                "articulation_point": "Ø­Ù„Ù‚ÙŠ",
                "hardness": "Ù„ÙŠÙ†",
                "function": "Ù…Ø­ÙØ² ØµØ±ÙÙŠ",
                "morphological_weight": 0.95,
                "frequency_score": 0.90,
            },
            {
                "letter": "Ø§",
                "type": "ØµØ§Ø¦Øª Ø·ÙˆÙŠÙ„",
                "articulation_point": "ÙÙ…ÙŠ",
                "hardness": "Ù„ÙŠÙ†",
                "function": "Ù…Ø¯ ØµÙˆØªÙŠ",
                "morphological_weight": 0.92,
                "frequency_score": 0.98,
            },
            {
                "letter": "Ùˆ",
                "type": "ØµØ§Ø¦Øª Ø·ÙˆÙŠÙ„",
                "articulation_point": "Ø´ÙÙˆÙŠ",
                "hardness": "Ù„ÙŠÙ†",
                "function": "Ù…Ø¯ ÙˆØ±Ø¨Ø·",
                "morphological_weight": 0.88,
                "frequency_score": 0.85,
            },
            {
                "letter": "ÙŠ",
                "type": "ØµØ§Ø¦Øª Ø·ÙˆÙŠÙ„",
                "articulation_point": "ÙˆØ³Ø· Ø§Ù„Ù„Ø³Ø§Ù†",
                "hardness": "Ù„ÙŠÙ†",
                "function": "Ù…Ø¯ ÙˆØ±Ø¨Ø·",
                "morphological_weight": 0.87,
                "frequency_score": 0.88,
            },
            {
                "letter": "Ù†",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø®ÙŠØ´ÙˆÙ…",
                "hardness": "Ù…Ø®ÙÙ",
                "function": "Ø²ÙŠØ§Ø¯Ø© ØµØ±ÙÙŠØ©",
                "morphological_weight": 0.75,
                "frequency_score": 0.80,
            },
            {
                "letter": "Ù…",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø´ÙÙˆÙŠ",
                "hardness": "Ù…Ø®ÙÙ",
                "function": "Ø²ÙŠØ§Ø¯Ø© ØµØ±ÙÙŠØ©",
                "morphological_weight": 0.78,
                "frequency_score": 0.83,
            },
            {
                "letter": "Ù„",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø·Ø±Ù Ø§Ù„Ù„Ø³Ø§Ù†",
                "hardness": "Ù…Ø§Ø¦Ø¹",
                "function": "Ø±Ø¨Ø· ÙˆØªØ¹Ø±ÙŠÙ",
                "morphological_weight": 0.70,
                "frequency_score": 0.95,
            },
            {
                "letter": "Ø±",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø·Ø±Ù Ø§Ù„Ù„Ø³Ø§Ù†",
                "hardness": "Ù…ÙƒØ±Ø±",
                "function": "Ù…Ø¨Ù†ÙŠ Ù„Ù„Ø¬Ø°Ø±",
                "morphological_weight": 0.82,
                "frequency_score": 0.85,
            },
            {
                "letter": "Ø¹",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø­Ù„Ù‚ÙŠ",
                "hardness": "Ø§Ø­ØªÙƒØ§ÙƒÙŠ",
                "function": "Ù…Ø¨Ù†ÙŠ Ù„Ù„Ø¬Ø°Ø±",
                "morphological_weight": 0.85,
                "frequency_score": 0.70,
            },
            {
                "letter": "Ù",
                "type": "ØµØ§Ù…Øª",
                "articulation_point": "Ø´ÙÙˆÙŠ Ø£Ø³Ù†Ø§Ù†ÙŠ",
                "hardness": "Ø§Ø­ØªÙƒØ§ÙƒÙŠ",
                "function": "Ù…Ø¨Ù†ÙŠ Ù„Ù„Ø¬Ø°Ø±",
                "morphological_weight": 0.83,
                "frequency_score": 0.77,
            },
        ]

        phonemes = []
        for p in phonemes_data:
            phoneme = Phoneme()
                letter=p["letter"],
                type=p["type"],
                articulation_point=p["articulation_point"],
                hardness=p["hardness"],
                function=p["function"],
                morphological_weight=p["morphological_weight"],
                frequency_score=p["frequency_score"])
            phonemes.append(phoneme)

        return phonemes,
    def _initialize_harakat(self) -> List[Haraka]:
        """ğŸ”¢ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø±ÙƒØ§Øª"""
        harakat_data = [
            {
                "symbol": "Ù",
                "name": "ÙØªØ­Ø©",
                "type": "Ù†ØµÙ ÙÙˆÙ†ÙŠÙ…",
                "clarity": "Ù…ØªÙˆØ³Ø·",
                "role": "ØªØ­Ø±ÙŠÙƒ Ø§Ù„Ø¬Ø°Ø±",
                "phonetic_weight": 0.80,
                "grammatical_significance": 0.75,
            },
            {
                "symbol": "Ù",
                "name": "ÙƒØ³Ø±Ø©",
                "type": "Ù†ØµÙ ÙÙˆÙ†ÙŠÙ…",
                "clarity": "Ø­Ø§Ø¯",
                "role": "Ø¯Ù„Ø§Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ¯Ø±/Ø§Ù„Ø§Ø³Ù…",
                "phonetic_weight": 0.85,
                "grammatical_significance": 0.90,
            },
            {
                "symbol": "Ù",
                "name": "Ø¶Ù…Ø©",
                "type": "Ù†ØµÙ ÙÙˆÙ†ÙŠÙ…",
                "clarity": "ØºÙ„ÙŠØ¸",
                "role": "Ø¹Ù„Ø§Ù…Ø© Ù„Ù„ÙØ§Ø¹Ù„ Ø£Ùˆ Ø§Ù„Ù…Ø¶Ø§Ø±Ø¹",
                "phonetic_weight": 0.82,
                "grammatical_significance": 0.88,
            },
            {
                "symbol": "Ù’",
                "name": "Ø³ÙƒÙˆÙ†",
                "type": "Ø³Ø§Ù„Ø¨ Ø­Ø±ÙƒØ©",
                "clarity": "Ø§Ù†ØºÙ„Ø§Ù‚",
                "role": "ÙˆÙ‚Ù ÙˆØªØ«Ø¨ÙŠØª",
                "phonetic_weight": 0.60,
                "grammatical_significance": 0.70,
            },
            {
                "symbol": "Ù‘",
                "name": "Ø´Ø¯Ø©",
                "type": "ØªØ¶Ø§Ø¹Ù",
                "clarity": "Ù…Ø¶Ø§Ø¹Ù",
                "role": "ØªÙ‚ÙˆÙŠØ© ÙˆØªÙƒØ±Ø§Ø±",
                "phonetic_weight": 0.95,
                "grammatical_significance": 0.85,
            },
            {
                "symbol": "Ù‹",
                "name": "ØªÙ†ÙˆÙŠÙ† ÙØªØ­",
                "type": "ØªÙ†ÙˆÙŠÙ†",
                "clarity": "Ø®ÙÙŠÙ",
                "role": "Ù†ÙƒØ±Ø© Ù…Ù†ØµÙˆØ¨Ø©",
                "phonetic_weight": 0.65,
                "grammatical_significance": 0.92,
            },
            {
                "symbol": "Ù",
                "name": "ØªÙ†ÙˆÙŠÙ† ÙƒØ³Ø±",
                "type": "ØªÙ†ÙˆÙŠÙ†",
                "clarity": "Ø®ÙÙŠÙ",
                "role": "Ù†ÙƒØ±Ø© Ù…Ø¬Ø±ÙˆØ±Ø©",
                "phonetic_weight": 0.65,
                "grammatical_significance": 0.92,
            },
            {
                "symbol": "ÙŒ",
                "name": "ØªÙ†ÙˆÙŠÙ† Ø¶Ù…",
                "type": "ØªÙ†ÙˆÙŠÙ†",
                "clarity": "Ø®ÙÙŠÙ",
                "role": "Ù†ÙƒØ±Ø© Ù…Ø±ÙÙˆØ¹Ø©",
                "phonetic_weight": 0.65,
                "grammatical_significance": 0.92,
            },
        ]

        harakat = []
        for h in harakat_data:
            haraka = Haraka()
                symbol=h["symbol"],
                name=h["name"],
                type=h["type"],
                clarity=h["clarity"],
                role=h["role"],
                phonetic_weight=h["phonetic_weight"],
                grammatical_significance=h["grammatical_significance"])
            harakat.append(haraka)

        return harakat,
    def _initialize_combinations(self) -> Dict[str, Dict]:
        """ğŸ”— ØªÙ‡ÙŠØ¦Ø© ØªØ±ÙƒÙŠØ¨Ø§Øª Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª"""
        return {
            "consonant_vowel": {
                "CV": {"weight": 1.0, "type": "Ù…Ù‚Ø·Ø¹ Ø®ÙÙŠÙ", "frequency": 0.95},
                "CVC": {"weight": 2.0, "type": "Ù…Ù‚Ø·Ø¹ Ø«Ù‚ÙŠÙ„", "frequency": 0.85},
                "CVV": {"weight": 2.0, "type": "Ù…Ù‚Ø·Ø¹ Ø·ÙˆÙŠÙ„", "frequency": 0.75},
                "CVVC": {"weight": 3.0, "type": "Ù…Ù‚Ø·Ø¹ ÙØ§Ø¦Ù‚", "frequency": 0.45},
            },
            "morphological_templates": {
                "ÙØ¹Ù„": {
                    "pattern": "CaCaC",
                    "phonemes": ["C", "a", "C", "a", "C"],
                    "weight": 0.95,
                },
                "ÙØ§Ø¹Ù„": {
                    "pattern": "CaaCiC",
                    "phonemes": ["C", "aa", "C", "i", "C"],
                    "weight": 0.88,
                },
                "Ù…ÙØ¹ÙˆÙ„": {
                    "pattern": "mafCuuC",
                    "phonemes": ["m", "a", "C", "uu", "C"],
                    "weight": 0.82,
                },
                "Ø§Ø³ØªÙØ¹Ù„": {
                    "pattern": "istafCaC",
                    "phonemes": ["i", "s", "t", "a", "C", "a", "C"],
                    "weight": 0.65,
                },
            },
        }

    def _initialize_morphological_rules(self) -> Dict[str, Any]:
        """ğŸ“‹ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØµØ±ÙÙŠØ© Ù„Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª"""
        return {
            "assimilation_rules": {
                "sun_letters": [
                    "Øª",
                    "Ø«",
                    "Ø¯",
                    "Ø°",
                    "Ø±",
                    "Ø²",
                    "Ø³",
                    "Ø´",
                    "Øµ",
                    "Ø¶",
                    "Ø·",
                    "Ø¸",
                    "Ù„",
                    "Ù†",
                ],
                "moon_letters": [
                    "Ø£",
                    "Ø¨",
                    "Ø¬",
                    "Ø­",
                    "Ø®",
                    "Ø¹",
                    "Øº",
                    "Ù",
                    "Ù‚",
                    "Ùƒ",
                    "Ù…",
                    "Ù‡",
                    "Ùˆ",
                    "ÙŠ",
                ],
            },
            "vowel_harmony": {
                "front_vowels": ["Ù", "ÙŠ"],
                "back_vowels": ["Ù", "Ùˆ"],
                "central_vowels": ["Ù", "Ø§"],
            },
            "syllable_rules": {
                "initial_clusters": ["bl", "br", "dr", "kr"],
                "final_clusters": ["nt", "nd", "st", "kt"],
                "forbidden_sequences": ["aa", "ii", "uu"],
            },
        }

    def analyze_phonetic_structure(self, word: str) -> Dict[str, Any]:
        """ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµÙˆØªÙŠØ© Ù„Ù„ÙƒÙ„Ù…Ø©"""
        try:
            phonetic_analysis = {
                "word": word,
                "phonemes": [],
                "harakat": [],
                "syllable_structure": [],
                "phonetic_weight": 0.0,
                "morphological_complexity": 0.0,
                "assimilation_effects": [],
            }

            # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ø­Ø±Ù ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø©,
    for i, char in enumerate(word):
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙÙˆÙ†ÙŠÙ…,
    phoneme = self.find_phoneme(char)
                if phoneme:
                    phonetic_analysis["phonemes"].append()
                        {
                            "position": i,
                            "letter": char,
                            "type": phoneme.type,
                            "articulation_point": phoneme.articulation_point,
                            "function": phoneme.function,
                            "weight": phoneme.morphological_weight,
                        }
                    )
                    phonetic_analysis["phonetic_weight"] += phoneme.morphological_weight

                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø­Ø±ÙƒØ©,
    haraka = self.find_haraka(char)
                if haraka:
                    phonetic_analysis["harakat"].append()
                        {
                            "position": i,
                            "symbol": char,
                            "name": haraka.name,
                            "role": haraka.role,
                            "grammatical_significance": haraka.grammatical_significance,
                        }
                    )

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ù‚Ø·Ø¹ÙŠØ©,
    phonetic_analysis["syllable_structure"] = self._extract_syllable_structure()
                word
            )

            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ØµØ±ÙÙŠ,
    phonetic_analysis["morphological_complexity"] = ()
                self._calculate_morphological_complexity()
                    phonetic_analysis["phonemes"], phonetic_analysis["harakat"]
                )
            )

            # ØªØ­Ù„ÙŠÙ„ ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¥Ø¯ØºØ§Ù…,
    phonetic_analysis["assimilation_effects"] = self._analyze_assimilation(word)

            return {"status": "success", "analysis": phonetic_analysis}

        except Exception as e:
            logger.error(f"Error in phonetic analysis: {e}")
            return {"status": "error", "message": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ: {str(e)}"}

    def find_phoneme(self, letter: str) -> Optional[Phoneme]:
        """ğŸ”¤ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙÙˆÙ†ÙŠÙ…"""
        for phoneme in self.phonemes:
            if phoneme.letter == letter:
                return phoneme,
    return None,
    def find_haraka(self, symbol: str) -> Optional[Haraka]:
        """ğŸ”¢ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø­Ø±ÙƒØ©"""
        for haraka in self.harakat:
            if haraka.symbol == symbol:
                return haraka,
    return None,
    def _extract_syllable_structure(self, word: str) -> List[Dict]:
        """ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ù‚Ø·Ø¹ÙŠØ©"""
        syllables = []
        current_syllable = ""

        i = 0,
    while i < len(word):
            char = word[i]
            phoneme = self.find_phoneme(char)
            self.find_haraka(char)

            if phoneme:
                if phoneme.type in ["ØµØ§Ù…Øª"]:
                    current_syllable += "C"
                elif phoneme.type in ["ØµØ§Ø¦Øª", "ØµØ§Ø¦Øª Ø·ÙˆÙŠÙ„"]:
                    current_syllable += "V" if phoneme.type == "ØµØ§Ø¦Øª" else "VV"

            # ØªØ­Ø¯ÙŠØ¯ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…Ù‚Ø·Ø¹,
    if i == len(word) - 1 or self._is_syllable_boundary(word, i):
                if current_syllable:
                    syllable_weight = self.phoneme_combinations.get()
                        "consonant_vowel", {}
                    ).get(current_syllable, {"weight": 1.0, "type": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"})

                    syllables.append()
                        {
                            "pattern": current_syllable,
                            "type": syllable_weight["type"],
                            "weight": syllable_weight["weight"],
                            "position": len(syllables),
                        }
                    )
                    current_syllable = ""

            i += 1,
    return syllables,
    def _is_syllable_boundary(self, word: str, position: int) -> bool:
        """ğŸ” ØªØ­Ø¯ÙŠØ¯ Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""
        if position >= len(word) - 1:
            return True,
    current_char = word[position]
        next_char = word[position + 1]

        current_phoneme = self.find_phoneme(current_char)
        next_phoneme = self.find_phoneme(next_char)

        # Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø³ÙŠØ·Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹,
    if current_phoneme and next_phoneme:
            if ()
                current_phoneme.type in ["ØµØ§Ø¦Øª", "ØµØ§Ø¦Øª Ø·ÙˆÙŠÙ„"]
                and next_phoneme.type == "ØµØ§Ù…Øª"
            ):
                return True,
    return False,
    def _calculate_morphological_complexity()
        self, phonemes: List[Dict], harakat: List[Dict]
    ) -> float:
        """âš–ï¸ Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ØµØ±ÙÙŠ"""
        complexity = 0.0

        # ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª,
    for phoneme in phonemes:
            if phoneme["type"] == "ØµØ§Ù…Øª":
                complexity += 0.5,
    elif phoneme["type"] in ["ØµØ§Ø¦Øª Ø·ÙˆÙŠÙ„"]:
                complexity += 0.3,
    else:
                complexity += 0.2

        # ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø­Ø±ÙƒØ§Øª,
    for haraka in harakat:
            complexity += haraka["grammatical_significance"] * 0.2

        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©,
    total_elements = len(phonemes) + len(harakat)
        return complexity / total_elements if total_elements > 0 else 0.0,
    def _analyze_assimilation(self, word: str) -> List[Dict]:
        """ğŸ”„ ØªØ­Ù„ÙŠÙ„ ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¥Ø¯ØºØ§Ù…"""
        assimilation_effects = []

        # ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£Ù„ Ø§Ù„ØªØ¹Ø±ÙŠÙ,
    if word.startswith("Ø§Ù„"):
            third_letter = word[2] if len(word) > 2 else ""
            if ()
                third_letter,
    in self.morphological_rules["assimilation_rules"]["sun_letters"]
            ):
                assimilation_effects.append()
                    {
                        "type": "Ø¥Ø¯ØºØ§Ù… Ø´Ù…Ø³ÙŠ",
                        "position": 1,
                        "effect": f"Ø¥Ø¯ØºØ§Ù… Ø§Ù„Ù„Ø§Ù… ÙÙŠ {third_letter}",
                        "phonetic_change": f"Ø§Ù„{third_letter}  > Ø§{third_letter}Ù‘",
                    }
                )

        # ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ£Ø«ÙŠØ±Ø§Øª Ø£Ø®Ø±Ù‰,
    for i in range(len(word) - 1):
            current = word[i]
            next_char = word[i + 1]

            # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¯ØºØ§Ù… Ø§Ù„Ø¨Ø³ÙŠØ·Ø©,
    if current == next_char:
                assimilation_effects.append()
                    {
                        "type": "Ø¥Ø¯ØºØ§Ù… ØªÙ…Ø§Ø«Ù„ÙŠ",
                        "position": i,
                        "effect": f"Ø¥Ø¯ØºØ§Ù… {current} ÙÙŠ {next_char}}",
                        "phonetic_change": f"{current}{next_char}  > {current}Ù‘",
                    }
                )

        return assimilation_effects,
    def get_phonemes_statistics(self) -> Dict[str, Any]:
        """ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª"""
        consonants = [p for p in self.phonemes if p.type == "ØµØ§Ù…Øª"]
        vowels = [p for p in self.phonemes if "ØµØ§Ø¦Øª" in p.type]

        return {
            "total_phonemes": len(self.phonemes),
            "consonants_count": len(consonants),
            "vowels_count": len(vowels),
            "average_morphological_weight": sum()
                p.morphological_weight for p in self.phonemes
            )
            / len(self.phonemes),
            "average_frequency": sum(p.frequency_score for p in self.phonemes)
            / len(self.phonemes),
            "articulation_points": list()
                set(p.articulation_point for p in self.phonemes)
            ),
            "functions": list(set(p.function for p in self.phonemes)),
        }

    def get_harakat_statistics(self) -> Dict[str, Any]:
        """ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø­Ø±ÙƒØ§Øª"""
        return {
            "total_harakat": len(self.harakat),
            "average_phonetic_weight": sum(h.phonetic_weight for h in self.harakat)
            / len(self.harakat),
            "average_grammatical_significance": sum()
                h.grammatical_significance for h in self.harakat
            )
            / len(self.harakat),
            "harakat_types": list(set(h.type for h in self.harakat)),
            "grammatical_roles": list(set(h.role for h in self.harakat)),
        }

    def export_phonemes_dataframe(self):  # type: ignore[no-untyped def]
        """ğŸ“Š ØªØµØ¯ÙŠØ± Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙƒÙ€ DataFrame"""
        try:
            import pandas as pd  # noqa: F401,
    PANDAS_AVAILABLE = True,
    except ImportError:
            PANDAS_AVAILABLE = False,
    data = []
        for phoneme in self.phonemes:
            data.append()
                {
                    "Ø§Ù„Ø­Ø±Ù": phoneme.letter,
                    "Ø§Ù„Ù†ÙˆØ¹": phoneme.type,
                    "Ø§Ù„Ù…Ø®Ø±Ø¬": phoneme.articulation_point,
                    "Ø§Ù„ØµÙ„Ø§Ø¨Ø©": phoneme.hardness,
                    "Ø§Ù„ÙˆØ¸ÙŠÙØ©": phoneme.function,
                    "Ø§Ù„ÙˆØ²Ù†_Ø§Ù„ØµØ±ÙÙŠ": phoneme.morphological_weight,
                    "Ù†Ù‚Ø§Ø·_Ø§Ù„ØªÙƒØ±Ø§Ø±": phoneme.frequency_score,
                }
            )

        if PANDAS_AVAILABLE:
            return pd.DataFrame(data)
        else:
            return {"error": "pandas ØºÙŠØ± Ù…ØªÙˆÙØ±", "data": data}

    def export_harakat_dataframe(self):  # type: ignore[no-untyped def]
        """ğŸ“Š ØªØµØ¯ÙŠØ± Ø§Ù„Ø­Ø±ÙƒØ§Øª ÙƒÙ€ DataFrame"""
        try:
            import pandas as pd  # noqa: F401,
    PANDAS_AVAILABLE = True,
    except ImportError:
            PANDAS_AVAILABLE = False,
    data = []
        for haraka in self.harakat:
            data.append()
                {
                    "Ø§Ù„Ø­Ø±ÙƒØ©": haraka.symbol,
                    "Ø§Ù„Ø§Ø³Ù…": haraka.name,
                    "Ø§Ù„Ù†ÙˆØ¹": haraka.type,
                    "Ø§Ù„ÙˆØ¶ÙˆØ­": haraka.clarity,
                    "Ø§Ù„Ø¯ÙˆØ±": haraka.role,
                    "Ø§Ù„ÙˆØ²Ù†_Ø§Ù„ØµÙˆØªÙŠ": haraka.phonetic_weight,
                    "Ø§Ù„Ø£Ù‡Ù…ÙŠØ©_Ø§Ù„Ù†Ø­ÙˆÙŠØ©": haraka.grammatical_significance,
                }
            )

        if PANDAS_AVAILABLE:
            return pd.DataFrame(data)
        else:
            return {"error": "pandas ØºÙŠØ± Ù…ØªÙˆÙØ±", "data": data}

    # Ø¥Ø¶Ø§ÙØ§Øª Ù„Ø¯Ø¹Ù… Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø©,
    def get_detailed_features(self, word: str) -> Dict[str, Any]:
        """ØªÙØ§ØµÙŠÙ„ Ù…ÙŠØ²Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ Ù„ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©"""
        result = self.analyze_phonetic_structure(word)
        return result.get('analysis', {})

    def get_batch_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"""
        total = len(results)
        phonetic_weights = []
        for r in results:
            if r.get('status') == 'success':
                analysis = r.get('analysis', {}).get('analysis', {})
                weight = analysis.get('phonetic_weight')
                if weight is not None:
                    phonetic_weights.append(weight)
        avg_weight = ()
            sum(phonetic_weights) / len(phonetic_weights) if phonetic_weights else 0.0
        )
        return {
            'average_phonetic_weight': avg_weight,
            'processed': len(phonetic_weights),
            'total_requested': total,
        }

    def compare_phonetic_structures()
        self, analyses: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨Ù†Ù‰ Ø§Ù„ØµÙˆØªÙŠØ© Ù„Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"""
        comparisons = []
        for i in range(len(analyses)):
            for j in range(i + 1, len(analyses)):
                w1 = analyses[i].get('word')
                w2 = analyses[j].get('word')
                ph1 = ()
                    analyses[i]
                    .get('analysis', {})
                    .get('analysis', {})
                    .get('phonemes', [])
                )
                ph2 = ()
                    analyses[j]
                    .get('analysis', {})
                    .get('analysis', {})
                    .get('phonemes', [])
                )
                comparisons.append()
                    {
                        'word1': w1,
                        'word2': w2,
                        'phonemes_equal': ph1 == ph2,
                        'shared_phonemes': [p for p in ph1 if p in ph2],
                    }
                )
        return {'comparisons': comparisons}  # type: ignore
        # type ignore to satisfy declared return type


# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…,
    def demo_phonemes_analyzer():  # type: ignore[no-untyped-def]
    """ğŸ§ª Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù…Ø­Ù„Ù„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª"""
    analyzer = PhonemesHarakatAnalyzer()

    print("ğŸ§± Ù…Ø­Ù„Ù„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª - Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙØ§Ø¹Ù„ Ø§Ù„ØµØ±ÙÙŠ")
    print("=" * 60)

    # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø©,
    result = analyzer.analyze_phonetic_structure("ÙƒØªØ§Ø¨")
    print("ğŸ“Š ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© 'ÙƒØªØ§Ø¨':")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª,
    phonemes_stats = analyzer.get_phonemes_statistics()
    harakat_stats = analyzer.get_harakat_statistics()

    print("\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª:")
    print(json.dumps(phonemes_stats, ensure_ascii=False, indent=2))

    print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø­Ø±ÙƒØ§Øª:")
    print(json.dumps(harakat_stats, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    demo_phonemes_analyzer()

