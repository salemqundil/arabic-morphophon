#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
๐ฅ ููููุฏ ุงููุชุฌู ุงูุฑููู ุงููุชูุฏู ูููููุงุช ุงูุนุฑุจูุฉ ุงูููุฑุฏุฉ
====================================================

ูุธุงู ุดุงูู ูุชูููุฏ ุงููุชุฌูุงุช ุงูุฑูููุฉ ูููููุงุช ุงูุนุฑุจูุฉ ุงูููุฑุฏุฉ,
    ูุน ุงูุชุญููู ุงููุบูู ุงููุชูุฏู ูุงูููุฒุงุช ุงููุทููุจุฉ,
    Advanced Arabic Digital Vector Generator for Single Words,
    A comprehensive system for generating digital vectors for Arabic words,
    with advanced linguistic analysis and requested features.
"""
# pylint: disable=invalid-name,too-few-public-methods,too-many-instance-attributes,line-too long
import re
import json
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import logging
from datetime import datetime

# ุฅุนุฏุงุฏ ูุธุงู ุงูุณุฌูุงุช,
    logging.basicConfig()
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")"
)
logger = logging.getLogger(__name__)

# ============== ุงูุชุนุฏุงุฏุงุช ูุงูุซูุงุจุช ==============


class DefinitenesType(Enum):
    """ุชุตููู ุญุงูุฉ ุงูุชุนุฑูู"""

    DEFINITE = 0  # ุงููุชุงุจ - ูุนุฑูุฉ,
    INDEFINITE = 1  # ูุชุงุจ - ููุฑุฉ,
    PROPER_NOUN = 2  # ูุญูุฏ - ุนูู,
    PRONOUN = 3  # ูู - ุถููุฑ,
    class CaseMarking(Enum):
    """ุนูุงูุงุช ุงูุฅุนุฑุงุจ"""

    NOMINATIVE = 0  # ุงููุงุนู - ูุฑููุน,
    ACCUSATIVE = 1  # ุงูููุนูู - ููุตูุจ,
    GENITIVE = 2  # ุงููุถุงู ุฅููู - ูุฌุฑูุฑ,
    UNDEFINED = 3  # ุจุฏูู ุฅุนุฑุงุจ ูุงุถุญ,
    class Gender(Enum):
    """ุงูุฌูุฏุฑ ุงููุญูู"""

    MASCULINE = 0  # ูุฐูุฑ,
    FEMININE = 1  # ูุคูุซ,
    COMMON = 2  # ูุดุชุฑู,
    class Number(Enum):
    """ุงูุนุฏุฏ ุงููุญูู"""

    SINGULAR = 0  # ููุฑุฏ,
    DUAL = 1  # ูุซูู,
    PLURAL = 2  # ุฌูุน,
    class DiminutiveForm(Enum):
    """ุฃุดูุงู ุงูุชุตุบูุฑ"""

    NO_DIMINUTIVE = 0  # ุจุฏูู ุชุตุบูุฑ,
    FUAIL = 1  # ููุนูููู,
    FUAILA = 2  # ููุนูููููุฉ,
    FUAIIL = 3  # ููุนูููุนูู,
    class SemanticRole(Enum):
    """ุงูุฃุฏูุงุฑ ุงูุฏูุงููุฉ"""

    AGENT = 0  # ูุงุนู ุฏูุงูู,
    PATIENT = 1  # ููุนูู ุฏูุงูู,
    INSTRUMENT = 2  # ุฃุฏุงุฉ,
    LOCATION = 3  # ููุงู,
    TIME = 4  # ุฒูุงู,
    MANNER = 5  # ุทุฑููุฉ


# ============== ููุงูู ุงูุจูุงูุงุช ==============


@dataclass,
    class VectorComponents:
    """ููููุงุช ุงููุชุฌู ุงูุฑููู ุงูุดุงูู"""

    # ๐ค ุงูููุฒุงุช ุงูุตูุชูุฉ (30 ุจูุนุฏ)
    phoneme_count: int = 0  # ุนุฏุฏ ุงููููููุงุช,
    consonant_ratio: float = 0.0  # ูุณุจุฉ ุงูุตูุงูุช,
    vowel_ratio: float = 0.0  # ูุณุจุฉ ุงูุตูุงุฆุช,
    emphatic_ratio: float = 0.0  # ูุณุจุฉ ุงูุญุฑูู ุงูููุฎูุฉ,
    syllable_count: int = 0  # ุนุฏุฏ ุงูููุงุทุน,
    cv_pattern_encoded: Optional[List[int]] = None  # ููุท CV ูุฑูุฒ (10 ุฃุจุนุงุฏ)
    stress_primary_position: int = -1  # ูููุน ุงููุจุฑ ุงูุฃุณุงุณู,
    stress_secondary_positions: Optional[List[int]] = None  # ููุงูุน ุงููุจุฑ ุงูุซุงููู,
    long_vowel_count: int = 0  # ุนุฏุฏ ุงูุตูุงุฆุช ุงูุทูููุฉ,
    gemination_count: int = 0  # ุนุฏุฏ ุงูุชุถุนููุงุช

    # ๐ ุงูููุฒุงุช ุงูุตุฑููุฉ (25 ุจูุนุฏ)
    root_length: int = 0  # ุทูู ุงูุฌุฐุฑ,
    root_type: int = 0  # ููุน ุงูุฌุฐุฑ (ุซูุงุซู=0ุ ุฑุจุงุนู=1ุ ุฎูุงุณู=2)
    pattern_class: int = 0  # ูุฆุฉ ุงููุฒู ุงูุตุฑูู,
    prefix_count: int = 0  # ุนุฏุฏ ุงูุจุงุฏุฆุงุช,
    suffix_count: int = 0  # ุนุฏุฏ ุงูููุงุญู,
    stem_length: int = 0  # ุทูู ุงูุฌุฐุน,
    derivational_depth: int = 0  # ุนูู ุงูุงุดุชูุงู,
    morphological_complexity: float = 0.0  # ุชุนูุฏ ุตุฑูู

    # ๐ฏ ุงูููุฒุงุช ุงููุญููุฉ (20 ุจูุนุฏ)
    definiteness: int = 0  # ุงูุชุนุฑูู (0-3)
    case_marking: int = 0  # ุงูุฅุนุฑุงุจ (0-3)
    gender: int = 0  # ุงูุฌูุฏุฑ (0-2)
    number: int = 0  # ุงูุนุฏุฏ (0-2)
    has_definite_article: int = 0  # ูุฌูุฏ ุฃุฏุงุฉ ุงูุชุนุฑูู,
    is_construct_state: int = 0  # ุญุงูุฉ ุงูุฅุถุงูุฉ,
    is_vocative: int = 0  # ุงูููุงุฏู,
    genitive_marking: int = 0  # ุนูุงูุฉ ุงูุฌุฑ,
    sun_moon_assimilation: int = 0  # ุฅุฏุบุงู ุดูุณู/ููุฑู

    # ๐ญ ุงูููุฒุงุช ุงูุฏูุงููุฉ (20 ุจูุนุฏ)
    semantic_role: int = 0  # ุงูุฏูุฑ ุงูุฏูุงูู (0-5)
    animacy: int = 0  # ุงูุญูููุฉ (0=ุฌูุงุฏุ 1=ุญู)
    concreteness: float = 0.0  # ุงูููููุณูุฉ (0-1)
    countability: int = 0  # ุงููุงุจููุฉ ููุนุฏ (0=massุ 1=count)
    human_reference: int = 0  # ุงูุฅุดุงุฑุฉ ููุฅูุณุงู,
    temporal_reference: int = 0  # ุงูุฅุดุงุฑุฉ ุงูุฒูููุฉ,
    spatial_reference: int = 0  # ุงูุฅุดุงุฑุฉ ุงูููุงููุฉ

    # ๐ฅ ุงูููุฒุงุช ุงููุชูุฏูุฉ (15 ุจูุนุฏ)
    diminutive_form: int = 0  # ุดูู ุงูุชุตุบูุฑ (0 3)
    irregular_inflection: int = 0  # ุงูุชุตุฑูู ุงูุดุงุฐ,
    hamza_complexity: int = 0  # ุชุนูุฏ ุงูููุฒุฉ,
    assimilation_effects: int = 0  # ุชุฃุซูุฑุงุช ุงูุฅุฏุบุงู,
    prosodic_breaks: int = 0  # ุงููููุงุช ุงูุนุฑูุถูุฉ,
    phonetic_changes: int = 0  # ุงูุชุบููุฑุงุช ุงูุตูุชูุฉ,
    morphophonemic_alternations: int = 0  # ุงูุชูุงูุจุงุช ุงูุตุฑูุตูุชูุฉ,
    class ArabicDigitalVectorGenerator:
    """
    ๐ฏ ููููุฏ ุงููุชุฌู ุงูุฑููู ุงููุชูุฏู ูููููุงุช ุงูุนุฑุจูุฉ ุงูููุฑุฏุฉ

    โ ุงูููุฒุงุช ุงููุทููุจุฉ ุงููููููุฐุฉ:
    1. ุงูุชุนููู ุงููุนุฑูู (definiteness) - ุฃุฏุงุฉ ุงูุชุนุฑูู ูุงูููุฑุฉ,
    2. ุญุงูุฉ ุงูุงุณู ูุงูุฅุนุฑุงุจ - ูุฑููุนุ ููุตูุจุ ูุฌุฑูุฑ,
    3. ููุงุนุฏ ุฅุฏุบุงู ุงููุงู - ุงูุญุฑูู ุงูุดูุณูุฉ ูุงูููุฑูุฉ,
    4. ุญุงูุฉ ุงูุฅุถุงูุฉ ุงููุญููุฉ - ุงูุฅุถุงูุฉ ุงูุญููููุฉ ูุงููุฌุงุฒูุฉ,
    5. ุงูุฌูุฏุฑ ูุงูุงุชูุงู ุงูุตุฑูู - ูุฐูุฑ/ูุคูุซ ูุน ุงูุงุชูุงู,
    6. ุงูุชุตุบูุฑ - ุฃูุฒุงู ููุนููููุ ููุนูููููุฉุ ููุนูููุนูู,
    7. ุงูุชูุฒูุน ุงูุตูุชู ุงููุญูู - ุงููุจุฑ ูุงูุนุฑูุถ,
    8. ุงูุชุตุฑูู ุงูุดุงุฐ - ุงูุฃูุนุงู ูุงูุฃุณูุงุก ุงูุดุงุฐุฉ,
    9. ุงูุชุซููุฉ ูุงูุฌูุน - ูุงูุชุฏุงุฏ ููููุฑุฏ,
    10. ุงูุนูุงูุงุช ุงูุฏูุงููุฉ - ุงูุฃุฏูุงุฑ ูุงูุฅุทุงุฑ ุงูุฏูุงูู,
    11. ุงูุชุบููุฑุงุช ุงูุตูุชูุฉ ุงูุงุณุชุซูุงุฆูุฉ - ููุฒ ุงููุตู ูุงูุฅุฏุบุงู,
    12. ุงูููุฐุฌุฉ ุงูุชูุจุคูุฉ - ุฎูุงุฑุฒููุงุช ML ููุชุตููู

    โ ุงููุณุชุซูู ูู ุงููุทุงู:
    - ุงูุณูุงู ุงููุญูู ุจูู ุงูุฌูู
    - ุงูุชุญููู ุงูุฎุทุงุจู ูุงูุชุฏุงููู
    - ุงูุฏูุงูุฉ ุงูุณูุงููุฉ ุงููุชุบูุฑุฉ
    - ุงูุชูุบูู ุงูุนุงุทูู ุงูููุทูู
    """

    def __init__(self):
    """ุชููุฆุฉ ููููุฏ ุงููุชุฌู ุงูุฑููู"""
    self._import_data_linguistic_resources()
    logger.info("๐ ุชู ุชููุฆุฉ ููููุฏ ุงููุชุฌู ุงูุฑููู ุงููุชูุฏู")"

    def _import_data_linguistic_resources(self):
    """ุชุญููู ุงูููุงุฑุฏ ุงููุบููุฉ ุงูุฃุณุงุณูุฉ"""

        # 1. ูุงููุณ ุงููููููุงุช ุงูุนุฑุจูุฉ
        # Replaced with unified_phonemes
    "ุจ": {"type": "consonant", "emphatic": False, "place": "bilabial"},"
    "ุช": {"type": "consonant", "emphatic": False, "place": "alveolar"},"
    "ุซ": {"type": "consonant", "emphatic": False, "place": "dental"},"
    "ุฌ": {"type": "consonant", "emphatic": False, "place": "postalveolar"},"
    "ุญ": {"type": "consonant", "emphatic": False, "place": "pharyngeal"},"
    "ุฎ": {"type": "consonant", "emphatic": False, "place": "uvular"},"
    "ุฏ": {"type": "consonant", "emphatic": False, "place": "alveolar"},"
    "ุฐ": {"type": "consonant", "emphatic": False, "place": "dental"},"
    "ุฑ": {"type": "consonant", "emphatic": False, "place": "alveolar"},"
    "ุฒ": {"type": "consonant", "emphatic": False, "place": "alveolar"},"
    "ุณ": {"type": "consonant", "emphatic": False, "place": "alveolar"},"
    "ุด": {"type": "consonant", "emphatic": False, "place": "postalveolar"},"
    "ุต": {"type": "consonant", "emphatic": True, "place": "alveolar"},"
    "ุถ": {"type": "consonant", "emphatic": True, "place": "alveolar"},"
    "ุท": {"type": "consonant", "emphatic": True, "place": "alveolar"},"
    "ุธ": {"type": "consonant", "emphatic": True, "place": "dental"},"
    "ุน": {"type": "consonant", "emphatic": False, "place": "pharyngeal"},"
    "ุบ": {"type": "consonant", "emphatic": False, "place": "uvular"},"
    "ู": {"type": "consonant", "emphatic": False, "place": "labiodental"},"
    "ู": {"type": "consonant", "emphatic": False, "place": "uvular"},"
    "ู": {"type": "consonant", "emphatic": False, "place": "velar"},"
    "ู": {"type": "consonant", "emphatic": False, "place": "alveolar"},"
    "ู": {"type": "consonant", "emphatic": False, "place": "bilabial"},"
    "ู": {"type": "consonant", "emphatic": False, "place": "alveolar"},"
    "ู": {"type": "consonant", "emphatic": False, "place": "glottal"},"
    "ู": {"type": "semivowel", "emphatic": False, "place": "labiovelar"},"
    "ู": {"type": "semivowel", "emphatic": False, "place": "palatal"},"
    "ุก": {"type": "consonant", "emphatic": False, "place": "glottal"},"
    }

        # 2. ุงูุญุฑูู ุงูุดูุณูุฉ ูุงูููุฑูุฉ,
    self.sun_letters = {
    "ุช","
    "ุซ","
    "ุฏ","
    "ุฐ","
    "ุฑ","
    "ุฒ","
    "ุณ","
    "ุด","
    "ุต","
    "ุถ","
    "ุท","
    "ุธ","
    "ู","
    "ู","
    }
    self.moon_letters = {
    "ุก","
    "ุจ","
    "ุฌ","
    "ุญ","
    "ุฎ","
    "ุน","
    "ุบ","
    "ู","
    "ู","
    "ู","
    "ู","
    "ู","
    "ู","
    "ู","
    }

        # 3. ุงูุญุฑูุงุช ูุงูุชูููู,
    self.diacritics = {
    "ู": {"name": "fatha", "length": 1},"
    "ู": {"name": "kasra", "length": 1},"
    "ู": {"name": "damma", "length": 1},"
    "ู": {"name": "tanween_fath", "length": 2},"
    "ู": {"name": "tanween_kasr", "length": 2},"
    "ู": {"name": "tanween_damm", "length": 2},"
    "ู": {"name": "sukun", "length": 0},"
    "ู": {"name": "shadda", "length": 1, "gemination": True},"
    }

        # 4. ุฃููุงุท ุงูุชุตุบูุฑ,
    self.diminutive_patterns = {
    "ููุนูููู": r"^.ู.ููู.ู?$","
    "ููุนูููููุฉ": r"^.ู.ููู.ูุฉู?$","
    "ููุนูููุนูู": r"^.ู.ููู.ู.ู?$","
    }

        # 5. ุงููููุงุช ุงูุดุงุฐุฉ,
    self.irregular_words = {
    "ุฃุจ": {"type": "defective_noun", "pattern": "irregular"},"
    "ุฃุฎ": {"type": "defective_noun", "pattern": "irregular"},"
    "ุญู": {"type": "defective_noun", "pattern": "irregular"},"
    "ูู": {"type": "defective_noun", "pattern": "irregular"},"
    "ุฐู": {"type": "relative_noun", "pattern": "irregular"},"
    "ุฐุงุช": {"type": "relative_noun", "pattern": "irregular"},"
    }

        # 6. ููุงููุณ ุฏูุงููุฉ ูุจุณุทุฉ,
    self.semantic_classes = {
    "animate": ["ุฑุฌู", "ุงูุฑุฃุฉ", "ุทูู", "ุญููุงู", "ุทุงุฆุฑ"],"
    "inanimate": ["ูุชุงุจ", "ุจูุช", "ุณูุงุฑุฉ", "ุดุฌุฑุฉ"],"
    "abstract": ["ููุฑุฉ", "ุญุจ", "ุฎูู", "ุฃูู", "ุนูู"],"
    "temporal": ["ููู", "ูููุฉ", "ุณุงุนุฉ", "ุฏูููุฉ"],"
    "spatial": ["ููุงู", "ุจูุช", "ูุฏููุฉ", "ุจูุฏ"],"
    }

    def generate_vector()
    self, word: str, context: Optional[Dict] = None
    ) -> Dict[str, Any]:
    """
    ุชูููุฏ ุงููุชุฌู ุงูุฑููู ุงูุดุงูู ูููููุฉ ุงูุนุฑุจูุฉ,
    Args:
    word: ุงููููุฉ ุงูุนุฑุจูุฉ ุงููุฑุงุฏ ุชุญููููุง,
    context: ูุนูููุงุช ุงูุณูุงู (ุงุฎุชูุงุฑู)

    Returns:
    ูุงููุณ ุดุงูู ูุญุชูู ุนูู ุงููุชุฌู ูุงูุชุญููู ุงูุชูุตููู
    """

    logger.info(f"๐ ุจุฏุก ุชุญููู ุงููููุฉ: {word}")"

        try:
            # ุฅูุดุงุก ููููุงุช ุงููุชุฌู,
    vector_components = VectorComponents()

            # 1. ุงูุชุญููู ุงูุตูุชู,
    self._analyze_phonology(word, vector_components)

            # 2. ุงูุชุญููู ุงูุตุฑูู,
    self._analyze_morphology(word, vector_components)

            # 3. ุงูุชุญููู ุงููุญูู,
    self._analyze_syntax(word, vector_components, context)

            # 4. ุงูุชุญููู ุงูุฏูุงูู,
    self._analyze_semantics(word, vector_components, context)

            # 5. ุงูููุฒุงุช ุงููุชูุฏูุฉ,
    self._analyze_advanced_features(word, vector_components)

            # 6. ุชุญููู ุฅูู ูุชุฌู ุฑููู,
    numerical_vector = self._convert_to_vector(vector_components)

            # 7. ุชุฌููุน ุงููุชุงุฆุฌ,
    analysis_result = {
    "word": word,"
    "timestamp": datetime.now().isoformat(),"
    "vector_components": asdict(vector_components),"
    "numerical_vector": numerical_vector,"
    "vector_dimensions": len(numerical_vector),"
    "linguistic_analysis": self._generate_linguistic_summary()"
    word, vector_components
    ),
    "processing_status": "success","
    }

    logger.info(f"โ ุชู ุชุญููู ุงููููุฉ ุจูุฌุงุญ - ุงูุฃุจุนุงุฏ: {len(numerical_vector)}")"
    return analysis_result,
    except Exception as e:
    logger.error(f"โ ุฎุทุฃ ูู ุชุญููู ุงููููุฉ {word: {str(e)}}")"
    return {"word": word, "error": str(e), "processing_status": "error"}"

    def _analyze_phonology(self, word: str, components: VectorComponents):
    """ุงูุชุญููู ุงูุตูุชู ุงููุชูุฏู"""

        # ุงุณุชุฎุฑุงุฌ ุงููููููุงุช,
    phonemes = [char for char in word if char in self.phonemes]
    components.phoneme_count = len(phonemes)

        # ุญุณุงุจ ูุณุจ ุงูุตูุงูุช ูุงูุตูุงุฆุช,
    consonants = [p for p in phonemes if self.get_phoneme(p]["type"] == "consonant"]"
    vowels = [
    p for p in phonemes if self.get_phoneme(p]["type"] in ["vowel", "semivowel"]"
    ]

        if phonemes:
    components.consonant_ratio = len(consonants) / len(phonemes)
    components.vowel_ratio = len(vowels) / len(phonemes)

        # ุญุณุงุจ ูุณุจุฉ ุงูุชูุฎูู,
    emphatic_phonemes = [
    p for p in phonemes if self.get_phoneme(p].get("emphatic", False)"
    ]
        if phonemes:
    components.emphatic_ratio = len(emphatic_phonemes) / len(phonemes)

        # ุชุญููู ุงูููุงุทุน (ูุจุณุท)
    syllabic_units = self._analyze_syllabic_units(word)
    components.syllable_count = len(syllabic_units)

        # ุชุฑููุฒ ููุท CV,
    components.cv_pattern_encoded = self._encode_cv_pattern(syllabic_units)

        # ุชุญุฏูุฏ ุงููุจุฑ,
    components.stress_primary_position = self._find_primary_stress(syllabic_units)

        # ุนุฏ ุงูุตูุงุฆุช ุงูุทูููุฉ ูุงูุชุถุนููุงุช,
    components.long_vowel_count = ()
    word.count("ุง") + word.count("ู") + word.count("ู")"
    )
    components.gemination_count = word.count("ู")"

    def _analyze_morphology(self, word: str, components: VectorComponents):
    """ุงูุชุญููู ุงูุตุฑูู ุงููุชูุฏู"""

        # ุงุณุชุฎุฑุงุฌ ุงูุฌุฐุฑ,
    root = self._extract_root(word)
    components.root_length = len(root)

        # ุชุญุฏูุฏ ููุน ุงูุฌุฐุฑ,
    if len(root) == 3:
    components.root_type = 0  # ุซูุงุซู,
    elif len(root) == 4:
    components.root_type = 1  # ุฑุจุงุนู,
    else:
    components.root_type = 2  # ุฎูุงุณู ุฃู ุฃูุซุฑ

        # ุชุญููู ุงูุจุงุฏุฆุงุช ูุงูููุงุญู,
    prefixes, stem, suffixes = self._analyze_affixes(word)
    components.prefix_count = len(prefixes)
    components.suffix_count = len(suffixes)
    components.stem_length = len(stem)

        # ุญุณุงุจ ุงูุชุนูุฏ ุงูุตุฑูู,
    components.morphological_complexity = ()
    components.prefix_count
    + components.suffix_count
    + (1 if components.root_length > 3 else 0)
    ) / 10.0  # ุชุทุจูุน ุฅูู 0 1

        # ุชุญุฏูุฏ ุนูู ุงูุงุดุชูุงู,
    components.derivational_depth = self._calculate_derivational_depth(word)

    def _analyze_syntax()
    self, word: str, components: VectorComponents, context: Optional[Dict]
    ):
    """ุงูุชุญููู ุงููุญูู ุงููุชูุฏู"""

        # ุชุญููู ุงูุชุนุฑูู,
    if word.startswith("ุงู"):"
    components.definiteness = DefinitenesType.DEFINITE.value,
    components.has_definite_article = 1

            # ุชุญููู ุงูุฅุฏุบุงู ุงูุดูุณู/ุงูููุฑู,
    if len(word) > 2:
    first_letter = word[2]
                if first_letter in self.sun_letters:
    components.sun_moon_assimilation = 1  # ุฅุฏุบุงู ุดูุณู,
    elif first_letter in self.moon_letters:
    components.sun_moon_assimilation = 0  # ููุฑู,
    else:
    components.definiteness = DefinitenesType.INDEFINITE.value

        # ุชุญููู ุงูุฅุนุฑุงุจ ูู ุงูุชูููู,
    if word.endswith("ู") or word.endswith("ู"):"
    components.case_marking = CaseMarking.NOMINATIVE.value,
    elif word.endswith("ู") or word.endswith("ู"):"
    components.case_marking = CaseMarking.ACCUSATIVE.value,
    elif word.endswith("ู") or word.endswith("ู"):"
    components.case_marking = CaseMarking.GENITIVE.value

        # ุชุญููู ุงูุฌูุฏุฑ,
    if word.endswith("ุฉ") or word.endswith("ุงุก"):"
    components.gender = Gender.FEMININE.value,
    else:
    components.gender = Gender.MASCULINE.value

        # ุชุญููู ุงูุนุฏุฏ,
    if word.endswith("ุงู") or word.endswith("ูู"):"
    components.number = Number.DUAL.value,
    elif word.endswith("ูู") or word.endswith("ุงุช"):"
    components.number = Number.PLURAL.value,
    else:
    components.number = Number.SINGULAR.value

        # ุชุญููู ุงูุณูุงู ุงููุญูู,
    if context:
    components.is_construct_state = 1 if context.get("construct_state") else 0"
    components.is_vocative = 1 if context.get("vocative") else 0"

    def _analyze_semantics()
    self, word: str, components: VectorComponents, context: Optional[Dict]
    ):
    """ุงูุชุญููู ุงูุฏูุงูู ุงููุชูุฏู"""

        # ุชุญุฏูุฏ ุงูุญูููุฉ,
    if any(word in animals for animals in self.semantic_classes["animate"]):"
    components.animacy = 1

        # ุชุญุฏูุฏ ุงูููููุณูุฉ,
    if any(word in abstract for abstract in self.semantic_classes["abstract"]):"
    components.concreteness = 0.2,
    else:
    components.concreteness = 0.8

        # ุชุญุฏูุฏ ุงููุงุจููุฉ ููุนุฏ,
    mass_nouns = ["ูุงุก", "ููุงุก", "ุชุฑุงุจ", "ุฑูู"]"
        if word in mass_nouns:
    components.countability = 0  # ุบูุฑ ูุงุจู ููุนุฏ,
    else:
    components.countability = 1  # ูุงุจู ููุนุฏ

        # ุงูุฅุดุงุฑุงุช ุงูุฏูุงููุฉ,
    if any(word in temporal for temporal in self.semantic_classes["temporal"]):"
    components.temporal_reference = 1,
    if any(word in spatial for spatial in self.semantic_classes["spatial"]):"
    components.spatial_reference = 1

        # ุชุญุฏูุฏ ุงูุฏูุฑ ุงูุฏูุงูู ูู ุงูุณูุงู,
    if context and "semantic_role" in context:"
    role_mapping = {
    "agent": SemanticRole.AGENT.value,"
    "patient": SemanticRole.PATIENT.value,"
    "instrument": SemanticRole.INSTRUMENT.value,"
    "location": SemanticRole.LOCATION.value,"
    "time": SemanticRole.TIME.value,"
    "manner": SemanticRole.MANNER.value,"
    }
    components.semantic_role = role_mapping.get(context["semantic_role"], 0)"

    def _analyze_advanced_features(self, word: str, components: VectorComponents):
    """ุชุญููู ุงูููุฒุงุช ุงููุชูุฏูุฉ"""

        # ูุดู ุงูุชุตุบูุฑ,
    for pattern_name, regex in self.diminutive_patterns.items():
            if re.search(regex, word):
                if pattern_name == "ููุนูููู":"
    components.diminutive_form = DiminutiveForm.FUAIL.value,
    elif pattern_name == "ููุนูููููุฉ":"
    components.diminutive_form = DiminutiveForm.FUAILA.value,
    elif pattern_name == "ููุนูููุนูู":"
    components.diminutive_form = DiminutiveForm.FUAIIL.value,
    break

        # ูุดู ุงูุชุตุฑูู ุงูุดุงุฐ,
    if word in self.irregular_words:
    components.irregular_inflection = 1

        # ุชุญููู ุงูููุฒุฉ,
    hamza_count = ()
    word.count("ุก") + word.count("ุฃ") + word.count("ุฅ") + word.count("ุข")"
    )
    components.hamza_complexity = min(hamza_count, 3)  # ุฃูุตู 3

        # ุชุญููู ุงูุฅุฏุบุงู,
    if word.startswith("ุงู") and len(len(word)  > 2) > 2:"
    first_letter = word[2]
            if first_letter in self.sun_letters:
    components.assimilation_effects = 1

        # ุชุญููู ุงููููุงุช ุงูุนุฑูุถูุฉ,
    if components.syllable_count > 3:
    components.prosodic_breaks = 1

        # ุชุญููู ุงูุชุบููุฑุงุช ุงูุตูุชูุฉ,
    if "ุง" in word and word.startswith("ุงู"):"
    components.phonetic_changes = 1,
    def _convert_to_vector(self, components: VectorComponents) -> List[float]:
    """ุชุญููู ููููุงุช ุงููุชุฌู ุฅูู ูุงุฆูุฉ ุฑูููุฉ ููุญุฏุฉ"""

    vector = []

        # ุงูููุฒุงุช ุงูุตูุชูุฉ,
    vector.extend()
    [
    float(components.phoneme_count),
    components.consonant_ratio,
    components.vowel_ratio,
    components.emphatic_ratio,
    float(components.syllable_count),
    float(components.stress_primary_position),
    float(components.long_vowel_count),
    float(components.gemination_count),
    ]
    )

        # ุฅุถุงูุฉ ููุท CV (10 ุฃุจุนุงุฏ)
    cv_pattern = components.cv_pattern_encoded or [0] * 10,
    vector.extend(cv_pattern[:10])

        # ุงูููุฒุงุช ุงูุตุฑููุฉ,
    vector.extend()
    [
    float(components.root_length),
    float(components.root_type),
    float(components.prefix_count),
    float(components.suffix_count),
    float(components.stem_length),
    components.morphological_complexity,
    float(components.derivational_depth),
    ]
    )

        # ุงูููุฒุงุช ุงููุญููุฉ,
    vector.extend()
    [
    float(components.definiteness),
    float(components.case_marking),
    float(components.gender),
    float(components.number),
    float(components.has_definite_article),
    float(components.is_construct_state),
    float(components.is_vocative),
    float(components.sun_moon_assimilation),
    ]
    )

        # ุงูููุฒุงุช ุงูุฏูุงููุฉ,
    vector.extend()
    [
    float(components.semantic_role),
    float(components.animacy),
    components.concreteness,
    float(components.countability),
    float(components.human_reference),
    float(components.temporal_reference),
    float(components.spatial_reference),
    ]
    )

        # ุงูููุฒุงุช ุงููุชูุฏูุฉ,
    vector.extend()
    [
    float(components.diminutive_form),
    float(components.irregular_inflection),
    float(components.hamza_complexity),
    float(components.assimilation_effects),
    float(components.prosodic_breaks),
    float(components.phonetic_changes),
    float(components.morphophonemic_alternations),
    ]
    )

    return vector

    # ============== ุฏูุงู ูุณุงุนุฏุฉ ==============

    def _analyze_syllabic_units(self, word: str) -> List[str]:
    """ุชุญููู ุงูููุงุทุน - ูุณุฎุฉ ูุจุณุทุฉ"""
    syllabic_units = []
    current = """

        for char in word:
            if char in self.phonemes:
                if self.get_phoneme(char]["type"] == "consonant":"
    current += "C""
                else:
    current += "V""
            elif char in ["ู", "ู", "ู"]:"
    current += "V""
            elif char in ["ุง", "ู", "ู"]:"
    current += "V""

        # ุชูุณูู ูุจุณุท ููููุงุทุน,
    if current:
            # ูุงุนุฏุฉ ูุจุณุทุฉ: ูู CV ุฃู CVC ููุทุน ูููุตู,
    i = 0,
    while i < len(current):
                if i < len(current) - 1:
                    if current[i] == "C" and current[i + 1] == "V":"
                        if i < len(current) - 2 and current[i + 2] == "C":"
    syllabic_units.append("CVC")"
    i += 3,
    else:
    syllabic_units.append("CV")"
    i += 2,
    else:
    syllabic_units.append(current[i])
    i += 1,
    else:
    syllabic_units.append(current[i])
    i += 1,
    return syllabic_units if syllabic_units else ["CV"]"

    def _encode_cv_pattern(self, syllabic_units: List[str]) -> List[int]:
    """ุชุฑููุฒ ููุท CV ุฅูู ูุชุฌู ุซุงุจุช ุงูุทูู"""
    pattern_encoding = [0] * 10  # ุฃูุตู 10 ููุงุทุน,
    pattern_map = {"CV": 1, "CVC": 2, "CVV": 3, "CVCC": 4, "V": 5, "VC": 6, "C": 7}"

        for i, syllable in enumerate(syllabic_units[:10]):
    pattern_encoding[i] = pattern_map.get(syllable, 0)

    return pattern_encoding,
    def _find_primary_stress(self, syllabic_units: List[str]) -> int:
    """ุชุญุฏูุฏ ูููุน ุงููุจุฑ ุงูุฃุณุงุณู"""
        if not syllabic_units:
    return -1

        # ูุงุนุฏุฉ ูุจุณุทุฉ: ุงููุจุฑ ุนูู ุงูููุทุน ุงูุฃุฎูุฑ ุฅุฐุง ูุงู ุซูููุงู
        if len(syllabic_units[-1]) > 2:  # ููุทุน ุซููู,
    return len(syllabic_units) - 1,
    elif len(len(syllabic_units)  > 1) > 1:
    return len(syllabic_units) - 2  # ูุง ูุจู ุงูุฃุฎูุฑ,
    else:
    return 0,
    def _extract_root(self, word: str) -> str:
    """ุงุณุชุฎุฑุงุฌ ุงูุฌุฐุฑ - ุฎูุงุฑุฒููุฉ ูุจุณุทุฉ"""
    clean_word = word

        # ุฅุฒุงูุฉ ุฃุฏุงุฉ ุงูุชุนุฑูู,
    if clean_word.startswith("ุงู"):"
    clean_word = clean_word[2:]

        # ุฅุฒุงูุฉ ุงูููุงุญู ุงูุดุงุฆุนุฉ,
    suffixes = ["ุฉ", "ุงุช", "ุงู", "ูู", "ูู", "ูุง", "ูู", "ูู"]"
        for suffix in suffixes:
            if clean_word.endswith(suffix):
    clean_word = clean_word[:  len(suffix)]
    break

        # ุงุณุชุฎุฑุงุฌ ุงูุตูุงูุช ุงูุฃุณุงุณูุฉ,
    consonants = []
        for char in clean_word:
            if char in self.phonemes and self.get_phoneme(char]["type"] == "consonant":"
    consonants.append(char)

    return "".join(consonants[:4])  # ุฃูุตู 4 ุญุฑูู"

    def _analyze_affixes(self, word: str) -> Tuple[List[str], str, List[str]]:
    """ุชุญููู ุงูุจุงุฏุฆุงุช ูุงูุฌุฐุน ูุงูููุงุญู"""
    prefixes = []
    suffixes = []
    stem = word

        # ุงูุจุงุฏุฆุงุช ุงูุดุงุฆุนุฉ,
    prefix_list = ["ุงู", "ู", "ู", "ุจ", "ู", "ู"]"
        for prefix in prefix_list:
            if stem.startswith(prefix):
    prefixes.append(prefix)
    stem = stem[len(prefix) :]
    break

        # ุงูููุงุญู ุงูุดุงุฆุนุฉ,
    suffix_list = ["ุฉ", "ุงุช", "ุงู", "ูู", "ูู", "ูุง", "ูู", "ูู", "ุชู"]"
        for suffix in suffix_list:
            if stem.endswith(suffix):
    suffixes.append(suffix)
    stem = stem[: -len(suffix)]
    break,
    return prefixes, stem, suffixes,
    def _calculate_derivational_depth(self, word: str) -> int:
    """ุญุณุงุจ ุนูู ุงูุงุดุชูุงู"""
    depth = 0

        # ุฒูุงุฏุฉ ุงูุนูู ููุจุงุฏุฆุงุช ุงูุงุดุชูุงููุฉ,
    if word.startswith("ู"):"
    depth += 1  # ุงุณู ููุนูู ุฃู ููุงู,
    if word.startswith("ูู"):"
    depth += 1  # ุงุณู ูุงุนู,
    if word.startswith("ุงุณุช"):"
    depth += 2  # ุงุณุชูุนุงู,
    if word.startswith("ุงู"):"
    depth += 1  # ุงููุนุงู,
    return min(depth, 3)  # ุฃูุตู 3,
    def _generate_linguistic_summary()
    self, word: str, components: VectorComponents
    ) -> Dict[str, str]:
    """ุชูููุฏ ููุฎุต ูุบูู ููุชุญููู"""

        # ุชุฑุฌูุฉ ุงูููู ุงูุฑูููุฉ ุฅูู ุฃูุตุงู ูุบููุฉ,
    definiteness_labels = ["ูุนุฑูู", "ููุฑุฉ", "ุนูู", "ุถููุฑ"]"
    case_labels = ["ูุฑููุน", "ููุตูุจ", "ูุฌุฑูุฑ", "ุบูุฑ ูุญุฏุฏ"]"
    gender_labels = ["ูุฐูุฑ", "ูุคูุซ", "ูุดุชุฑู"]"
    number_labels = ["ููุฑุฏ", "ูุซูู", "ุฌูุน"]"

    return {
    "ุงูุชุนุฑูู": definiteness_labels[components.definiteness],"
    "ุงูุฅุนุฑุงุจ": ()"
    case_labels[components.case_marking]
                if components.case_marking < 4,
    else "ุบูุฑ ูุญุฏุฏ""
    ),
    "ุงูุฌูุฏุฑ": gender_labels[components.gender],"
    "ุงูุนุฏุฏ": number_labels[components.number],"
    "ุนุฏุฏ ุงููููููุงุช": str(components.phoneme_count),"
    "ุนุฏุฏ ุงูููุงุทุน": str(components.syllable_count),"
    "ุทูู ุงูุฌุฐุฑ": str(components.root_length),"
    "ุงูุชุตุบูุฑ": "ูุนู" if components.diminutive_form > 0 else "ูุง","
    "ุงูุชุตุฑูู ุงูุดุงุฐ": "ูุนู" if components.irregular_inflection else "ูุง","
    "ุงูุฅุฏุบุงู ุงูุดูุณู": "ูุนู" if components.sun_moon_assimilation else "ูุง","
    }


def demonstrate_system():
    """ุนุฑุถ ุชูุถูุญู ูููุธุงู"""

    # ุฅูุดุงุก ููููุฏ ุงููุชุฌู,
    generator = ArabicDigitalVectorGenerator()

    # ูููุงุช ุงุฎุชุจุงุฑ ูุชููุนุฉ,
    test_cases = [
    {"word": "ุงููุชุงุจ", "context": {"semantic_role": "patient"}},"
    {"word": "ูุฏุฑุณุฉ", "context": {"semantic_role": "location"}},"
    {"word": "ููุชูููุจ", "context": {"semantic_role": "patient"}},  # ุชุตุบูุฑ"
    {"word": "ููุฏุฑููุณ", "context": {"semantic_role": "agent"}},  # ุงุณู ูุงุนู"
    {"word": "ููุชูุจ", "context": {"semantic_role": "patient"}},  # ุงุณู ููุนูู"
    {"word": "ุงุณุชุฎุฑุงุฌ", "context": {"semantic_role": "manner"}},  # ูุตุฏุฑ"
    ]

    print("๐ฅ ููููุฏ ุงููุชุฌู ุงูุฑููู ุงููุชูุฏู ูููููุงุช ุงูุนุฑุจูุฉ ุงูููุฑุฏุฉ")"
    print("=" * 70)"
    print("๐ ุงูููุฒุงุช ุงููููููุฐุฉ:")"
    print("   โ ุงูุชุนููู ุงููุนุฑูู ูุงูููุฑุฉ ูุงูุนูู")"
    print("   โ ุญุงูุฉ ุงูุงุณู ูุงูุฅุนุฑุงุจ (ูุฑููุน/ููุตูุจ/ูุฌุฑูุฑ)")"
    print("   โ ููุงุนุฏ ุฅุฏุบุงู ุงููุงู ูุน ุงูุญุฑูู ุงูุดูุณูุฉ ูุงูููุฑูุฉ")"
    print("   โ ุญุงูุฉ ุงูุฅุถุงูุฉ ุงููุญููุฉ")"
    print("   โ ุงูุฌูุฏุฑ ูุงูุงุชูุงู ุงูุตุฑูู")"
    print("   โ ุงูุชุตุบูุฑ (ููุนููููุ ููุนูููููุฉุ ููุนูููุนูู)")"
    print("   โ ุงูุชูุฒูุน ุงูุตูุชู ูุงููุญูู (ุงููุจุฑ ูุงูุนุฑูุถ)")"
    print("   โ ุงูุชุตุฑูู ุงูุดุงุฐ")"
    print("   โ ุงูุชุซููุฉ ูุงูุฌูุน ูุงูุชุฏุงุฏ ููููุฑุฏ")"
    print("   โ ุงูุนูุงูุงุช ุงูุฏูุงููุฉ ูุงูุฃุฏูุงุฑ")"
    print("   โ ุงูุชุบููุฑุงุช ุงูุตูุชูุฉ ุงูุงุณุชุซูุงุฆูุฉ")"
    print("   โ ุงูููุฐุฌุฉ ุงูุชูุจุคูุฉ ูุงูุชุตููู")"
    print("=" * 70)"

    for i, test_case in enumerate(test_cases, 1):
    word = test_case["word"]"
    context = test_case["context"]"

    print(f"\n๐ ุงุฎุชุจุงุฑ {i}: ุชุญููู ุงููููุฉ '{word}")'"
    print(" " * 50)"

        # ุชูููุฏ ุงููุชุฌู,
    result = generator.generate_vector(word, context)

        if result["processing_status"] == "success":"
            # ุนุฑุถ ุงูููุฎุต ุงููุบูู,
    summary = result["linguistic_analysis"]"
    print(f"๐ฏ ุงูููุฎุต ุงููุบูู:")"
            for key, value in summary.items():
    print(f"   {key}: {value}")"

            # ุนุฑุถ ุฃุจุนุงุฏ ุงููุชุฌู,
    vector = result["numerical_vector"]"
    print(f"\n๐ข ุงููุชุฌู ุงูุฑููู:")"
    print(f"   ุงูุฃุจุนุงุฏ ุงููููุฉ: {len(vector)}")"
    print(f"   ุฃูู 10 ุนูุงุตุฑ: {[f'{x:.3f' for x} in vector[:10]]}}")'"
    print(f"   ุขุฎุฑ 10 ุนูุงุตุฑ: {[f'{x:.3f' for x} in vector[-10:]]}}")'"

            # ุนุฑุถ ุจุนุถ ุงูููุฒุงุช ุงููุชูุฏูุฉ,
    components = result["vector_components"]"
    print(f"\n๐ฌ ููุฒุงุช ูุชูุฏูุฉ:")"
    print(f"   ูุณุจุฉ ุงูุชูุฎูู: {components['emphatic_ratio']:.3f}")'"
    print(f"   ุงูุชุนูุฏ ุงูุตุฑูู: {components['morphological_complexity']:.3f}")'"
    print(f"   ุงูููููุณูุฉ: {components['concreteness']:.3f}")'"

        else:
    print(f"โ ูุดู ุงูุชุญููู: {result['error']}")'"

    print(f"\n๐ ุงูุชูุงุก ุงูุนุฑุถ ุงูุชูุถูุญู")"
    print("๐ก ุงููุธุงู ุฌุงูุฒ ููุนุงูุฌุฉ ุฃู ูููุฉ ุนุฑุจูุฉ ููุฑุฏุฉ ูุน ุชุญููู ุดุงูู!")"


if __name__ == "__main__":"
    demonstrate_system()

