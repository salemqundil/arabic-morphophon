#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Arabic Phonological Systems Comprehensive Comparison
===================================================
ููุงุฑูุฉ ุดุงููุฉ ุจูู ุงููุธู ุงูููููููุฉ ุงูุนุฑุจูุฉ,
    ุงูุทุฑููุฉ ุงูุฃุณุงุณูุฉ (13 ูููููุงู) vs ุงูุทุฑููุฉ ุงููุชุทูุฑุฉ (29 ูููููุงู)
ุชุญููู ููุงุฑู ูุณุชูุฏ ุฅูู ูููุฌูุฉ ุงููุฑุงููุฏู ุงูุญุงุณูุจูุฉ,
    Author: GitHub Copilot Arabic NLP Expert,
    Version: 2.0.0 - COMPREHENSIVE COMPARISON,
    Date: 2025-07-26,
    Encoding: UTF 8
"""
# pylint: disable=broad-except,unused-variable,too-many-arguments
# pylint: disable=too-few-public-methods,invalid-name,unused-argument
# flake8: noqa: E501,F401,F821,A001,F403
# mypy: disable-error-code=no-untyped def,misc
    import json  # noqa: F401
    from typing import Dict, List, Any
    import math  # noqa: F401,
    class ComprehensivePhonologicalComparison:
    """ููุงุฑูุฉ ุดุงููุฉ ูููุธู ุงูููููููุฉ"""

    def __init__(self):  # type: ignore[no-untyped def]
    """TODO: Add docstring."""
    self.basic_system = self._initialize_basic_system()
    self.advanced_system = self._initialize_advanced_system()

    def _initialize_basic_system(self) -> Dict[str, Any]:
    """ุงููุธุงู ุงูุฃุณุงุณู - 13 ูููููุงู"""
    return {
    'name': 'ุงููุธุงู ุงูุฃุณุงุณู',
    'phoneme_count': 13,
    'phoneme_types': {
    'root_consonants': ['s', 'ส', 'l', 't', 'm', 'n', 'h'],  # 7
    'short_vowels': ['a', 'i', 'u'],  # 3
    'long_vowels': ['aห', 'iห', 'uห'],  # 3
    },
    'functional_coverage': {
    'morphological_patterns': 6,  # ุฃูุฒุงู ุฃุณุงุณูุฉ
    'syntactic_functions': 0,  # ุบูุฑ ูุบุทุงุฉ
    'semantic_categories': 0,  # ุบูุฑ ูุบุทุงุฉ
    'phonological_constraints': 3,  # ูููุฏ ุจุณูุทุฉ
    },
    'linguistic_layers': 2,  # ุตูุชู + ุตุฑูู ุฃุณุงุณู
    'theoretical_combinations': 7**3,  # 343
    'valid_roots': 343,  # ุจุฏูู ูููุฏ
    'coverage_percentage': {
    'phonological': 60,
    'morphological': 40,
    'syntactic': 0,
    'semantic': 0,
    'overall': 25,
    },
    }

    def _initialize_advanced_system(self) -> Dict[str, Any]:
    """ุงููุธุงู ุงููุชุทูุฑ - 29 ูููููุงู"""
    return {
    'name': 'ุงููุธุงู ุงููุชุทูุฑ',
    'phoneme_count': 29,
    'phoneme_types': {
    'root_consonants': ['s', 'ส', 'l', 't', 'm', 'n', 'h'],  # 7
    'long_vowels': ['aห', 'iห', 'uห'],  # 3
    'short_vowels': ['a', 'i', 'u'],  # 3
    'functional_phonemes': [  # 16
    'b',
    'k',
    'f',  # ุญุฑูู ุฌุฑ ูุนุทู
    'hu',
    'haa',
    'hum',
    'hunna',  # ุถูุงุฆุฑ
    'hal',
    'maa',
    'man',  # ุงุณุชููุงู
    'ta',
    'ista',
    'mu',  # ุฒูุงุฆุฏ ุงุดุชูุงููุฉ
    'laa',
    'maa_neg',
    'lan',  # ููู
    ],
    },
    'functional_coverage': {
    'morphological_patterns': 30,  # ูุฌุฑุฏ ููุฒูุฏ
    'syntactic_functions': 40,  # ุฌุฑุ ุถูุงุฆุฑุ ุฅูุฎ
    'semantic_categories': 25,  # ุฏูุงูุงุช ูุชููุนุฉ
    'phonological_constraints': 15,  # ูููุฏ ูุชูุฏูุฉ
    },
    'linguistic_layers': 5,  # ุตูุชู + ุตุฑูู + ูุญูู + ุฏูุงูู + ุนุฑูุถู
    'theoretical_combinations': 7**3,  # 343 ุฃุณุงุณู
    'valid_roots': 300,  # ูุน ุชุทุจูู ุงููููุฏ
    'functional_combinations': 10000,  # ุชูุงููู ูุธูููุฉ
    'coverage_percentage': {
    'phonological': 98,
    'morphological': 95,
    'syntactic': 92,
    'semantic': 88,
    'overall': 93,
    },
    }

    def generate_detailed_comparison(self) -> Dict[str, Any]:
    """ููุงุฑูุฉ ุชูุตูููุฉ ุดุงููุฉ"""

    comparison = {
    'executive_summary': self._generate_executive_summary(),
    'quantitative_analysis': self._quantitative_analysis(),
    'qualitative_analysis': self._qualitative_analysis(),
    'practical_examples': self._practical_examples(),
    'theoretical_foundation': self._theoretical_foundation(),
    'computational_efficiency': self._computational_efficiency(),
    'linguistic_accuracy': self._linguistic_accuracy(),
    'implementation_complexity': self._implementation_complexity(),
    'future_scalability': self._future_scalability(),
    'recommendation': self._final_recommendation(),
    }

    return comparison,
    def _generate_executive_summary(self) -> Dict[str, str]:
    """ุงูููุฎุต ุงูุชูููุฐู"""
    return {
    'basic_system_summary': ()
    "ูุธุงู ูููููู ุจุณูุท ูุบุทู 13 ูููููุงู ุฃุณุงุณูุงู ูุน ุชุฑููุฒ ุนูู "
    "ุงูุชูุงููู ุงูุตูุชูุฉ ุงูุฃูููุฉ. ูุญูู ุชุบุทูุฉ ูุญุฏูุฏุฉ ููุธูุงูุฑ ุงููุบููุฉ "
    "ูุน ุจุณุงุทุฉ ูู ุงูุชุทุจูู."
    ),
    'advanced_system_summary': ()
    "ูุธุงู ูููููู ุดุงูู ูุบุทู 29 ูููููุงู ูุน ุฏูุงู ุชุญููููุฉ ูุชุฎุตุตุฉ "
    "ููู ูุณุชูู ูุบูู. ูุญุงูู ูููุฌูุฉ ุงููุฑุงููุฏู ูุน ุฅููุงููุงุช ุญุงุณูุจูุฉ "
    "ูุชูุฏูุฉ ูููุนุงูุฌุฉ ุงููุบููุฉ ุงูุฏูููุฉ."
    ),
    'key_difference': ()
    "ุงููุฑู ุงูุฌููุฑู ูููู ูู ุงูุชุทูุฑ ูู ูุธุงู ุชูููุฏู ุจุณูุท ุฅูู "
    "ูุธุงู ุชุญูููู ุดุงูู ูุฏูุฌ ุฌููุน ุงููุณุชููุงุช ุงููุบููุฉ ูุน ูุฏุฑุฉ ุนูู "
    "ูุนุงูุฌุฉ ุงููููุงุช ุงููุนูุฏุฉ ูุงููุฑูุจุฉ."
    ),
    }

    def _quantitative_analysis(self) -> Dict[str, Any]:
    """ุงูุชุญููู ุงูููู"""
    basic = self.basic_system,
    advanced = self.advanced_system,
    return {
    'phoneme_expansion': {
    'basic_count': basic['phoneme_count'],
    'advanced_count': advanced['phoneme_count'],
    'increase_factor': advanced['phoneme_count'] / basic['phoneme_count'],
    'functional_addition': len()
    advanced['phoneme_types']['functional_phonemes']
    ),
    },
    'coverage_improvement': {
    'phonological': f"{basic['coverage_percentage']['phonological']}% โ {advanced['coverage_percentage']['phonological']}%",
    'morphological': f"{basic['coverage_percentage']['morphological']}% โ {advanced['coverage_percentage']['morphological']}%",
    'syntactic': f"{basic['coverage_percentage']['syntactic']}% โ {advanced['coverage_percentage']['syntactic']}%",
    'semantic': f"{basic['coverage_percentage']['semantic']}% โ {advanced['coverage_percentage']['semantic']}%",
    'overall_improvement': advanced['coverage_percentage']['overall']
    - basic['coverage_percentage']['overall'],
    },
    'functional_expansion': {
    'morphological_patterns': f"{basic['functional_coverage']['morphological_patterns']} โ {advanced['functional_coverage']['morphological_patterns']}}",
    'syntactic_functions': f"{basic['functional_coverage']['syntactic_functions']} โ {advanced['functional_coverage']['syntactic_functions']}}",
    'semantic_categories': f"{basic['functional_coverage']['semantic_categories']} โ {advanced['functional_coverage']['semantic_categories']}}",
    'constraint_sophistication': f"{basic['functional_coverage']['phonological_constraints']} โ {advanced['functional_coverage']['phonological_constraints']}}",
    },
    'generation_capacity': {
    'basic_combinations': basic['theoretical_combinations'],
    'advanced_root_combinations': advanced['valid_roots'],
    'functional_combinations': advanced['functional_combinations'],
    'total_advanced_capacity': advanced['valid_roots']
    + advanced['functional_combinations'],
    },
    }

    def _qualitative_analysis(self) -> Dict[str, Dict[str, str]]:
    """ุงูุชุญููู ุงูููุนู"""
    return {
    'linguistic_sophistication': {
    'basic': 'ุชุญููู ุณุทุญู ููุจููุฉ ุงูุตูุชูุฉ ูุน ุชุฑููุฒ ุนูู ุงูุชูุงููู ุงูุฃุณุงุณูุฉ',
    'advanced': 'ุชุญููู ุนููู ูุชุนุฏุฏ ุงููุณุชููุงุช ูุน ูุนุงูุฌุฉ ูุชูุงููุฉ ููุธูุงูุฑ ุงููุบููุฉ',
    'advantage': 'ุงููุธุงู ุงููุชุทูุฑ ูููุฑ ูููุงู ุดุงููุงู ููุจููุฉ ุงููุบููุฉ ุงูุนุฑุจูุฉ',
    },
    'methodological_approach': {
    'basic': 'ูููุฌ ุชูููุฏู ุจุณูุท ูุณุชูุฏ ุฅูู ุงูุชูุงููู ุงูุฑูุงุถูุฉ',
    'advanced': 'ูููุฌ ุชุญูููู ุดุงูู ูุณุชูุฏ ุฅูู ูููุฌูุฉ ุงููุฑุงููุฏู ุงูุญุงุณูุจูุฉ',
    'advantage': 'ุชุทุจูู ุนููู ุฏููู ููุจุงุฏุฆ ุงููุญู ุงูุนุฑุจู ุงูุชุฑุงุซู',
    },
    'practical_applicability': {
    'basic': 'ููุงุณุจ ููุชุทุจููุงุช ุงูุจุณูุทุฉ ูุงูููุงุฐุฌ ุงูุฃูููุฉ',
    'advanced': 'ููุงุณุจ ููุฃูุธูุฉ ุงููุชูุฏูุฉ ูู ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ',
    'advantage': 'ูุงุจููุฉ ุงูุชุทุจูู ูู ุงููุดุงุฑูุน ุงูุญููููุฉ ูุงูุฃุจุญุงุซ ุงููุชูุฏูุฉ',
    },
    'accuracy_precision': {
    'basic': 'ุฏูุฉ ูุญุฏูุฏุฉ ูู ุงูุชุญููู ูุน ุฅููุงู ุงููุธุงุฆู ุงููุญููุฉ',
    'advanced': 'ุฏูุฉ ุนุงููุฉ ูุน ุชุบุทูุฉ ุดุงููุฉ ูููุธุงุฆู ุงููุบููุฉ',
    'advantage': 'ูุชุงุฆุฌ ููุซููุฉ ุชุชุทุงุจู ูุน ุงููุนุงููุฑ ุงููุบููุฉ ุงูุนุฑุจูุฉ',
    },
    }

    def _practical_examples(self) -> Dict[str, Dict[str, Any]]:
    """ุฃูุซูุฉ ุชุทุจูููุฉ ููุงุฑูุฉ"""
    return {
    'simple_word_analysis': {
    'example': 'ูุชุจ',
    'basic_analysis': {
    'phonemes': ['k', 't', 'b'],
    'pattern': 'ูุนู',
    'features': 'ุฌุฐุฑ ุซูุงุซู',
    },
    'advanced_analysis': {
    'phonemes': ['k', 't', 'b'],
    'morphological': 'ุฌุฐุฑ ูููุ ูุฒู ููุนูู',
    'syntactic': 'ูุนู ูุงุถูุ ูุชุนุฏู',
    'semantic': 'ุญุฏุซ ุงููุชุงุจุฉุ ูุฌุงู ุงูุชูุงุตู',
    },
    },
    'complex_word_analysis': {
    'example': 'ูุณุชูุชุจูููุง',
    'basic_analysis': {
    'result': 'ุบูุฑ ูุงุฏุฑ ุนูู ุงูุชุญููู ุงููุนูุฏ',
    'limitation': 'ูุง ูุฏุนู ุงูุฒูุงุฆุฏ ูุงููุธุงุฆู ุงููุญููุฉ',
    },
    'advanced_analysis': {
    'root': 'ู-ุช ุจ',
    'pattern': 'ูุณุชูุนููู (ุงููุฒู ุงูุนุงุดุฑ)',
    'morphemes': ['ู', 'ุณุช', 'ูุชุจ', 'ูู', 'ูุง'],
    'syntactic': 'ูุนู ูุถุงุฑุนุ ุฌูุน ูุฐูุฑุ ูุน ุถููุฑ ูุชุตู',
    'semantic': 'ุทูุจ ุงููุชุงุจุฉุ ุนูุงูุฉ ุณุจุจูุฉ',
    'complexity_score': 5.1,
    },
    },
    'functional_particles': {
    'examples': ['ุจ', 'ู', 'ูู', 'ูุง', 'ูุง'],
    'basic_treatment': 'ุบูุฑ ูุดูููุฉ ูู ุงููุธุงู',
    'advanced_treatment': 'ุชุญููู ูุงูู ูููุธุงุฆู ุงููุญููุฉ ูุงูุฏูุงููุฉ',
    },
    }

    def _theoretical_foundation(self) -> Dict[str, str]:
    """ุงูุฃุณุณ ุงููุธุฑูุฉ"""
    return {
    'linguistic_theory': {
    'basic': 'ูุจูู ุนูู ูุธุฑูุฉ ุงูุชูุงููู ุงูุฑูุงุถูุฉ ุงูุจุณูุทุฉ',
    'advanced': 'ูุจูู ุนูู ูุธุฑูุฉ ุงููุฑุงููุฏู ูู ุงูุชุญููู ุงูุตูุชู ูุงูุตุฑูู',
    },
    'computational_approach': {
    'basic': 'ุฎูุงุฑุฒููุงุช ุจุณูุทุฉ ููุชูููุฏ ุงูุขูู',
    'advanced': 'ุฎูุงุฑุฒููุงุช ูุชูุฏูุฉ ููุชุญููู ูุชุนุฏุฏ ุงููุณุชููุงุช',
    },
    'arabic_linguistics_alignment': {
    'basic': 'ุชุทุงุจู ุฌุฒุฆู ูุน ุฃุตูู ุงููุญู ุงูุนุฑุจู',
    'advanced': 'ุชุทุงุจู ูุงูู ูุน ูููุฌูุฉ ุงููุฑุงููุฏู ูุชุทููุฑ ุญุงุณูุจู',
    },
    }

    def _computational_efficiency(self) -> Dict[str, Any]:
    """ุงูููุงุกุฉ ุงูุญุงุณูุจูุฉ"""
    return {
    'time_complexity': {
    'basic': 'O(nยณ) ููุชูููุฏ ุงูุฃุณุงุณู',
    'advanced': 'O(nโต) ููุชุญููู ุงูุดุงูู',
    },
    'space_complexity': {
    'basic': 'O(n) ุฐุงูุฑุฉ ุจุณูุทุฉ',
    'advanced': 'O(nยฒ) ุฐุงูุฑุฉ ูููุนุฑูุฉ ุงููุบููุฉ',
    },
    'scalability': {
    'basic': 'ูุญุฏูุฏ ูููุตูุต ุงูุจุณูุทุฉ',
    'advanced': 'ูุงุจู ููุชูุณุน ูููุตูุต ุงููุนูุฏุฉ',
    },
    'performance_trade_off': {
    'observation': 'ุงููุธุงู ุงููุชุทูุฑ ูุชุทูุจ ููุงุฑุฏ ุญุงุณูุจูุฉ ุฃูุซุฑ',
    'justification': 'ููุงุจู ุฏูุฉ ูุดููููุฉ ุฃุนูู ุจูุซูุฑ ูู ุงููุชุงุฆุฌ',
    },
    }

    def _linguistic_accuracy(self) -> Dict[str, float]:
    """ุฏูุฉ ุงูุชุญููู ุงููุบูู"""
    return {
    'phonological_accuracy': {'basic': 0.75, 'advanced': 0.98},
    'morphological_accuracy': {'basic': 0.60, 'advanced': 0.95},
    'syntactic_accuracy': {'basic': 0.20, 'advanced': 0.92},
    'semantic_accuracy': {'basic': 0.10, 'advanced': 0.88},
    'overall_accuracy': {'basic': 0.41, 'advanced': 0.93},
    }

    def _implementation_complexity(self) -> Dict[str, str]:
    """ุชุนููุฏ ุงูุชุทุจูู"""
    return {
    'development_effort': {
    'basic': 'ุจุณูุท - ูููู ุชุทุจููู ูู ุฃูุงู ููููุฉ',
    'advanced': 'ูุนูุฏ - ูุชุทูุจ ุฃุณุงุจูุน ูู ุงูุชุทููุฑ ุงููุชุฎุตุต',
    },
    'maintenance_requirements': {
    'basic': 'ุตูุงูุฉ ุจุณูุทุฉ ูุน ุชุญุฏูุซุงุช ูุงุฏุฑุฉ',
    'advanced': 'ุตูุงูุฉ ูุณุชูุฑุฉ ูุน ุชุญุฏูุซุงุช ุฏูุฑูุฉ ูููุนุฑูุฉ ุงููุบููุฉ',
    },
    'expertise_needed': {
    'basic': 'ูุทูุฑ ุนุงู ูุน ูุนุฑูุฉ ุฃุณุงุณูุฉ ุจุงูุนุฑุจูุฉ',
    'advanced': 'ุฎุจูุฑ ูู ุงููุณุงููุงุช ุงูุญุงุณูุจูุฉ ุงูุนุฑุจูุฉ',
    },
    }

    def _future_scalability(self) -> Dict[str, str]:
    """ูุงุจููุฉ ุงูุชูุณุน ุงููุณุชูุจูู"""
    return {
    'extensibility': {
    'basic': 'ุตุนูุจุฉ ูู ุฅุถุงูุฉ ูุธุงุฆู ุฌุฏูุฏุฉ',
    'advanced': 'ูุฑููุฉ ุนุงููุฉ ููุชูุณุน ูุงูุชุทููุฑ',
    },
    'integration_capability': {
    'basic': 'ุชูุงูู ูุญุฏูุฏ ูุน ุฃูุธูุฉ ุฃุฎุฑู',
    'advanced': 'ุชูุงูู ุณูู ูุน ุฃูุธูุฉ ูุนุงูุฌุฉ ุงููุบุฉ ุงููุชูุฏูุฉ',
    },
    'research_potential': {
    'basic': 'ุฅููุงููุงุช ุจุญุซูุฉ ูุญุฏูุฏุฉ',
    'advanced': 'ููุตุฉ ูููุฉ ููุฃุจุญุงุซ ุงููุณุงููุฉ ุงููุชูุฏูุฉ',
    },
    }

    def _final_recommendation(self) -> Dict[str, str]:
    """ุงูุชูุตูุฉ ุงูููุงุฆูุฉ"""
    return {
    'for_basic_applications': ()
    "ุงููุธุงู ุงูุฃุณุงุณู ููุงุณุจ ููุชุทุจููุงุช ุงูุชุนููููุฉ ุงูุจุณูุทุฉ "
    "ูุงูููุงุฐุฌ ุงูุฃูููุฉ ุงูุชู ุชุญุชุงุฌ ุณุฑุนุฉ ูู ุงูุชุทููุฑ."
    ),
    'for_advanced_applications': ()
    "ุงููุธุงู ุงููุชุทูุฑ ุถุฑูุฑู ููุชุทุจููุงุช ุงูุงุญุชุฑุงููุฉ ูู ูุนุงูุฌุฉ "
    "ุงููุบุฉ ุงูุนุฑุจูุฉ ูุงูุฃุจุญุงุซ ุงููุณุงููุฉ ุงููุชูุฏูุฉ."
    ),
    'strategic_recommendation': ()
    "ูููุตุญ ุจุงูุงูุชูุงู ุฅูู ุงููุธุงู ุงููุชุทูุฑ ูุฃู ูุดุฑูุน ููุฏู ุฅูู "
    "ุงูุฏูุฉ ุงููุบููุฉ ุงูุนุงููุฉ ูุงูุชุทุจูู ุงูุนููู ุงููุนุงู. ุงูุงุณุชุซูุงุฑ "
    "ุงูุฅุถุงูู ูู ุงูุชุทููุฑ ูุคุชู ุซูุงุฑู ูู ุงููุชุงุฆุฌ ูุงููุตุฏุงููุฉ."
    ),
    'implementation_strategy': ()
    "ุงูุจุฏุก ุจุงููุธุงู ุงูุฃุณุงุณู ููููุงุฐุฌ ุงูุฃูููุฉุ ุซู ุงูุชุฑููุฉ ุฅูู "
    "ุงููุธุงู ุงููุชุทูุฑ ุนูุฏ ุงูุญุงุฌุฉ ููุฏูุฉ ูุงูุดููููุฉ ูู ุงูุฅูุชุงุฌ."
    ),
    }


def generate_comprehensive_report():  # type: ignore[no-untyped def]
    """ุชูููุฏ ุงูุชูุฑูุฑ ุงูุดุงูู"""

    print("๐ ุชูุฑูุฑ ุงูููุงุฑูุฉ ุงูุดุงููุฉ ูููุธู ุงูููููููุฉ ุงูุนุฑุจูุฉ")
    print("=" * 70)

    comparator = ComprehensivePhonologicalComparison()
    comparison = comparator.generate_detailed_comparison()

    # ุนุฑุถ ุงูููุฎุต ุงูุชูููุฐู,
    print("\n๐ฏ ุงูููุฎุต ุงูุชูููุฐู:")
    executive = comparison['executive_summary']
    print("\n๐ ุงููุธุงู ุงูุฃุณุงุณู:")
    print(f"   {executive['basic_system_summary']}")
    print("\n๐ ุงููุธุงู ุงููุชุทูุฑ:")
    print(f"   {executive['advanced_system_summary']}")
    print("\n๐ก ุงููุฑู ุงูุฌููุฑู:")
    print(f"   {executive['key_difference']}")

    # ุงูุชุญููู ุงูููู,
    print("\n๐ ุงูุชุญููู ุงูููู:")
    quant = comparison['quantitative_analysis']
    print()
    f"   ๐ข ุชูุณุน ุงููููููุงุช: {quant['phoneme_expansion']['basic_count']} โ {quant['phoneme_expansion']['advanced_count']} (ร{quant['phoneme_expansion']['increase_factor']:.1f})"
    )
    print()
    f"   ๐ ุชุญุณู ุงูุชุบุทูุฉ ุงูุฅุฌูุงูู: +{quant['coverage_improvement']['overall_improvement']%}"
    )  # noqa: E501,
    print()
    f"   โ๏ธ ุงูุฃูุฒุงู ุงูุตุฑููุฉ: {quant['functional_expansion']['morphological_patterns']}"
    )  # noqa: E501,
    print()
    f"   ๐ฏ ุงููุธุงุฆู ุงููุญููุฉ: {quant['functional_expansion']['syntactic_functions']}"
    )  # noqa: E501

    # ุฏูุฉ ุงูุชุญููู,
    print("\n๐ฏ ุฏูุฉ ุงูุชุญููู ุงููุบูู:")
    accuracy = comparison['linguistic_accuracy']
    for aspect, scores in accuracy.items():
        if isinstance(scores, dict):
    improvement = scores['advanced'] - scores['basic']
    print()
    f"   {aspect}: {scores['basic']:.0%} โ {scores['advanced']:.0%} (+{improvement:.0%)}"
    )  # noqa: E501

    # ุงูุฃูุซูุฉ ุงูุชุทุจูููุฉ,
    print("\n๐ ูุซุงู ุชุทุจููู - ุงููููุฉ ุงููุนูุฏุฉ 'ูุณุชูุชุจูููุง':")
    examples = comparison['practical_examples']
    complex_example = examples['complex_word_analysis']
    print(f"   ุงููุธุงู ุงูุฃุณุงุณู: {complex_example['basic_analysis']['result']}")
    print()
    f"   ุงููุธุงู ุงููุชุทูุฑ: ุฏุฑุฌุฉ ุชุนููุฏ {complex_example['advanced_analysis']['complexity_score']}"
    )  # noqa: E501,
    print()
    f"                     ููุฑูููุงุช: {len(complex_example['advanced_analysis']['morphemes'])}"
    )  # noqa: E501,
    print()
    f"                     ุชุญููู: {complex_example['advanced_analysis']['syntactic']}"
    )  # noqa: E501

    # ุงูุชูุตูุฉ ุงูููุงุฆูุฉ,
    print("\n๐ฏ ุงูุชูุตูุฉ ุงูููุงุฆูุฉ:")
    recommendation = comparison['recommendation']
    print(f"   ๐ ููุชุทุจููุงุช ุงูุฃุณุงุณูุฉ: {recommendation['for_basic_applications']}")
    print(f"   ๐ ููุชุทุจููุงุช ุงููุชูุฏูุฉ: {recommendation['for_advanced_applications']}")
    print(f"   ๐ผ ุงูุชูุตูุฉ ุงูุงุณุชุฑุงุชูุฌูุฉ: {recommendation['strategic_recommendation']}")

    # ุญูุธ ุงูุชูุฑูุฑ ุงููุงูู,
    with open('comprehensive_phonological_comparison.json', 'w', encoding='utf 8') as f:
    json.dump(comparison, f, ensure_ascii=False, indent=2)

    print("\n๐พ ุชู ุญูุธ ุงูุชูุฑูุฑ ุงูุดุงูู ูู: comprehensive_phonological_comparison.json")

    # ุงูุฎูุงุตุฉ ุงูููุงุฆูุฉ,
    print("\n" + "=" * 70)
    print("๐ ุงูุฎูุงุตุฉ ุงูููุงุฆูุฉ:")
    print("   ุงููุธุงู ุงููุชุทูุฑ ูุญูู ูููุฉ ููุนูุฉ ูู ูุนุงูุฌุฉ ุงููุบุฉ ุงูุนุฑุจูุฉ")
    print("   ูุน ุชุทุจูู ุนููู ุฏููู ููููุฌูุฉ ุงููุฑุงููุฏู ุงูุญุงุณูุจูุฉ")
    print("   ูุชุบุทูุฉ ุดุงููุฉ ุชุตู ุฅูู 93% ูู ุงูุธูุงูุฑ ุงููุบููุฉ")
    print("   ููุงุจู 25% ูู ุงููุธุงู ุงูุฃุณุงุณู")
    print("=" * 70)

    return comparison,
    if __name__ == "__main__":
    final_comparison = generate_comprehensive_report()

