"""
ğŸ”¥ Comprehensive Tests for FrozenRootsEngine
Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ù…Ø­Ø±Ùƒ ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ø¬Ø§Ù…Ø¯Ø©

ÙŠØ®ØªØ¨Ø± Ø¬Ù…ÙŠØ¹ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø­Ø±Ùƒ:
âœ… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Ø¬Ø§Ù…Ø¯/Ù…Ø´ØªÙ‚)
âœ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø·Ø¹ÙŠ ÙˆØ§Ù„ÙÙˆÙ†ÙŠÙ…ÙŠ
âœ… ÙƒØ´Ù Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£ÙØ¹Ø§Ù„
âœ… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
âœ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…
"""
# pylint: disable=invalid-name,too-few-public-methods,too-many-instance-attributes,line-too-long


import_data unittest
import_data time
import_data sys
from pathlib import_data Path

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_root = Path(__file__).parents[2]
sys.path.insert(0, str(project_root))

from engines.nlp.frozen_root.engine import_data FrozenRootsEngine
from engines.nlp.frozen_root.models.classifier import_data AdvancedRootClassifier
from engines.nlp.frozen_root.models.syllabic_unit_check import_data SyllabicUnitAnalyzer
from engines.nlp.frozen_root.models.verb_check import_data VerbPatternRecognizer

class TestFrozenRootsEngine(unittest.TestCase):
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø­Ø±Ùƒ ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ø¬Ø§Ù…Ø¯Ø©"""
    
    @classmethod
    def setUpClass(cls):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
        cls.engine = FrozenRootsEngine()
        cls.test_data = {
            "frozen_words": [
                "Ù…Ù†", "Ù„Ù†", "Ø¥Ø°Ø§", "ÙŠØ§", "Ù„Ù…", "Ù‚Ø¯", "ÙƒÙ„Ø§", "Ù‡Ù„",
                "Ø¥Ù†", "Ø£Ù†", "ÙƒÙŠ", "Ù„ÙƒÙ†", "ØºÙŠØ±", "Ø³ÙˆÙ", "Ù„ÙŠØ³",
                "Ù…Ø§Ø°Ø§", "Ù…ØªÙ‰", "Ø£ÙŠÙ†", "ÙƒÙŠÙ", "Ù„Ù…Ø§Ø°Ø§", "Ø°Ù„Ùƒ", "Ù‡Ø°Ø§"
            ],
            "derivable_words": [
                "ÙƒØªØ¨", "Ø¯Ø±Ø³", "ÙØ¹Ù„", "Ø¹Ù„Ù…", "Ø´Ø±Ø¨", "Ø£ÙƒÙ„",
                "ÙƒØ³Ù‘Ø±", "Ø¯Ø±Ù‘Ø³", "Ø¹Ù„Ù‘Ù…", "Ù‚Ø§ØªÙ„", "Ø´Ø§Ø±Ùƒ", "Ø³Ø§Ø¹Ø¯",
                "Ø§Ù†ÙƒØ³Ø±", "Ø§Ø¬ØªÙ…Ø¹", "Ø§Ø³ØªØ®Ø±Ø¬", "Ø§Ø³ØªØ¹Ù…Ù„"
            ]
        }
    
    def test_basic_classification_frozen(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ø¬Ø§Ù…Ø¯Ø©"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ - Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ø¬Ø§Ù…Ø¯Ø©")
        
        for word in self.test_data["frozen_words"]:
            with self.subTest(word=word):
                result = self.engine.classify(word)
                
                self.assertEqual(result["classification"], "frozen",
                               f"Ø§Ù„ÙƒÙ„Ù…Ø© '{word}' ÙŠØ¬Ø¨ Ø£Ù† ØªØµÙ†Ù ÙƒØ¬Ø§Ù…Ø¯Ø©")
                self.assertTrue(result["is_frozen"],
                              f"Ø§Ù„ÙƒÙ„Ù…Ø© '{word}' ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† is_frozen=True")
                self.assertFalse(result["is_derivable"],
                               f"Ø§Ù„ÙƒÙ„Ù…Ø© '{word}' ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† is_derivable=False")
                self.assertGreater(result["confidence"], 0.5,
                                 f"Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© Ù„Ù„ÙƒÙ„Ù…Ø© '{word}' Ù…Ù†Ø®ÙØ¶Ø©: {result['confidence']}")
                
                print(f"   âœ… {word}: {result['classification']} ({result['confidence']:.1%})")
    
    def test_basic_classification_derivable(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ù…Ø´ØªÙ‚Ø©"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ - Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ù…Ø´ØªÙ‚Ø©")
        
        for word in self.test_data["derivable_words"]:
            with self.subTest(word=word):
                result = self.engine.classify(word)
                
                self.assertEqual(result["classification"], "derivable",
                               f"Ø§Ù„ÙƒÙ„Ù…Ø© '{word}' ÙŠØ¬Ø¨ Ø£Ù† ØªØµÙ†Ù ÙƒÙ…Ø´ØªÙ‚Ø©")
                self.assertFalse(result["is_frozen"],
                               f"Ø§Ù„ÙƒÙ„Ù…Ø© '{word}' ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† is_frozen=False")
                self.assertTrue(result["is_derivable"],
                              f"Ø§Ù„ÙƒÙ„Ù…Ø© '{word}' ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† is_derivable=True")
                self.assertGreater(result["confidence"], 0.5,
                                 f"Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© Ù„Ù„ÙƒÙ„Ù…Ø© '{word}' Ù…Ù†Ø®ÙØ¶Ø©: {result['confidence']}")
                
                print(f"   âœ… {word}: {result['classification']} ({result['confidence']:.1%})")
    
    def test_detailed_analysis(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„")
        
        test_cases = [
            ("Ù…Ù†", "frozen"),
            ("ÙƒØªØ¨", "derivable"),
            ("Ø§Ø³ØªØ®Ø±Ø¬", "derivable"),
            ("Ø¥Ø°Ø§", "frozen")
        ]
        
        for word, expected_type in test_cases:
            with self.subTest(word=word):
                result = self.engine.analyze(word, detailed=True)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ§Øª
                self.assertEqual(result["type"], expected_type)
                self.assertIn("analysis", result)
                self.assertIn("cv_pattern", result["analysis"])
                self.assertIn("phonemes", result["analysis"])
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø·Ø¹ÙŠ
                if "syllabic_unit_analysis" in result:
                    syllabic_unit_data = result["syllabic_unit_analysis"]
                    self.assertIn("syllabic_units", syllabic_unit_data)
                    self.assertIn("syllabic_unit_count", syllabic_unit_data)
                    self.assertGreater(syllabic_unit_data["syllabic_unit_count"], 0)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙØ¹Ø§Ù„
                if "verb_pattern_analysis" in result:
                    verb_data = result["verb_pattern_analysis"]
                    self.assertIn("is_verb_pattern", verb_data)
                
                print(f"   âœ… {word}: {result['type']} | CV: {result['analysis']['cv_pattern']} | Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: {result.get('syllabic_unit_analysis', {}).get('syllabic_unit_count', 'N/A')}")
    
    def test_cv_patterns(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù†Ù…Ø§Ø· CV"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø£Ù†Ù…Ø§Ø· CV")
        
        expected_patterns = {
            "Ù…Ù†": "CVC",
            "Ø¥Ø°Ø§": "VCV", 
            "ÙƒØªØ¨": "CVCVC",
            "Ø§Ø³ØªØ®Ø±Ø¬": "CCVCVC",
            "Ù‚Ø§ØªÙ„": "CVVCVC",
            "ÙƒØ³Ù‘Ø±": "CVCCVC"
        }
        
        for word, expected_pattern in expected_patterns.items():
            with self.subTest(word=word):
                result = self.engine.analyze(word)
                actual_pattern = result["analysis"]["cv_pattern"]
                
                self.assertEqual(actual_pattern, expected_pattern,
                               f"Ù†Ù…Ø· CV Ù„Ù„ÙƒÙ„Ù…Ø© '{word}' Ø®Ø§Ø·Ø¦")
                
                print(f"   âœ… {word}: {actual_pattern}")
    
    def test_phoneme_analysis(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…ÙŠ"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…ÙŠ")
        
        test_words = ["Ù…Ù†", "ÙƒØªØ¨", "Ø¥Ø°Ø§", "Ù‚Ø§ØªÙ„"]
        
        for word in test_words:
            with self.subTest(word=word):
                result = self.engine.analyze(word, include_phonemes=True)
                phonemes = result["analysis"].get("phonemes", [])
                
                self.assertIsInstance(phonemes, list)
                self.assertGreater(len(phonemes), 0,
                                 f"Ù„Ø§ ØªÙˆØ¬Ø¯ ÙÙˆÙ†ÙŠÙ…Ø§Øª Ù„Ù„ÙƒÙ„Ù…Ø© '{word}'")
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±Ù…ÙˆØ² IPA ØµØ­ÙŠØ­Ø©
                for phoneme in phonemes:
                    self.assertIsInstance(phoneme, str)
                    self.assertGreater(len(phoneme), 0)
                
                print(f"   âœ… {word}: {phonemes}")
    
    def test_syllabic_unit_analysis(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹")
        
        test_words = ["ÙƒØªØ¨", "Ø§Ø³ØªØ®Ø±Ø¬", "Ù‚Ø§ØªÙ„", "Ù…Ù†"]
        
        for word in test_words:
            with self.subTest(word=word):
                result = self.engine.analyze(word, include_syllabic_units=True)
                
                if "syllabic_unit_analysis" in result:
                    syllabic_unit_data = result["syllabic_unit_analysis"]
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
                    self.assertIn("syllabic_units", syllabic_unit_data)
                    self.assertIn("syllabic_unit_count", syllabic_unit_data)
                    self.assertIn("complexity_score", syllabic_unit_data)
                    
                    syllabic_units = syllabic_unit_data["syllabic_units"]
                    self.assertIsInstance(syllabic_units, list)
                    self.assertGreater(len(syllabic_units), 0)
                    
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¨Ù†ÙŠØ© ÙƒÙ„ Ù…Ù‚Ø·Ø¹
                    for syllabic_unit in syllabic_units:
                        self.assertIn("pattern", syllabic_unit)
                        self.assertIn("phonemes", syllabic_unit)
                        self.assertIn("type", syllabic_unit)
                    
                    print(f"   âœ… {word}: {syllabic_unit_data['syllabic_unit_count']} Ù…Ù‚Ø§Ø·Ø¹ØŒ ØªØ¹Ù‚Ø¯: {syllabic_unit_data['complexity_score']:.2f}")
    
    def test_batch_processing(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©")
        
        batch_words = ["Ù…Ù†", "ÙƒØªØ¨", "Ø¥Ø°Ø§", "Ø¯Ø±Ø³", "Ù‡Ù„", "Ù‚Ø§ØªÙ„"]
        
        result = self.engine.batch_analyze(batch_words, detailed=False)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.assertIn("batch_summary", result)
        self.assertIn("results", result)
        
        batch_summary = result["batch_summary"]
        self.assertEqual(batch_summary["total_words"], len(batch_words))
        self.assertGreaterEqual(batch_summary["successful_analyses"], 0)
        self.assertGreaterEqual(batch_summary["batch_processing_time_ms"], 0)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ±Ø¯ÙŠØ©
        results = result["results"]
        for word in batch_words:
            self.assertIn(word, results)
            word_result = results[word]
            self.assertIn("type", word_result)
            self.assertIn("confidence", word_result)
        
        print(f"   âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© {batch_summary['total_words']} ÙƒÙ„Ù…Ø§Øª ÙÙŠ {batch_summary['batch_processing_time_ms']:.1f}ms")
        print(f"   âœ… Ù†Ø¬Ø­: {batch_summary['successful_analyses']}, ÙØ´Ù„: {batch_summary['failed_analyses']}")
    
    def test_performance_metrics(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡")
        
        # ØªÙ†ÙÙŠØ° Ø¹Ø¯Ø© ØªØµÙ†ÙŠÙØ§Øª Ù„ØªÙˆÙ„ÙŠØ¯ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        test_words = ["Ù…Ù†", "ÙƒØªØ¨", "Ø¥Ø°Ø§", "Ø¯Ø±Ø³", "Ù‡Ù„"]
        for word in test_words:
            self.engine.classify(word)
        
        stats = self.engine.get_performance_stats()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ù†ÙŠØ©
        self.assertIn("engine_info", stats)
        self.assertIn("performance_metrics", stats)
        self.assertIn("configuration", stats)
        self.assertIn("component_stats", stats)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        engine_info = stats["engine_info"]
        self.assertEqual(engine_info["name"], "frozen_root")
        self.assertEqual(engine_info["version"], "1.0.0")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        metrics = stats["performance_metrics"]
        self.assertGreaterEqual(metrics["total_classifications"], len(test_words))
        self.assertGreaterEqual(metrics["average_processing_time"], 0.0)
        
        print(f"   âœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª: {metrics['total_classifications']}")
        print(f"   âœ… Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {metrics['average_processing_time']:.4f}s")
        print(f"   âœ… Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ø¬Ø§Ù…Ø¯Ø©: {metrics['frozen_count']}")
        print(f"   âœ… Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ù…Ø´ØªÙ‚Ø©: {metrics['derivable_count']}")
    
    def test_error_handling(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡")
        
        error_cases = ["", "   ", "123", "!@#", None]
        
        for case in error_cases:
            if case is None:
                continue
                
            with self.subTest(case=case):
                result = self.engine.analyze(case)
                
                # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø®Ø·Ø£ Ø£Ùˆ ØªØ¹Ø§Ù…Ù„ ØµØ­ÙŠØ­
                if result["type"] == "error":
                    self.assertIn("reason", result)
                    self.assertEqual(result["confidence"], 0.0)
                    print(f"   âœ… Ø­Ø§Ù„Ø© Ø®Ø·Ø£ ØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§: '{case}'")
                else:
                    # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ø§Ù„ØµØ­ÙŠØ­ Ù…Ø¹ Ø§Ù„Ù…Ø¯Ø®Ù„
                    print(f"   âœ… ØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø¯Ø®Ù„: '{case}' -> {result['type']}")
    
    def test_word_details(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©")
        
        test_word = "Ø§Ø³ØªØ®Ø±Ø¬"
        details = self.engine.get_word_details(test_word)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.assertIn("word", details)
        self.assertIn("comprehensive_analysis", details)
        self.assertIn("classification_explanation", details)
        self.assertIn("linguistic_features", details)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ù„ØºÙˆÙŠØ©
        features = details["linguistic_features"]
        self.assertIn("cv_pattern", features)
        self.assertIn("phoneme_count", features)
        self.assertIn("syllabic_unit_count", features)
        self.assertIn("word_length", features)
        
        self.assertEqual(features["word_length"], len(test_word))
        
        print(f"   âœ… Ø§Ù„ÙƒÙ„Ù…Ø©: {details['word']}")
        print(f"   âœ… Ø§Ù„Ù†Ù…Ø· CV: {features['cv_pattern']}")
        print(f"   âœ… Ø¹Ø¯Ø¯ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª: {features['phoneme_count']}")
        print(f"   âœ… Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: {features['syllabic_unit_count']}")
        print(f"   âœ… Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: {details['classification_confidence']:.1%}")
    
    def test_speed_performance(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø±Ø¹Ø©"""
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø±Ø¹Ø©")
        
        test_words = ["Ù…Ù†", "ÙƒØªØ¨", "Ø¥Ø°Ø§", "Ø§Ø³ØªØ®Ø±Ø¬", "Ù‚Ø§ØªÙ„"] * 20  # 100 ÙƒÙ„Ù…Ø©
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø³Ø±ÙŠØ¹
        begin_time = time.time()
        for word in test_words:
            self.engine.classify(word)
        classify_time = time.time() - begin_time
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„
        begin_time = time.time()
        for word in test_words[:10]:  # 10 ÙƒÙ„Ù…Ø§Øª ÙÙ‚Ø· Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„
            self.engine.analyze(word, detailed=True)
        detailed_time = time.time() - begin_time
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡
        avg_classify_time = (classify_time / len(test_words)) * 1000  # Ø¨Ø§Ù„Ù…ÙŠÙ„ÙŠ Ø«Ø§Ù†ÙŠØ©
        avg_detailed_time = (detailed_time / 10) * 1000
        
        self.assertLess(avg_classify_time, 10,  # Ø£Ù‚Ù„ Ù…Ù† 10ms Ù„ÙƒÙ„ ØªØµÙ†ÙŠÙ
                       f"Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ø·ÙŠØ¡ Ø¬Ø¯Ø§Ù‹: {avg_classify_time:.2f}ms")
        self.assertLess(avg_detailed_time, 100,  # Ø£Ù‚Ù„ Ù…Ù† 100ms Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„
                       f"Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„ Ø¨Ø·ÙŠØ¡ Ø¬Ø¯Ø§Ù‹: {avg_detailed_time:.2f}ms")
        
        print(f"   âœ… Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„ØªØµÙ†ÙŠÙ: {avg_classify_time:.2f}ms")
        print(f"   âœ… Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØµÙ„: {avg_detailed_time:.2f}ms")
        print(f"   âœ… Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {len(test_words)/classify_time:.0f} ÙƒÙ„Ù…Ø©/Ø«Ø§Ù†ÙŠØ©")

class TestSyllabicUnitAnalyzer(unittest.TestCase):
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ù…Ù†ÙØµÙ„Ø©"""
    
    def setUp(self):
        self.analyzer = SyllabicUnitAnalyzer()
    
    def test_cv_pattern_extraction(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù†Ù…Ø§Ø· CV"""
        test_cases = {
            "ÙƒØªØ¨": "CVCVC",
            "Ù…Ù†": "CVC", 
            "Ø¥Ø°Ø§": "VCV",
            "Ø§Ø³ØªØ®Ø±Ø¬": "CCVCVC"
        }
        
        for word, expected in test_cases.items():
            actual = self.analyzer.get_cv_pattern(word)
            self.assertEqual(actual, expected,
                           f"Ù†Ù…Ø· CV Ø®Ø§Ø·Ø¦ Ù„Ù„ÙƒÙ„Ù…Ø© '{word}': ØªÙˆÙ‚Ø¹ {expected}, Ø­ØµÙ„ Ø¹Ù„Ù‰ {actual}")
    
    def test_phoneme_conversion(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª"""
        word = "ÙƒØªØ¨"
        phonemes = self.analyzer.get_phonemes(word)
        
        self.assertIsInstance(phonemes, list)
        self.assertGreater(len(phonemes), 0)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª Ù†ØµÙˆØµ
        for phoneme in phonemes:
            self.assertIsInstance(phoneme, str)

class TestVerbPatternRecognizer(unittest.TestCase):
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙƒØ§Ø´Ù Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ù…Ù†ÙØµÙ„Ø©"""
    
    def setUp(self):
        self.recognizer = VerbPatternRecognizer()
    
    def test_verb_pattern_recognition(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£ÙØ¹Ø§Ù„"""
        verb_patterns = ["CVCVC", "CVCCVC", "CVVCVC", "CCVCVC"]
        non_verb_patterns = ["CV", "VC", "CVC"]
        
        for pattern in verb_patterns:
            self.assertTrue(self.recognizer.is_verb_form(pattern),
                          f"Ø§Ù„Ù†Ù…Ø· {pattern} ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù†Ù…Ø· ÙØ¹Ù„")
        
        for pattern in non_verb_patterns:
            self.assertFalse(self.recognizer.is_verb_form(pattern),
                           f"Ø§Ù„Ù†Ù…Ø· {pattern} Ù„Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù†Ù…Ø· ÙØ¹Ù„")
    
    def test_derivation_potential(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„Ø§Ø´ØªÙ‚Ø§Ù‚"""
        high_derivability = "CVCVC"  # ÙÙØ¹ÙÙ„Ù
        result = self.recognizer.get_derivation_potential(high_derivability)
        
        self.assertEqual(result["potential"], "high")
        self.assertGreater(result["score"], 0.8)
        self.assertIsInstance(result["possible_derivations"], list)

def run_comprehensive_tests():
    """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
    print("ğŸ”¥ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù„Ù…Ø­Ø±Ùƒ ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬Ø°ÙˆØ± Ø§Ù„Ø¬Ø§Ù…Ø¯Ø©")
    print("=" * 80)
    
    # ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    test_suite = unittest.TestSuite()
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    test_suite.addTest(unittest.TestImporter().import_dataTestsFromTestCase(TestFrozenRootsEngine))
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©
    test_suite.addTest(unittest.TestImporter().import_dataTestsFromTestCase(TestSyllabicUnitAnalyzer))
    test_suite.addTest(unittest.TestImporter().import_dataTestsFromTestCase(TestVerbPatternRecognizer))
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print("\n" + "=" * 80)
    print("ğŸ“Š Ù…Ù„Ø®Øµ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:")
    print(f"   âœ… Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   âŒ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙØ´Ù„Øª: {len(result.failures)}")
    print(f"   ğŸš¨ Ø£Ø®Ø·Ø§Ø¡: {len(result.errors)}")
    print(f"   ğŸ“ˆ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100):.1f}%")
    
    if result.failures:
        print("\nâŒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©:")
        for test, traceback in result.failures:
            print(f"   - {test}: {traceback.split('AssertionError: ')[-1].split('\\n')[0]}")
    
    if result.errors:
        print("\nğŸš¨ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:")
        for test, traceback in result.errors:
            print(f"   - {test}: {traceback.split('\\n')[-2]}")
    
    return result.wasSuccessful()

if __name__ == "__main__":
    success = run_comprehensive_tests()
    
    if success:
        print("\nğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª! Ù…Ø­Ø±Ùƒ FrozenRootsEngine Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¥Ù†ØªØ§Ø¬.")
    else:
        print("\nâš ï¸  Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙØ´Ù„Øª. ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£Ø¹Ù„Ø§Ù‡.")
        sys.exit(1)
