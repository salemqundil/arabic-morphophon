"""
ğŸ”¥ Ù…Ù„Ù Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
=======================================================

Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ÙŠØ®ØªØ¨Ø± Ø¬Ù…ÙŠØ¹ ÙˆØ¸Ø§Ø¦Ù FullPipeline Engine ÙˆÙŠØ¹Ø±Ø¶ Ø¥Ù…ÙƒØ§Ù†ÙŠØ§ØªÙ‡ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
"""
# pylint: disable=invalid-name,too-few-public-methods,too-many-instance-attributes,line-too-long


import_data sys
import_data os
import_data json
from datetime import_data datetime

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from engines.nlp.full_pipeline.engine import_data FullPipelineEngine, create_flask_app

def test_pipeline_engine():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
    
    print("ğŸ”¥ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    print("=" * 60)
    
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ
    try:
        pipeline = FullPipelineEngine()
        print(f"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø¨Ù†Ø¬Ø§Ø­ - Ø§Ù„Ø¥ØµØ¯Ø§Ø±: {pipeline.version}")
        print(f"ğŸ“Š Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: {list(pipeline.engines.keys())}")
        print(f"ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª: {len(pipeline.engines)}")
        print()
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ: {e}")
        return False
    
    # Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    test_texts = [
        "ÙƒØªØ§Ø¨Ø©",
        "Ø§Ù„Ù…ÙƒØªÙˆØ¨",
        "ÙŠÙƒØªØ¨",
        "ÙƒØ§ØªØ¨",
        "Ù…ÙƒØªØ¨",
        "Ø£Ø¬Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØµØ±ÙÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"
    ]
    
    print("ğŸ§ª Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†ØµÙˆØµ...")
    print("-" * 40)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ Ø§Ù„Ù†Øµ {i}: '{text}'")
        
        try:
            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            result = pipeline.analyze(
                text=text,
                target_engines=None,  # Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª
                enable_parallel=True,
                detailed_output=True
            )
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø®ØªØµØ±Ø©
            pipeline_info = result.get("pipeline_info", {})
            summary = result.get("pipeline_summary", {})
            
            print(f"   â±ï¸  ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {pipeline_info.get('processing_time', 0):.3f} Ø«Ø§Ù†ÙŠØ©")
            print(f"   âœ… Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {summary.get('successful_engines', 0)}")
            print(f"   âŒ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©: {summary.get('failed_engines', 0)}")
            print(f"   ğŸ¯ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {summary.get('average_confidence', 0):.2f}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ÙƒÙ„ Ù…Ø­Ø±Ùƒ
            key_findings = summary.get("key_findings", {})
            for engine_name, findings in key_findings.items():
                if isinstance(findings, dict) and "error" not in findings:
                    print(f"   ğŸ” {engine_name}: {list(findings.keys())[:3]}")  # Ø£ÙˆÙ„ 3 Ù…ÙØ§ØªÙŠØ­
            
        except Exception as e:
            print(f"   âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:")
    print("-" * 20)
    
    stats = pipeline.get_pipeline_stats()
    comp_stats = stats.get("comprehensive_stats", {})
    perf_stats = stats.get("performance_summary", {})
    
    print(f"   ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª: {comp_stats.get('total_analyses', 0)}")
    print(f"   âœ… Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {comp_stats.get('successful_analyses', 0)}")
    print(f"   â±ï¸  Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {comp_stats.get('average_processing_time', 0):.3f}s")
    print(f"   ğŸ¯ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {perf_stats.get('success_rate', 0):.1f}%")
    print(f"   ğŸ”„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©: {comp_stats.get('parallel_operations', 0)}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print(f"\nğŸ’¾ Ø§Ø®ØªØ¨Ø§Ø± ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
    print("-" * 25)
    
    try:
        # ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ù„Ù„ØªØµØ¯ÙŠØ±
        store_data_result = pipeline.analyze("ÙƒØªØ§Ø¨Ø©", detailed_output=False)
        
        # ØªØµØ¯ÙŠØ± JSON
        json_store_data = pipeline.store_data_results(store_data_result, "json")
        print(f"   âœ… ØªØµØ¯ÙŠØ± JSON: {len(json_store_data)} Ø­Ø±Ù")
        
        # ØªØµØ¯ÙŠØ± CSV
        csv_store_data = pipeline.store_data_results(store_data_result, "csv")
        print(f"   âœ… ØªØµØ¯ÙŠØ± CSV: {len(csv_store_data)} Ø­Ø±Ù")
        
    except Exception as e:
        print(f"   âŒ ÙØ´Ù„ Ø§Ù„ØªØµØ¯ÙŠØ±: {e}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
    print(f"\nğŸ“¦ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©:")
    print("-" * 30)
    
    try:
        batch_texts = ["ÙƒØªØ§Ø¨Ø©", "Ù…ÙƒØªÙˆØ¨", "ÙŠÙƒØªØ¨"]
        batch_results = pipeline.analyze_batch(
            batch_texts, 
            target_engines=["weight", "morphology"],
            enable_parallel=True,
            detailed_output=False
        )
        
        print(f"   âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…Ø¹Ø© Ù„Ù€ {len(batch_results)} Ù†Øµ")
        for i, result in enumerate(batch_results):
            if "error" not in result:
                summary = result.get("pipeline_summary", {})
                print(f"   ğŸ“ Ø§Ù„Ù†Øµ {i+1}: {summary.get('successful_engines', 0)} Ù…Ø­Ø±Ùƒ Ù†Ø§Ø¬Ø­")
            else:
                print(f"   âŒ Ø§Ù„Ù†Øµ {i+1}: Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
    
    except Exception as e:
        print(f"   âŒ ÙØ´Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©: {e}")
    
    print(f"\nğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­!")
    print("=" * 60)
    
    return True

def test_flask_integration():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªÙƒØ§Ù…Ù„ Flask"""
    
    print("\nğŸŒ Ø§Ø®ØªØ¨Ø§Ø± ØªÙƒØ§Ù…Ù„ Flask:")
    print("-" * 25)
    
    try:
        app = create_flask_app()
        print("   âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ Flask Ø¨Ù†Ø¬Ø§Ø­")
        print("   ğŸŒ ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„Ù‡ Ø¹Ù„Ù‰: http://localhost:5000")
        print("   ğŸ“± ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…ØªØ§Ø­Ø©")
        return True
    except Exception as e:
        print(f"   âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ Flask: {e}")
        return False

def demo_advanced_features():
    """Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
    
    print("\nğŸš€ Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:")
    print("-" * 30)
    
    try:
        pipeline = FullPipelineEngine()
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ù‚Ø¯
        complex_text = "Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¬Ù…ÙŠÙ„Ø© ÙˆØ§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØµØ±ÙÙŠØ© Ø§Ù„Ù…ØªÙ†ÙˆØ¹Ø© ØªØ¸Ù‡Ø± Ø«Ø±Ø§Ø¡ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
        
        print(f"ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ù‚Ø¯: '{complex_text}'")
        
        # ØªØ­Ù„ÙŠÙ„ Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ ÙƒØ§Ù…Ù„Ø©
        result = pipeline.analyze(
            text=complex_text,
            target_engines=None,
            enable_parallel=True,
            detailed_output=True
        )
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø§Ø·Ø¹
        cross_insights = result.get("cross_engine_insights", {})
        if cross_insights:
            print("   ğŸ”— Ø±Ø¤Ù‰ Ù…ØªÙ‚Ø§Ø·Ø¹Ø©:")
            for insight_type, data in cross_insights.items():
                print(f"      â€¢ {insight_type}: Ù…ØªØ§Ø­")
        
        # Ø¹Ø±Ø¶ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©
        quality = result.get("quality_assessment", {})
        if quality:
            print(f"   ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©:")
            print(f"      â€¢ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {quality.get('overall_score', 0):.2f}")
            print(f"      â€¢ Ù…Ø¤Ø´Ø± Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©: {quality.get('reliability_index', 0):.2f}")
            print(f"      â€¢ Ø§Ù„Ø§ÙƒØªÙ…Ø§Ù„: {quality.get('completeness', 0):.1f}%")
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª
        recommendations = result.get("recommendations", [])
        if recommendations:
            print(f"   ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
            for rec in recommendations[:3]:  # Ø£ÙˆÙ„ 3 ØªÙˆØµÙŠØ§Øª
                print(f"      â€¢ {rec}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ ÙØ´Ù„ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ”¥ Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - FullPipeline Engine")
    print("=" * 70)
    print(f"ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    success = True
    
    success &= test_pipeline_engine()
    success &= test_flask_integration()
    success &= demo_advanced_features()
    
    if success:
        print(f"\nğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª! Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù….")
        print(f"ğŸš€ Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ÙˆÙŠØ¨:")
        print(f"   python engines/nlp/full_pipeline/engine.py")
    else:
        print(f"\nâš ï¸  Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙØ´Ù„Øª. ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£Ø¹Ù„Ø§Ù‡.")
from engines.nlp.full_pipeline.engine import_data FullPipelineEngine

pipeline = FullPipelineEngine()
result = pipeline.analyze("ÙƒØªØ§Ø¨Ø©")
print(result["pipeline_summary"])