#!/usr/bin/env python3
"""
üöÄ Complete Arabic NLP Engine Pipeline Flask Application
Full Integration: Phonology ‚Üí SyllabicUnit ‚Üí Root ‚Üí Verb ‚Üí Pattern ‚Üí Inflection ‚Üí Noun Plural

This Flask application demonstrates the complete Arabic NLP processing pipeline
with proper JSON responses and engine orchestration.
"""
# pylint: disable=invalid-name,too-few-public-methods,too-many-instance-attributes,line-too-long


import_data json
import_data logging
import_data os
import_data sys
import_data time
from dataclasses import_data asdict, dataclass
from datetime import_data datetime
from typing import_data Any, Dict, List, Optional

# Flask import_datas
from flask import_data Flask, jsonify, request
from flask_cors import_data CORS

# Add project root to path
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

# Suppress warnings
os.environ['PYTHONWARNINGS'] = 'ignore'
logging.getLogger().setLevel(logging.ERROR)

# Import our engine logic
try:
    from unified_phonemes from unified_phonemes import get_unified_phonemes, extract_phonemes, get_phonetic_features, is_emphatic
        FlaskJSONResponseGenerator,
        PhonologyToSyllabicUnitProcessor,
    )
except ImportError:
    print("Warning: phonology_syllabic_unit_logic not available")

@dataclass
class EngineResult:
    """Standard result format for all engines"""
    engine_name: str
    version: str
    input_text: str
    output: Dict[str, Any]
    processing_time_ms: float
    success: bool
    error_message: Optional[str] = None

class MockRootEngine:
    """Mock Root Extraction Engine"""
    
    def __init__(self):
        self.name = "RootEngine"
        self.version = "1.0.0"
        
        # Common Arabic roots
        self.known_roots = {
            'ŸÉÿ™ÿ®': ('ŸÉ', 'ÿ™', 'ÿ®'),
            'ÿØÿ±ÿ≥': ('ÿØ', 'ÿ±', 'ÿ≥'),
            'ÿπŸÑŸÖ': ('ÿπ', 'ŸÑ', 'ŸÖ'),
            'ŸÇÿ±ÿ£': ('ŸÇ', 'ÿ±', 'ÿ£'),
            'ŸÉÿ™ÿßÿ®': ('ŸÉ', 'ÿ™', 'ÿ®'),
            'ŸÖÿØÿ±ÿ≥ÿ©': ('ÿØ', 'ÿ±', 'ÿ≥'),
            'ŸÖÿπŸÑŸÖ': ('ÿπ', 'ŸÑ', 'ŸÖ'),
            'ŸÇÿßÿ±ÿ¶': ('ŸÇ', 'ÿ±', 'ÿ£'),
        }
    
    def extract_root(self, word: str) -> EngineResult:
        """Extract root from Arabic word"""
        begin_time = time.time()
        
        try:
            # Simple root extraction (mock implementation)
            root = self.known_roots.get(word, ('?', '?', '?'))
            
            output = {
                'original_word': word,
                'extracted_root': root,
                'root_string': ''.join(root),
                'confidence': 0.95 if word in self.known_roots else 0.3,
                'extraction_method': 'pattern_matching',
                'morphological_pattern': self._identify_pattern(word, root)
            }
            
            processing_time = (time.time() - begin_time) * 1000
            
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=word,
                output=output,
                processing_time_ms=processing_time,
                success=True
            )
            
        except Exception as e:
            processing_time = (time.time() - begin_time) * 1000
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=word,
                output={},
                processing_time_ms=processing_time,
                success=False,
                error_message=str(e)
            )
    
    def _identify_pattern(self, word: str, root: tuple) -> str:
        """Identify morphological pattern"""
        if len(word) == 3:
            return "ŸÅÿπŸÑ"  # CCC pattern
        elif len(word) == 4:
            return "ŸÅÿπÿßŸÑ"  # CCVC pattern
        elif len(word) == 5:
            return "ŸÖŸÅÿπŸÑÿ©"  # mCCCa pattern
        else:
            return "unknown"

class MockVerbEngine:
    """Mock Verb Analysis Engine"""
    
    def __init__(self):
        self.name = "VerbEngine"
        self.version = "1.0.0"
    
    def analyze_verb(self, root: tuple, word: str) -> EngineResult:
        """Analyze verb forms and conjugations"""
        begin_time = time.time()
        
        try:
            # Mock verb analysis
            verb_forms = self._generate_verb_forms(root)
            tense_analysis = self._analyze_tense(word)
            
            output = {
                'root': root,
                'root_string': ''.join(root),
                'input_word': word,
                'verb_forms': verb_forms,
                'tense_analysis': tense_analysis,
                'conjugation_possibilities': self._get_conjugation_possibilities(root),
                'verb_type': self._classify_verb_type(root)
            }
            
            processing_time = (time.time() - begin_time) * 1000
            
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=word,
                output=output,
                processing_time_ms=processing_time,
                success=True
            )
            
        except Exception as e:
            processing_time = (time.time() - begin_time) * 1000
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=word,
                output={},
                processing_time_ms=processing_time,
                success=False,
                error_message=str(e)
            )
    
    def _generate_verb_forms(self, root: tuple) -> Dict[str, str]:
        """Generate basic verb forms"""
        r1, r2, r3 = root
        return {
            'past_3rd_masc': f"{r1}{r2}{r3}",
            'present_3rd_masc': f"Ÿä{r1}{r2}{r3}",
            'imperative_masc': f"ÿß{r1}{r2}{r3}",
            'verbal_noun': f"{r1}{r2}ÿß{r3}ÿ©",
            'active_participle': f"{r1}ÿß{r2}{r3}",
            'passive_participle': f"ŸÖ{r1}{r2}Ÿàÿ®"
        }
    
    def _analyze_tense(self, word: str) -> Dict[str, Any]:
        """Analyze tense of input word"""
        if word.beginswith('Ÿä'):
            return {'tense': 'present', 'person': 3, 'gender': 'masculine', 'number': 'singular'}
        elif word.beginswith('ÿß'):
            return {'tense': 'imperative', 'person': 2, 'gender': 'masculine', 'number': 'singular'}
        else:
            return {'tense': 'past', 'person': 3, 'gender': 'masculine', 'number': 'singular'}
    
    def _get_conjugation_possibilities(self, root: tuple) -> List[Dict[str, str]]:
        """Get all possible conjugations"""
        return [
            {'tense': 'past', 'person': 1, 'number': 'singular', 'form': f"{root[0]}{root[1]}{root[2]}ÿ™"},
            {'tense': 'past', 'person': 2, 'number': 'singular', 'form': f"{root[0]}{root[1]}{root[2]}ÿ™"},
            {'tense': 'past', 'person': 3, 'number': 'singular', 'form': f"{root[0]}{root[1]}{root[2]}"},
            {'tense': 'present', 'person': 1, 'number': 'singular', 'form': f"ÿ£{root[0]}{root[1]}{root[2]}"},
            {'tense': 'present', 'person': 2, 'number': 'singular', 'form': f"ÿ™{root[0]}{root[1]}{root[2]}"},
            {'tense': 'present', 'person': 3, 'number': 'singular', 'form': f"Ÿä{root[0]}{root[1]}{root[2]}"},
        ]
    
    def _classify_verb_type(self, root: tuple) -> str:
        """Classify verb type based on root"""
        weak_letters = {'Ÿà', 'Ÿä', 'ÿ°', 'ÿß'}
        if any(letter in weak_letters for letter in root):
            return 'weak'
        else:
            return 'sound'

class MockPatternEngine:
    """Mock Pattern Analysis Engine"""
    
    def __init__(self):
        self.name = "PatternEngine"
        self.version = "1.0.0"
    
    def analyze_pattern(self, word: str, root: tuple) -> EngineResult:
        """Analyze morphological patterns"""
        begin_time = time.time()
        
        try:
            pattern_analysis = self._extract_pattern(word, root)
            pattern_family = self._classify_pattern_family(pattern_analysis['pattern'])
            
            output = {
                'word': word,
                'root': root,
                'pattern_analysis': pattern_analysis,
                'pattern_family': pattern_family,
                'semantic_implications': self._get_semantic_implications(pattern_analysis['pattern']),
                'related_patterns': self._get_related_patterns(pattern_analysis['pattern'])
            }
            
            processing_time = (time.time() - begin_time) * 1000
            
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=word,
                output=output,
                processing_time_ms=processing_time,
                success=True
            )
            
        except Exception as e:
            processing_time = (time.time() - begin_time) * 1000
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=word,
                output={},
                processing_time_ms=processing_time,
                success=False,
                error_message=str(e)
            )
    
    def _extract_pattern(self, word: str, root: tuple) -> Dict[str, Any]:
        """Extract morphological pattern"""
        # Simple pattern extraction
        pattern = ""
        vowels = ""
        
        for char in word:
            if char in root:
                pattern += "ŸÅ" if char == root[0] else "ÿπ" if char == root[1] else "ŸÑ"
            else:
                pattern += char
                if char in "ÿßŸéŸèŸê":
                    vowels += char
        
        return {
            'pattern': pattern,
            'vowel_pattern': vowels,
            'template': self._map_to_template(pattern),
            'morphological_category': self._determine_category(pattern)
        }
    
    def _map_to_template(self, pattern: str) -> str:
        """Map to standard template"""
        templates = {
            'ŸÅÿπŸÑ': 'CCC',
            'ŸÅÿπÿßŸÑ': 'CCVC',
            'ŸÖŸÅÿπŸÑ': 'mCCC',
            'ŸÅÿßÿπŸÑ': 'CaCC',
            'ŸÖŸÅÿπŸàŸÑ': 'mCCuC'
        }
        return templates.get(pattern, 'unknown')
    
    def _determine_category(self, pattern: str) -> str:
        """Determine morphological category"""
        if pattern.beginswith('ŸÖ'):
            return 'noun_derived'
        elif 'ÿß' in pattern:
            return 'active_pattern'
        else:
            return 'basic_pattern'
    
    def _classify_pattern_family(self, pattern: str) -> str:
        """Classify pattern family"""
        if pattern in ['ŸÅÿπŸÑ', 'ŸÅÿπÿßŸÑ', 'ŸÅÿπŸàŸÑ']:
            return 'basic_verbal'
        elif pattern.beginswith('ŸÖ'):
            return 'derived_nominal'
        else:
            return 'other'
    
    def _get_semantic_implications(self, pattern: str) -> List[str]:
        """Get semantic implications of pattern"""
        implications = {
            'ŸÅÿßÿπŸÑ': ['agent', 'doer'],
            'ŸÖŸÅÿπŸàŸÑ': ['patient', 'done_to'],
            'ŸÅÿπÿßŸÑ': ['intensive', 'professional'],
            'ŸÖŸÅÿπŸÑ': ['place', 'instrument']
        }
        return implications.get(pattern, ['unknown'])
    
    def _get_related_patterns(self, pattern: str) -> List[str]:
        """Get related patterns"""
        families = {
            'ŸÅÿπŸÑ': ['ŸÅÿπÿßŸÑ', 'ŸÅÿßÿπŸÑ', 'ŸÖŸÅÿπŸàŸÑ'],
            'ŸÅÿπÿßŸÑ': ['ŸÅÿπŸÑ', 'ŸÅÿßÿπŸÑ'],
            'ŸÅÿßÿπŸÑ': ['ŸÅÿπŸÑ', 'ŸÖŸÅÿπŸàŸÑ']
        }
        return families.get(pattern, [])

class MockInflectionEngine:
    """Mock Inflection Engine"""
    
    def __init__(self):
        self.name = "InflectionEngine"
        self.version = "1.0.0"
    
    def apply_inflection(self, root: tuple, features: Dict[str, Any]) -> EngineResult:
        """Apply inflectional morphology"""
        begin_time = time.time()
        
        try:
            inflected_forms = self._generate_inflected_forms(root, features)
            
            output = {
                'root': root,
                'input_features': features,
                'inflected_forms': inflected_forms,
                'morphological_analysis': self._analyze_morphology(inflected_forms),
                'paradigm': self._generate_paradigm(root)
            }
            
            processing_time = (time.time() - begin_time) * 1000
            
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=str(root),
                output=output,
                processing_time_ms=processing_time,
                success=True
            )
            
        except Exception as e:
            processing_time = (time.time() - begin_time) * 1000
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=str(root),
                output={},
                processing_time_ms=processing_time,
                success=False,
                error_message=str(e)
            )
    
    def _generate_inflected_forms(self, root: tuple, features: Dict[str, Any]) -> Dict[str, str]:
        """Generate inflected forms based on features"""
        r1, r2, r3 = root
        tense = features.get('tense', 'present')
        person = features.get('person', 3)
        gender = features.get('gender', 'masculine')
        number = features.get('number', 'singular')
        
        forms = {}
        
        if tense == 'present':
            if person == 1:
                forms['present_1st'] = f"ÿ£{r1}{r2}{r3}"
            elif person == 2:
                forms['present_2nd'] = f"ÿ™{r1}{r2}{r3}"
            else:
                forms['present_3rd'] = f"Ÿä{r1}{r2}{r3}" if gender == 'masculine' else f"ÿ™{r1}{r2}{r3}"
        
        elif tense == 'past':
            if person == 1:
                forms['past_1st'] = f"{r1}{r2}{r3}ÿ™"
            elif person == 2:
                forms['past_2nd'] = f"{r1}{r2}{r3}ÿ™"
            else:
                forms['past_3rd'] = f"{r1}{r2}{r3}" if gender == 'masculine' else f"{r1}{r2}{r3}ÿ™"
        
        return forms
    
    def _analyze_morphology(self, forms: Dict[str, str]) -> Dict[str, Any]:
        """Analyze morphological structure of forms"""
        return {
            'prefixes': ['ÿ£', 'ÿ™', 'Ÿä'],
            'suffixes': ['ÿ™'],
            'infixes': [],
            'root_modifications': 'none'
        }
    
    def _generate_paradigm(self, root: tuple) -> Dict[str, Dict[str, str]]:
        """Generate complete paradigm"""
        r1, r2, r3 = root
        return {
            'past': {
                '1st_sing': f"{r1}{r2}{r3}ÿ™",
                '2nd_sing_masc': f"{r1}{r2}{r3}ÿ™",
                '3rd_sing_masc': f"{r1}{r2}{r3}",
            },
            'present': {
                '1st_sing': f"ÿ£{r1}{r2}{r3}",
                '2nd_sing_masc': f"ÿ™{r1}{r2}{r3}",
                '3rd_sing_masc': f"Ÿä{r1}{r2}{r3}",
            }
        }

class MockNounPluralEngine:
    """Mock Noun Pluralization Engine"""
    
    def __init__(self):
        self.name = "NounPluralEngine"
        self.version = "1.0.0"
    
    def generate_plurals(self, noun: str, root: tuple) -> EngineResult:
        """Generate plural forms of Arabic nouns"""
        begin_time = time.time()
        
        try:
            plural_forms = self._generate_plural_forms(noun, root)
            
            output = {
                'singular': noun,
                'root': root,
                'plural_forms': plural_forms,
                'pluralization_rules': self._get_pluralization_rules(noun),
                'semantic_analysis': self._analyze_semantic_plurality(noun)
            }
            
            processing_time = (time.time() - begin_time) * 1000
            
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=noun,
                output=output,
                processing_time_ms=processing_time,
                success=True
            )
            
        except Exception as e:
            processing_time = (time.time() - begin_time) * 1000
            return EngineResult(
                engine_name=self.name,
                version=self.version,
                input_text=noun,
                output={},
                processing_time_ms=processing_time,
                success=False,
                error_message=str(e)
            )
    
    def _generate_plural_forms(self, noun: str, root: tuple) -> Dict[str, List[str]]:
        """Generate different types of plural forms"""
        r1, r2, r3 = root
        
        return {
            'sound_masculine': [f"{noun}ŸàŸÜ", f"{noun}ŸäŸÜ"],
            'sound_feminine': [f"{noun}ÿßÿ™"],
            'broken_plurals': [
                f"{r1}{r2}Ÿà{r3}",      # ŸÅÿπŸàŸÑ
                f"ÿ£{r1}{r2}ÿß{r3}",     # ÿ£ŸÅÿπÿßŸÑ
                f"{r1}{r2}ÿß{r3}ÿ©",     # ŸÅÿπÿßŸÑÿ©
                f"ŸÖ{r1}ÿß{r2}{r3}",     # ŸÖŸÅÿßÿπŸÑ
            ],
            'collective': [f"{noun}ÿ©"] if not noun.endswith('ÿ©') else []
        }
    
    def _get_pluralization_rules(self, noun: str) -> List[Dict[str, str]]:
        """Get applicable pluralization rules"""
        rules = []
        
        if noun.endswith('ÿ©'):
            rules.append({
                'rule_type': 'sound_feminine',
                'pattern': 'replace ÿ© with ÿßÿ™',
                'example': f"{noun[:-1]}ÿßÿ™"
            })
        
        if len(noun) == 3:
            rules.append({
                'rule_type': 'broken_plural',
                'pattern': 'CCC ‚Üí CCVC',
                'example': f"{noun}ŸàŸÑ"
            })
        
        return rules
    
    def _analyze_semantic_plurality(self, noun: str) -> Dict[str, Any]:
        """Analyze semantic aspects of plurality"""
        return {
            'countability': 'countable',
            'collectiveness': 'individual',
            'preferred_plural_type': 'broken' if len(noun) <= 4 else 'sound',
            'semantic_field': self._determine_semantic_field(noun)
        }
    
    def _determine_semantic_field(self, noun: str) -> str:
        """Determine semantic field of noun"""
        fields = {
            'ŸÉÿ™ÿßÿ®': 'education',
            'ÿ∑ÿßŸÑÿ®': 'education',
            'ŸÖÿπŸÑŸÖ': 'education',
            'ÿ®Ÿäÿ™': 'dwelling',
            'ÿ≥Ÿäÿßÿ±ÿ©': 'transport'
        }
        return fields.get(noun, 'general')

class CompletePipelineEngine:
    """Complete Arabic NLP Pipeline Engine"""
    
    def __init__(self):
        self.phonology_syllabic_unit = PhonologyToSyllabicUnitProcessor()
        self.root_engine = MockRootEngine()
        self.verb_engine = MockVerbEngine()
        self.pattern_engine = MockPatternEngine()
        self.inflection_engine = MockInflectionEngine()
        self.noun_plural_engine = MockNounPluralEngine()
        
        self.pipeline_order = [
            'phonology_syllabic_unit',
            'root_extraction',
            'verb_analysis',
            'pattern_analysis',
            'inflection',
            'noun_plural'
        ]
    
    def process_complete(self, text: str, engines: Optional[List[str]] = None) -> Dict[str, Any]:
        """Process text through complete pipeline"""
        begin_time = time.time()
        
        engines_to_use = engines or self.pipeline_order
        results = {}
        
        # 1. Phonology + SyllabicUnit Analysis
        if 'phonology_syllabic_unit' in engines_to_use:
            try:
                phon_syll_result = self.phonology_syllabic_unit.process(text)
                results['phonology_syllabic_unit'] = {
                    'success': True,
                    'result': asdict(phon_syll_result),
                    'engine': 'PhonologyToSyllabicUnitProcessor'
                }
            except Exception as e:
                results['phonology_syllabic_unit'] = {
                    'success': False,
                    'error': str(e),
                    'engine': 'PhonologyToSyllabicUnitProcessor'
                }
        
        # Extract root for subsequent engines
        root = None
        if 'root_extraction' in engines_to_use:
            root_result = self.root_engine.extract_root(text)
            results['root_extraction'] = asdict(root_result)
            if root_result.success:
                root = root_result.output['extracted_root']
        
        # 2. Verb Analysis
        if 'verb_analysis' in engines_to_use and root:
            verb_result = self.verb_engine.analyze_verb(root, text)
            results['verb_analysis'] = asdict(verb_result)
        
        # 3. Pattern Analysis
        if 'pattern_analysis' in engines_to_use and root:
            pattern_result = self.pattern_engine.analyze_pattern(text, root)
            results['pattern_analysis'] = asdict(pattern_result)
        
        # 4. Inflection Analysis
        if 'inflection' in engines_to_use and root:
            features = {'tense': 'present', 'person': 3, 'gender': 'masculine', 'number': 'singular'}
            inflection_result = self.inflection_engine.apply_inflection(root, features)
            results['inflection'] = asdict(inflection_result)
        
        # 5. Noun Plural Analysis
        if 'noun_plural' in engines_to_use and root:
            noun_plural_result = self.noun_plural_engine.generate_plurals(text, root)
            results['noun_plural'] = asdict(noun_plural_result)
        
        # Pipeline metadata
        total_time = (time.time() - begin_time) * 1000
        
        return {
            'pipeline_metadata': {
                'input_text': text,
                'engines_used': engines_to_use,
                'total_processing_time_ms': total_time,
                'timestamp': datetime.now().isoformat(),
                'pipeline_version': '1.0.0'
            },
            'results': results,
            'success': True
        }

# Initialize Flask app
app = Flask(__name__)
CORS(app)

# Initialize pipeline
pipeline = CompletePipelineEngine()

@app.route('/api/pipeline/complete', methods=['POST'])
def complete_pipeline():
    """Complete pipeline analysis endpoint"""
    try:
        data = request.get_json()
        if not data or 'text' not in data:
            return jsonify({'error': 'No text provided'}), 400
        
        text = data['text']
        engines = data.get('engines', None)
        
        result = pipeline.process_complete(text, engines)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/pipeline/phonology-syllabic_unit', methods=['POST'])
def phonology_syllabic_unit_analysis():
    """Phonology and syllabic_unit analysis endpoint"""
    try:
        data = request.get_json()
        if not data or 'text' not in data:
            return jsonify({'error': 'No text provided'}), 400
        
        text = data['text']
        
        result = pipeline.phonology_syllabic_unit.process(text)
        json_response = FlaskJSONResponseGenerator.create_success_response(result)
        
        return jsonify(json_response)
        
    except Exception as e:
        error_response = FlaskJSONResponseGenerator.create_error_response(str(e))
        return jsonify(error_response), 500

@app.route('/api/engines/info', methods=['GET'])
def engines_info():
    """Get information about all available engines"""
    return jsonify({
        'engines': [
            {
                'name': 'PhonologyToSyllabicUnitProcessor',
                'version': '2.0.0',
                'description': 'Complete phonological analysis and syllabic_unit segmentation',
                'input': 'Arabic text',
                'output': 'Phonemes, syllabic_units, IPA representation'
            },
            {
                'name': 'RootEngine',
                'version': '1.0.0',
                'description': 'Arabic root extraction engine',
                'input': 'Arabic word',
                'output': 'Three-letter root, confidence, pattern'
            },
            {
                'name': 'VerbEngine',
                'version': '1.0.0',
                'description': 'Verb analysis and conjugation engine',
                'input': 'Arabic verb/root',
                'output': 'Verb forms, tense analysis, conjugations'
            },
            {
                'name': 'PatternEngine',
                'version': '1.0.0',
                'description': 'Morphological pattern analysis engine',
                'input': 'Arabic word + root',
                'output': 'Pattern analysis, semantic implications'
            },
            {
                'name': 'InflectionEngine',
                'version': '1.0.0',
                'description': 'Inflectional morphology engine',
                'input': 'Root + grammatical features',
                'output': 'Inflected forms, paradigms'
            },
            {
                'name': 'NounPluralEngine',
                'version': '1.0.0',
                'description': 'Noun pluralization engine',
                'input': 'Arabic noun + root',
                'output': 'Plural forms, pluralization rules'
            }
        ],
        'pipeline_order': pipeline.pipeline_order,
        'total_engines': 6
    })

@app.route('/api/demo', methods=['GET'])
def demo_endpoint():
    """Demo endpoint showing pipeline capabilities"""
    demo_text = "ŸÉÿ™ÿßÿ®"
    
    try:
        result = pipeline.process_complete(demo_text)
        return jsonify({
            'demo_text': demo_text,
            'demo_result': result,
            'message': 'Complete Arabic NLP pipeline demonstration'
        })
    except Exception as e:
        return jsonify({
            'error': str(e),
            'demo_text': demo_text
        }), 500

@app.route('/', methods=['GET'])
def home():
    """Home endpoint with API documentation"""
    return jsonify({
        'message': 'Complete Arabic NLP Pipeline API',
        'version': '1.0.0',
        'endpoints': {
            'POST /api/pipeline/complete': 'Complete pipeline analysis',
            'POST /api/pipeline/phonology-syllabic_unit': 'Phonology + syllabic_unit analysis',
            'GET /api/engines/info': 'Engine information',
            'GET /api/demo': 'Demo analysis',
        },
        'engines': pipeline.pipeline_order,
        'documentation': 'Send POST requests with {"text": "Arabic text"} to analyze'
    })

if __name__ == '__main__':
    print("üöÄ COMPLETE ARABIC NLP PIPELINE SERVER")
    print("=" * 60)
    print("üåê Server: http://localhost:5001")
    print("üì° API Endpoints:")
    print("   POST /api/pipeline/complete - Complete analysis")
    print("   POST /api/pipeline/phonology-syllabic_unit - Phonology + syllabic_unit")
    print("   GET  /api/engines/info - Engine information")
    print("   GET  /api/demo - Demo analysis")
    print("=" * 60)
    
    app.run(host='0.0.0.0', port=5001, debug=False)
