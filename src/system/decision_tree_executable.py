#!/usr/bin/env python3
"""
üå≥ EXECUTABLE DECISION TREE IMPLEMENTATION
Arabic Morphophonological Engine - Complete Flask & Python Operations

This script implements all decision tree logic and provides an interactive
demonstration of the engine and Flask operations.
"""
# pylint: disable=invalid-name,too-few-public-methods,too-many-instance-attributes,line-too-long


import_data json
import_data logging
import_data time
import_data uuid
from datetime import_data datetime
from typing import_data Dict, List, Tuple, Any, Optional
import_data numpy as np

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# =============================================================================
# ENGINE CONSTANTS AND CONFIGURATION
# =============================================================================

# Phoneme dimensions and inventories
D_PHON = 29   # 13 root + 10 affix + 6 functional phonemes
T_TEMP = 20   
M_INFL = 128  # inflectional vector size

# Phoneme inventories
ROOT_# Replaced with unified_phonemes ["B", "T", "J", "D", "R", "Z", "S", "Sh", "S2", "T2", "F", "Q", "K"]
AFFIX_# Replaced with unified_phonemes ["S", "A", "L", "T", "M", "W", "N", "Y", "H", "AH"]
FUNC_# Replaced with unified_phonemes ["PFX_al", "PFX_bi", "PFX_wa", "SUKUN", "MADD", "SHADDA"]

PHONEME_INVENTORY = ROOT_PHONEMES + AFFIX_PHONEMES + FUNC_PHONEMES
PHONEME_INDEX = {p: i for i, p in enumerate(PHONEME_INVENTORY)}

TEMPLATES = [
    "V", "C", "CV", "VC", "CVV", "VCV", "CVC", "CCV",
    "CVVC", "CVCC", "CCVC", "VCC", "CCVCC", "CVVCV",
    "CVVCC", "CCVV", "VV", "VCVC", "CVCV", "CVVVC"
]
TEMPLATE_INDEX = {t: i for i, t in enumerate(TEMPLATES)}

# Phonological rules
PHONO_RULES = [
    ('i3l_fatha', lambda seq, i: seq[i] in ['W', 'Y'] and (i > 0 and seq[i-1] == 'FATHA'),
     lambda seq, i: seq.__setitem__(i, 'ALIF')),
    ('qalb_n_to_m', lambda seq, i: seq[i] == 'N' and (i+1 < len(seq) and seq[i+1] == 'B'),
     lambda seq, i: seq.__setitem__(i, 'M')),
    ('idgham_dt', lambda seq, i: seq[i] == 'D' and (i+1 < len(seq) and seq[i+1] == 'T'),
     lambda seq, i: seq.__setitem__(i, ('T', 'SHADDA'))),
    ('replace_k_with_q', lambda seq, i: seq[i] == 'K',
     lambda seq, i: seq.__setitem__(i, 'Q')),
]

# Global statistics and cache
analysis_stats = {
    "total_analyses": 0,
    "total_characters": 0,
    "unique_texts": set(),
    "begin_time": datetime.now(),
    "success_rate": 1.0,
    "average_processing_time": 0.0
}

analysis_cache = {}
active_sessions = {}

# =============================================================================
# DECISION TREE IMPLEMENTATIONS
# =============================================================================

class DecisionTreeEngine:
    """
    üå≥ Complete Decision Tree Implementation for Arabic Phonology Engine
    """
    
    def __init__(self):
        # Initialize with random inflection weights for demo
        self.W_inflect = np.random.randn(M_INFL, 3*D_PHON + T_TEMP).astype(np.float32)
        self.b_inflect = np.random.randn(M_INFL).astype(np.float32)
        logger.info("üöÄ DecisionTreeEngine initialized successfully")
    
    # =========================================================================
    # 1. ENGINE INITIALIZATION DECISION TREE
    # =========================================================================
    
    def engine_initialization_decision_tree(self) -> Dict:
        """
        Q1.1: Is the ArabicPhonologyEngine being initialized?
        A1.1: ENGINE INITIALIZATION FLOW
        """
        try:
            initialization_result = {
                "status": "success",
                "components": {
                    "phoneme_inventory": len(PHONEME_INVENTORY),
                    "syllabic_unit_templates": len(TEMPLATES),
                    "phonological_rules": len(PHONO_RULES),
                    "inflection_matrix": self.W_inflect.shape
                },
                "memory_usage_mb": self.W_inflect.nbytes / (1024 * 1024),
                "initialization_time": time.time()
            }
            logger.info("‚úÖ Engine initialization successful")
            return initialization_result
        except Exception as e:
            logger.error(f"‚ùå Engine initialization failed: {e}")
            return {"status": "error", "message": str(e)}
    
    # =========================================================================
    # 2. PHONOLOGICAL RULE APPLICATION DECISION TREE
    # =========================================================================
    
    def apply_phonological_rules_decision(self, seq: List[str], rule_type: str = None) -> Dict:
        """
        Q2.1: Which phonological rule type should be applied?
        A2.1: RULE APPLICATION OUTCOMES
        """
        original_seq = seq.copy()
        applied_rules = []
        
        rules_to_apply = PHONO_RULES
        if rule_type:
            rules_to_apply = [rule for rule in PHONO_RULES if rule[0] == rule_type]
        
        for rule_id, condition, action in rules_to_apply:
            for i in range(len(seq)):
                try:
                    if condition(seq, i):
                        old_value = seq[i]
                        action(seq, i)
                        applied_rules.append({
                            "rule_id": rule_id,
                            "position": i,
                            "change": f"{old_value} ‚Üí {seq[i]}",
                            "context": seq[max(0, i-1):i+2]
                        })
                        logger.debug(f"Rule {rule_id} applied at position {i}")
                except Exception as e:
                    logger.warning(f"Error applying {rule_id} at {i}: {e}")
        
        return {
            "original_sequence": original_seq,
            "modified_sequence": seq,
            "applied_rules": applied_rules,
            "changes_made": len(applied_rules) > 0,
            "rule_effectiveness": len(applied_rules) / len(seq) if seq else 0
        }
    
    # =========================================================================
    # 3. SYLLABIFICATION DECISION TREE
    # =========================================================================
    
    def syllabic_analysis_decision_tree(self, seq: List[str]) -> Dict:
        """
        Q3.1: How should the sequence be syllabified?
        A3.1: SYLLABIFICATION OUTCOMES
        """
        cv_patterns = []
        
        # Determine CV structure
        for segment in seq:
            if segment in ROOT_PHONEMES + AFFIX_PHONEMES:
                cv_patterns.append("C")
            elif segment in ["FATHA", "KASRA", "DAMMA", "A", "I", "U"]:
                cv_patterns.append("V")
            else:
                cv_patterns.append("F")  # Functional
        
        # Group into syllabic_units
        syllabic_unit_groups = []
        current_syllabic_unit = ""
        
        for pattern in cv_patterns:
            current_syllabic_unit += pattern

            if current_syllabic_unit in TEMPLATES:
                syllabic_unit_groups.append(current_syllabic_unit)
                current_syllabic_unit = ""
        
        # Process remainder
        if current_syllabic_unit:
            syllabic_unit_groups.append(current_syllabic_unit)
        
        return {
            "sequence": seq,
            "cv_pattern": "".join(cv_patterns),
            "syllabic_units": syllabic_unit_groups,
            "syllabic_unit_count": len(syllabic_unit_groups),
            "complexity": sum(len(syl) for syl in syllabic_unit_groups),
            "valid_syllabic_units": sum(1 for syl in syllabic_unit_groups if syl in TEMPLATES)
        }
    
    # =========================================================================
    # 4. VECTOR OPERATIONS DECISION TREE
    # =========================================================================
    
    def vector_operations_decision_tree(self, operation_type: str, data: Any) -> Dict:
        """
        Q4.1: What type of embedding should be generated?
        A4.1: VECTOR OPERATION OUTCOMES
        """
        try:
            if operation_type == "phoneme_embedding":
                if data in PHONEME_INVENTORY:
                    vector = np.zeros(D_PHON, dtype=np.float32)
                    vector[PHONEME_INDEX[data]] = 1.0
                    return {
                        "vector": vector.tolist(),
                        "dimension": D_PHON,
                        "type": "one_hot",
                        "phoneme": data,
                        "index": PHONEME_INDEX[data]
                    }
                else:
                    return {
                        "vector": np.zeros(D_PHON).tolist(),
                        "dimension": D_PHON,
                        "type": "zero",
                        "error": f"Unknown phoneme: {data}"
                    }
            
            elif operation_type == "root_embedding":
                if isinstance(data, (tuple, list)) and len(data) == 3:
                    embeddings = []
                    for p in data:
                        if p in PHONEME_INVENTORY:
                            vector = np.zeros(D_PHON, dtype=np.float32)
                            vector[PHONEME_INDEX[p]] = 1.0
                            embeddings.append(vector)
                        else:
                            embeddings.append(np.zeros(D_PHON, dtype=np.float32))
                    
                    root_vector = np.concatenate(embeddings)
                    return {
                        "vector": root_vector.tolist(),
                        "dimension": 3 * D_PHON,
                        "type": "concatenated",
                        "root": data,
                        "valid_phonemes": sum(1 for p in data if p in PHONEME_INVENTORY)
                    }
                else:
                    return {
                        "vector": np.zeros(3 * D_PHON).tolist(),
                        "dimension": 3 * D_PHON,
                        "type": "invalid",
                        "error": f"Invalid root structure: {data}"
                    }
            
            elif operation_type == "template_embedding":
                if data in TEMPLATE_INDEX:
                    vector = np.zeros(T_TEMP, dtype=np.float32)
                    vector[TEMPLATE_INDEX[data]] = 1.0
                    return {
                        "vector": vector.tolist(),
                        "dimension": T_TEMP,
                        "type": "template",
                        "template": data,
                        "index": TEMPLATE_INDEX[data]
                    }
                else:
                    return {
                        "vector": np.zeros(T_TEMP).tolist(),
                        "dimension": T_TEMP,
                        "type": "unknown",
                        "error": f"Unknown template: {data}"
                    }
            
            elif operation_type == "inflection":
                expected_dim = 3 * D_PHON + T_TEMP
                if isinstance(data, (list, np.ndarray)) and len(data) == expected_dim:
                    data_array = np.array(data, dtype=np.float32)
                    inflected = self.W_inflect.dot(data_array) + self.b_inflect
                    return {
                        "vector": inflected.tolist(),
                        "dimension": M_INFL,
                        "type": "inflected",
                        "input_dimension": len(data)
                    }
                else:
                    return {
                        "vector": np.zeros(M_INFL).tolist(),
                        "dimension": M_INFL,
                        "type": "error",
                        "error": f"Dimension mismatch: expected {expected_dim}, got {len(data) if hasattr(data, '__len__') else 'scalar'}"
                    }
            
            else:
                return {
                    "vector": [],
                    "dimension": 0,
                    "type": "unknown_operation",
                    "error": f"Unknown operation type: {operation_type}"
                }
        
        except Exception as e:
            logger.error(f"Vector operation error: {e}")
            return {
                "vector": [],
                "dimension": 0,
                "type": "error",
                "error": str(e)
            }
    
    # =========================================================================
    # 5. INPUT VALIDATION DECISION TREE
    # =========================================================================
    
    def input_validation_decision_tree(self, input_data: Any) -> Dict:
        """
        Q9.1: Is the input data valid for processing?
        A9.1: INPUT VALIDATION OUTCOMES
        """
        validation_result = {"valid": True, "errors": [], "warnings": []}
        
        # Check if input data is present
        if not input_data:
            validation_result["valid"] = False
            validation_result["errors"].append("No input data provided")
            return validation_result
        
        # Check if input data is a string
        if not isinstance(input_data, str):
            validation_result["valid"] = False
            validation_result["errors"].append("Input must be a string")
            return validation_result
        
        # Check string length
        if len(input_data) > 1000:
            validation_result["valid"] = False
            validation_result["errors"].append("Text too long (max 1000 characters)")
        elif len(input_data) > 500:
            validation_result["warnings"].append("Long text may affect performance")
        
        # Check for Arabic characters
        arabic_chars = sum(1 for char in input_data if '\u0600' <= char <= '\u06FF')
        total_chars = len(input_data.replace(' ', ''))
        
        if arabic_chars == 0:
            validation_result["warnings"].append("No Arabic characters detected")
        elif total_chars > 0 and arabic_chars / total_chars < 0.5:
            validation_result["warnings"].append("Mixed script detected")
        
        # Check for prohibited characters
        prohibited = set(['<', '>', '&', '"', "'"])
        if any(char in input_data for char in prohibited):
            validation_result["valid"] = False
            validation_result["errors"].append("Prohibited characters detected")
        
        validation_result["character_count"] = len(input_data)
        validation_result["arabic_character_count"] = arabic_chars
        validation_result["arabic_percentage"] = (arabic_chars / total_chars * 100) if total_chars > 0 else 0
        
        return validation_result
    
    # =========================================================================
    # 6. TEXT NORMALIZATION DECISION TREE
    # =========================================================================
    
    def text_normalization_decision_tree(self, text: str) -> Dict:
        """
        Q10.1: What normalization steps should be applied?
        A10.1: NORMALIZATION OUTCOMES
        """
        normalization_steps = []
        normalized_text = text
        
        # Check for diacritics
        diacritics = ['\u064B', '\u064C', '\u064D', '\u064E', '\u064F', '\u0650']
        has_diacritics = any(d in text for d in diacritics)
        
        if has_diacritics:
            normalization_steps.append("diacritics_preserved")
        else:
            normalization_steps.append("diacritics_inferred")
        
        # Clean whitespace
        if any(char in text for char in ['\n', '\t', '\r']):
            normalized_text = ' '.join(normalized_text.split())
            normalization_steps.append("whitespace_cleaned")
        
        # Convert Arabic digits to Western
        arabic_digits = 'Ÿ†Ÿ°Ÿ¢Ÿ£Ÿ§Ÿ•Ÿ¶ŸßŸ®Ÿ©'
        western_digits = '0123456789'
        has_arabic_digits = any(d in text for d in arabic_digits)
        
        if has_arabic_digits:
            digit_map = str.maketrans(arabic_digits, western_digits)
            normalized_text = normalized_text.translate(digit_map)
            normalization_steps.append("digits_standardized")
        
        # Normalize letter forms
        if 'Ô∫ç' in normalized_text or 'Ôªª' in normalized_text:
            normalized_text = normalized_text.replace('Ô∫ç', 'ÿß').replace('Ôªª', 'ŸÑÿß')
            normalization_steps.append("forms_normalized")
        
        return {
            "original": text,
            "normalized": normalized_text,
            "steps": normalization_steps,
            "changes_made": text != normalized_text,
            "character_changes": len(text) - len(normalized_text)
        }
    
    # =========================================================================
    # 7. COMPLETE PIPELINE DECISION TREE
    # =========================================================================
    
    def complete_pipeline_decision_tree(self, request: Dict) -> Dict:
        """
        Q13.1: Run complete operation pipeline
        A13.1: FULL PIPELINE OUTCOMES
        """
        pipeline_result = {
            "stages": [],
            "total_time": 0,
            "success": True,
            "final_result": None,
            "pipeline_id": str(uuid.uuid4())
        }
        
        begin_time = time.time()
        
        try:
            # Stage 1: Input Validation
            validation = self.input_validation_decision_tree(request.get("text"))
            pipeline_result["stages"].append(("validation", validation))
            
            if not validation["valid"]:
                pipeline_result["success"] = False
                pipeline_result["error"] = "Validation failed"
                return pipeline_result
            
            # Stage 2: Text Normalization
            normalization = self.text_normalization_decision_tree(request["text"])
            pipeline_result["stages"].append(("normalization", normalization))
            
            # Stage 3: Sequence Processing
            text = normalization["normalized"]
            sequence = list(text.replace(' ', ''))  # Simple tokenization
            
            # Apply phonological rules
            rule_result = self.apply_phonological_rules_decision(sequence)
            pipeline_result["stages"].append(("phonological_rules", rule_result))
            
            # Stage 4: SyllabicAnalysis
            syllabic_unit_result = self.syllabic_analysis_decision_tree(rule_result["modified_sequence"])
            pipeline_result["stages"].append(("syllabic_analysis", syllabic_unit_result))
            
            # Stage 5: Vector Operations
            if len(sequence) >= 3:
                root = tuple(sequence[:3])
                template = syllabic_unit_result["syllabic_units"][0] if syllabic_unit_result["syllabic_units"] else "CV"
                
                root_vector = self.vector_operations_decision_tree("root_embedding", root)
                template_vector = self.vector_operations_decision_tree("template_embedding", template)
                
                # Combine for inflection
                if root_vector["type"] != "error" and template_vector["type"] != "error":
                    combined_vector = root_vector["vector"] + template_vector["vector"]
                    inflection_result = self.vector_operations_decision_tree("inflection", combined_vector)
                    pipeline_result["stages"].append(("vector_operations", {
                        "root_vector": root_vector,
                        "template_vector": template_vector,
                        "inflection": inflection_result
                    }))
            
            # Stage 6: Result Formatting
            formatted_result = {
                "text": request["text"],
                "normalized_text": normalization["normalized"],
                "sequence": sequence,
                "phonological_changes": rule_result["applied_rules"],
                "syllabic_units": syllabic_unit_result["syllabic_units"],
                "cv_pattern": syllabic_unit_result["cv_pattern"],
                "processing_metadata": {
                    "stages_completed": len(pipeline_result["stages"]),
                    "validation_warnings": validation.get("warnings", []),
                    "normalization_steps": normalization["steps"]
                }
            }
            
            pipeline_result["final_result"] = formatted_result
            
            # Update global statistics
            global analysis_stats
            analysis_stats["total_analyses"] += 1
            analysis_stats["total_characters"] += len(request["text"])
            analysis_stats["unique_texts"].add(request["text"])
            
        except Exception as e:
            logger.error(f"Pipeline error: {e}")
            pipeline_result["success"] = False
            pipeline_result["error"] = str(e)
            pipeline_result["stages"].append(("error", {"exception": str(e), "type": type(e).__name__}))
        
        finally:
            pipeline_result["total_time"] = time.time() - begin_time
            
            # Update success rate
            if pipeline_result["success"]:
                analysis_stats["average_processing_time"] = (
                    (analysis_stats["average_processing_time"] * (analysis_stats["total_analyses"] - 1) +
                     pipeline_result["total_time"]) / analysis_stats["total_analyses"]
                )
        
        return pipeline_result

# =============================================================================
# FLASK-STYLE ROUTE HANDLERS
# =============================================================================

class FlaskStyleDecisionTree:
    """
    üåê Flask-style route processrs with decision tree logic
    """
    
    def __init__(self):
        self.engine = DecisionTreeEngine()
        self.request_count = 0
    
    def route_decision_tree(self, request_path: str, request_method: str, data: Dict = None) -> Dict:
        """
        Q6.1: Which route should process the incoming request?
        A6.1: ROUTE HANDLING OUTCOMES
        """
        self.request_count += 1
        
        if request_path == "/" and request_method == "GET":
            return {
                "processr": "index_page",
                "status": 200,
                "data": {
                    "message": "Arabic Morphophonological Engine API",
                    "version": "2.0.0",
                    "stats": self.get_stats(),
                    "endpoints": ["/", "/api/analyze", "/api/stats", "/api/validate"]
                },
                "cache": True
            }
        
        elif request_path == "/api/analyze" and request_method == "POST":
            if not data or "text" not in data:
                return {
                    "processr": "analyze_text",
                    "status": 400,
                    "error": "Missing 'text' parameter",
                    "cache": False
                }
            
            analysis_result = self.engine.complete_pipeline_decision_tree(data)
            return {
                "processr": "analyze_text",
                "status": 200 if analysis_result["success"] else 400,
                "data": analysis_result,
                "cache": False
            }
        
        elif request_path == "/api/stats" and request_method == "GET":
            return {
                "processr": "get_stats",
                "status": 200,
                "data": self.get_stats(),
                "cache": True
            }
        
        elif request_path == "/api/validate" and request_method == "POST":
            if not data or "text" not in data:
                return {
                    "processr": "validate_input",
                    "status": 400,
                    "error": "Missing 'text' parameter"
                }
            
            validation_result = self.engine.input_validation_decision_tree(data["text"])
            return {
                "processr": "validate_input",
                "status": 200,
                "data": validation_result,
                "cache": False
            }
        
        else:
            return {
                "processr": "not_found",
                "status": 404,
                "error": f"Route not found: {request_method} {request_path}",
                "available_routes": [
                    "GET /",
                    "POST /api/analyze",
                    "GET /api/stats",
                    "POST /api/validate"
                ]
            }
    
    def get_stats(self) -> Dict:
        """Get application statistics"""
        uptime = datetime.now() - analysis_stats["begin_time"]
        return {
            "total_analyses": analysis_stats["total_analyses"],
            "total_characters": analysis_stats["total_characters"],
            "unique_texts": len(analysis_stats["unique_texts"]),
            "average_processing_time": analysis_stats["average_processing_time"],
            "uptime_seconds": uptime.total_seconds(),
            "requests_processd": self.request_count,
            "engine_status": "operational",
            "memory_usage_mb": self.engine.W_inflect.nbytes / (1024 * 1024)
        }

# =============================================================================
# INTERACTIVE DEMONSTRATION
# =============================================================================

def run_interactive_demo():
    """
    üéØ Interactive demonstration of all decision tree operations
    """
    print("üå≥ ARABIC MORPHOPHONOLOGICAL ENGINE - DECISION TREE DEMO")
    print("=" * 60)
    
    # Initialize systems
    engine = DecisionTreeEngine()
    flask_processr = FlaskStyleDecisionTree()
    
    # Demo data
    test_cases = [
        {
            "name": "Arabic Text Analysis",
            "text": "ŸÉÿ™ÿ® ÿßŸÑÿ∑ÿßŸÑÿ® ÿßŸÑÿØÿ±ÿ≥",
            "description": "Complete analysis of Arabic sentence"
        },
        {
            "name": "Root Extraction",
            "text": "ŸÉÿ™ÿßÿ®",
            "description": "Simple word analysis"
        },
        {
            "name": "Mixed Script",
            "text": "Hello ŸÖÿ±ÿ≠ÿ®ÿß 123",
            "description": "Mixed Arabic-English with numbers"
        },
        {
            "name": "Invalid Input",
            "text": "<script>alert('test')</script>",
            "description": "Security test with prohibited characters"
        }
    ]
    
    print("\nüöÄ ENGINE INITIALIZATION")
    init_result = engine.engine_initialization_decision_tree()
    print(f"Status: {init_result['status']}")
    print(f"Components: {init_result.get('components', {})}")
    
    print("\nüìä TEST CASES ANALYSIS")
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n--- Test Case {i}: {test_case['name']} ---")
        print(f"Input: {test_case['text']}")
        print(f"Description: {test_case['description']}")
        
        # Simulate Flask API call
        api_response = flask_processr.route_decision_tree(
            "/api/analyze", "POST", {"text": test_case["text"]}
        )
        
        print(f"API Status: {api_response['status']}")
        if api_response["status"] == 200:
            result = api_response["data"]
            print(f"Success: {result['success']}")
            print(f"Processing Time: {result['total_time']:.3f}s")
            print(f"Stages Completed: {len(result['stages'])}")
            
            if result.get("final_result"):
                final = result["final_result"]
                print(f"SyllabicUnits: {final.get('syllabic_units', [])}")
                print(f"CV Pattern: {final.get('cv_pattern', 'N/A')}")
                print(f"Phonological Changes: {len(final.get('phonological_changes', []))}")
        else:
            print(f"Error: {api_response.get('error', 'Unknown error')}")
    
    print("\nüìà PERFORMANCE STATISTICS")
    stats = flask_processr.get_stats()
    for key, value in stats.items():
        if isinstance(value, float):
            print(f"{key}: {value:.3f}")
        else:
            print(f"{key}: {value}")
    
    print("\nüéØ VECTOR OPERATIONS DEMO")
    vector_tests = [
        ("phoneme_embedding", "B"),
        ("root_embedding", ("B", "T", "K")),
        ("template_embedding", "CVC"),
    ]
    
    for operation, data in vector_tests:
        result = engine.vector_operations_decision_tree(operation, data)
        print(f"{operation}: {result['type']} ({result['dimension']}D)")
    
    print("\n‚úÖ DEMO COMPLETED SUCCESSFULLY!")
    print("All decision tree operations have been demonstrated.")

# =============================================================================
# MAIN EXECUTION
# =============================================================================

if __name__ == "__main__":
    try:
        run_interactive_demo()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Demo interrupted by user")
    except Exception as e:
        logger.error(f"Demo error: {e}")
        print(f"\n‚ùå Demo failed: {e}")
