#!/usr/bin/env python3
"""
ğŸ¯ Comprehensive Arabic Particles Classification & Segregation System
Complete analysis and categorization of all Arabic grammatical particles
"""
# pylint: disable=invalid-name,too-few-public-methods,too-many-instance-attributes,line-too-long


import_data sys
from collections import_data defaultdict
from pathlib import_data Path
from typing import_data Any, Dict, List, Set

# Add project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from engines.nlp.particles.engine import_data GrammaticalParticlesEngine

class ComprehensiveParticleAnalyzer:
    """
    Advanced Arabic Particles Classification and Segregation System
    Provides comprehensive analysis of all grammatical particle categories
    """
    
    def __init__(self):
        """Initialize the comprehensive analyzer"""
        self.particles_engine = GrammaticalParticlesEngine()
        
        # Comprehensive category definitions with subcategories
        self.category_definitions = {
            "Ø´Ø±Ø·": {
                "name": "Conditional Particles",
                "description": "Ø­Ø±ÙˆÙ Ø§Ù„Ø´Ø±Ø· - Particles that introduce conditional clauses",
                "subcategories": {
                    "Ø´Ø±Ø·_Ø¬Ø§Ø²Ù…": "Conditional particles that affect mood (Ø¬Ø§Ø²Ù…)",
                    "Ø´Ø±Ø·_ØºÙŠØ±_Ø¬Ø§Ø²Ù…": "Non-modal conditional particles",
                    "Ø´Ø±Ø·_Ø²Ù…Ù†ÙŠ": "Temporal conditional particles"
                },
                "function": "Introduce conditional or hypothetical statements"
            },
            "Ø§Ø³ØªÙÙ‡Ø§Ù…": {
                "name": "Interrogative Particles", 
                "description": "Ø­Ø±ÙˆÙ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… - Question formation particles",
                "subcategories": {
                    "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù†Ø¹Ù…_Ù„Ø§": "Yes/No question particles",
                    "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­": "Open-ended question particles",
                    "Ø§Ø³ØªÙÙ‡Ø§Ù…_ØªÙ‚Ø±ÙŠØ±ÙŠ": "Rhetorical question particles"
                },
                "function": "Form questions and interrogative expressions"
            },
            "Ø§Ø³ØªØ«Ù†Ø§Ø¡": {
                "name": "Exception Particles",
                "description": "Ø­Ø±ÙˆÙ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡ - Exception and exclusion particles", 
                "subcategories": {
                    "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù…ÙØ±Øº": "Complete exception particles",
                    "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù†Ø§Ù‚Øµ": "Incomplete exception particles",
                    "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù…ØªØµÙ„": "Connected exception particles"
                },
                "function": "Express exceptions and exclusions"
            },
            "Ù†ÙÙŠ": {
                "name": "Negation Particles",
                "description": "Ø­Ø±ÙˆÙ Ø§Ù„Ù†ÙÙŠ - Negation and denial particles",
                "subcategories": {
                    "Ù†ÙÙŠ_Ù…Ø·Ù„Ù‚": "Absolute negation particles",
                    "Ù†ÙÙŠ_Ù…Ù‚ÙŠØ¯": "Conditional negation particles", 
                    "Ù†ÙÙŠ_Ø§Ø³ØªÙ‚Ø¨Ø§Ù„": "Future negation particles"
                },
                "function": "Negate verbs, nouns, and sentences"
            },
            "Ø¥Ø´Ø§Ø±Ø©": {
                "name": "Demonstrative Particles",
                "description": "Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© - Demonstrative pronouns and particles",
                "subcategories": {
                    "Ø¥Ø´Ø§Ø±Ø©_Ù‚Ø±ÙŠØ¨": "Near demonstratives (this/these)",
                    "Ø¥Ø´Ø§Ø±Ø©_Ø¨Ø¹ÙŠØ¯": "Far demonstratives (that/those)",
                    "Ø¥Ø´Ø§Ø±Ø©_Ù…ÙƒØ§Ù†": "Locative demonstratives (here/there)"
                },
                "function": "Point to or indicate specific referents"
            },
            "Ù†Ø¯Ø§Ø¡": {
                "name": "Vocative Particles",
                "description": "Ø­Ø±ÙˆÙ Ø§Ù„Ù†Ø¯Ø§Ø¡ - Calling and addressing particles",
                "subcategories": {
                    "Ù†Ø¯Ø§Ø¡_Ù‚Ø±ÙŠØ¨": "Near vocatives",
                    "Ù†Ø¯Ø§Ø¡_Ø¨Ø¹ÙŠØ¯": "Distant vocatives",
                    "Ù†Ø¯Ø§Ø¡_ØªØ¹Ø¬Ø¨": "Exclamatory vocatives"
                },
                "function": "Call attention or address someone/something"
            },
            "Ù…ÙˆØµÙˆÙ„": {
                "name": "Relative Particles", 
                "description": "Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙˆÙ„Ø© - Relative pronouns",
                "subcategories": {
                    "Ù…ÙˆØµÙˆÙ„_Ø¹Ø§Ù‚Ù„": "Rational being relatives",
                    "Ù…ÙˆØµÙˆÙ„_ØºÙŠØ±_Ø¹Ø§Ù‚Ù„": "Non-rational relatives",
                    "Ù…ÙˆØµÙˆÙ„_Ù…Ø´ØªØ±Ùƒ": "Common relatives"
                },
                "function": "Connect relative clauses to main clauses"
            },
            "Ø¶Ù…ÙŠØ±": {
                "name": "Personal Pronouns",
                "description": "Ø§Ù„Ø¶Ù…Ø§Ø¦Ø± Ø§Ù„Ù…Ù†ÙØµÙ„Ø© - Detached personal pronouns",
                "subcategories": {
                    "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹": "Nominative pronouns",
                    "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨": "Accusative pronouns", 
                    "Ø¶Ù…ÙŠØ±_Ø¬Ø±": "Genitive pronouns"
                },
                "function": "Replace or refer to nouns and noun phrases"
            }
        }
        
        # Extended particle mappings with detailed classification
        self.extended_particles = {
            # Conditional Particles (Ø´Ø±Ø·)
            "Ø¥Ù†": {"category": "Ø´Ø±Ø·", "subcategory": "Ø´Ø±Ø·_Ø¬Ø§Ø²Ù…", "mood_effect": True},
            "Ø¥Ø°Ø§": {"category": "Ø´Ø±Ø·", "subcategory": "Ø´Ø±Ø·_ØºÙŠØ±_Ø¬Ø§Ø²Ù…", "mood_effect": False},
            "ÙƒÙ„Ù…Ø§": {"category": "Ø´Ø±Ø·", "subcategory": "Ø´Ø±Ø·_Ø²Ù…Ù†ÙŠ", "mood_effect": False},
            "Ù„Ùˆ": {"category": "Ø´Ø±Ø·", "subcategory": "Ø´Ø±Ø·_ØºÙŠØ±_Ø¬Ø§Ø²Ù…", "mood_effect": False},
            "Ù„ÙˆÙ„Ø§": {"category": "Ø´Ø±Ø·", "subcategory": "Ø´Ø±Ø·_ØºÙŠØ±_Ø¬Ø§Ø²Ù…", "mood_effect": False},
            "Ø£Ù†": {"category": "Ø´Ø±Ø·", "subcategory": "Ø´Ø±Ø·_ØºÙŠØ±_Ø¬Ø§Ø²Ù…", "mood_effect": False},
            "ÙƒÙŠ": {"category": "Ø´Ø±Ø·", "subcategory": "Ø´Ø±Ø·_ØºÙŠØ±_Ø¬Ø§Ø²Ù…", "mood_effect": False},
            "Ù„ÙƒÙŠ": {"category": "Ø´Ø±Ø·", "subcategory": "Ø´Ø±Ø·_ØºÙŠØ±_Ø¬Ø§Ø²Ù…", "mood_effect": False},
            
            # Interrogative Particles (Ø§Ø³ØªÙÙ‡Ø§Ù…) 
            "Ù‡Ù„": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù†Ø¹Ù…_Ù„Ø§", "answer_type": "yes_no"},
            "Ø£": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù†Ø¹Ù…_Ù„Ø§", "answer_type": "yes_no"},
            "Ù…Ù†": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "person"},
            "Ù…Ø§": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "thing"},
            "Ù…Ø§Ø°Ø§": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "thing"},
            "Ø£ÙŠÙ†": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "place"},
            "Ù…ØªÙ‰": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "time"},
            "ÙƒÙŠÙ": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "manner"},
            "Ù„Ù…Ø§Ø°Ø§": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "reason"},
            "ÙƒÙ…": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "quantity"},
            "Ø£ÙŠ": {"category": "Ø§Ø³ØªÙÙ‡Ø§Ù…", "subcategory": "Ø§Ø³ØªÙÙ‡Ø§Ù…_Ù…ÙØªÙˆØ­", "answer_type": "choice"},
            
            # Exception Particles (Ø§Ø³ØªØ«Ù†Ø§Ø¡)
            "Ø¥Ù„Ø§": {"category": "Ø§Ø³ØªØ«Ù†Ø§Ø¡", "subcategory": "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù…ØªØµÙ„", "exception_type": "connected"},
            "ØºÙŠØ±": {"category": "Ø§Ø³ØªØ«Ù†Ø§Ø¡", "subcategory": "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù…ØªØµÙ„", "exception_type": "connected"},
            "Ø³ÙˆÙ‰": {"category": "Ø§Ø³ØªØ«Ù†Ø§Ø¡", "subcategory": "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù…ØªØµÙ„", "exception_type": "connected"},
            "Ø®Ù„Ø§": {"category": "Ø§Ø³ØªØ«Ù†Ø§Ø¡", "subcategory": "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù…Ù†Ù‚Ø·Ø¹", "exception_type": "disconnected"},
            "Ø¹Ø¯Ø§": {"category": "Ø§Ø³ØªØ«Ù†Ø§Ø¡", "subcategory": "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù…Ù†Ù‚Ø·Ø¹", "exception_type": "disconnected"},
            "Ø­Ø§Ø´Ø§": {"category": "Ø§Ø³ØªØ«Ù†Ø§Ø¡", "subcategory": "Ø§Ø³ØªØ«Ù†Ø§Ø¡_Ù…Ù†Ù‚Ø·Ø¹", "exception_type": "disconnected"},
            
            # Negation Particles (Ù†ÙÙŠ)
            "Ù„Ø§": {"category": "Ù†ÙÙŠ", "subcategory": "Ù†ÙÙŠ_Ù…Ø·Ù„Ù‚", "tense_scope": "present"},
            "Ù„Ù†": {"category": "Ù†ÙÙŠ", "subcategory": "Ù†ÙÙŠ_Ø§Ø³ØªÙ‚Ø¨Ø§Ù„", "tense_scope": "future"},
            "Ù„Ù…": {"category": "Ù†ÙÙŠ", "subcategory": "Ù†ÙÙŠ_Ù…Ø§Ø¶ÙŠ", "tense_scope": "past"},
            "Ù…Ø§": {"category": "Ù†ÙÙŠ", "subcategory": "Ù†ÙÙŠ_Ù…Ø·Ù„Ù‚", "tense_scope": "general"},
            "Ù„ÙŠØ³": {"category": "Ù†ÙÙŠ", "subcategory": "Ù†ÙÙŠ_Ù…Ø·Ù„Ù‚", "tense_scope": "present"},
            "Ù„ÙŠØª": {"category": "Ù†ÙÙŠ", "subcategory": "Ù†ÙÙŠ_ØªÙ…Ù†ÙŠ", "tense_scope": "conditional"},
            
            # Demonstrative Particles (Ø¥Ø´Ø§Ø±Ø©)
            "Ù‡Ø°Ø§": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ù‚Ø±ÙŠØ¨", "distance": "near", "gender": "masculine"},
            "Ù‡Ø°Ù‡": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ù‚Ø±ÙŠØ¨", "distance": "near", "gender": "feminine"},
            "Ø°Ù„Ùƒ": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ø¨Ø¹ÙŠØ¯", "distance": "far", "gender": "masculine"},
            "ØªÙ„Ùƒ": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ø¨Ø¹ÙŠØ¯", "distance": "far", "gender": "feminine"},
            "Ø£ÙˆÙ„Ø¦Ùƒ": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ø¨Ø¹ÙŠØ¯", "distance": "far", "number": "plural"},
            "Ù‡Ø¤Ù„Ø§Ø¡": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ù‚Ø±ÙŠØ¨", "distance": "near", "number": "plural"},
            "Ù‡Ù†Ø§": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ù…ÙƒØ§Ù†", "location_type": "here"},
            "Ù‡Ù†Ø§Ùƒ": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ù…ÙƒØ§Ù†", "location_type": "there"},
            "Ù‡Ù†Ø§Ù„Ùƒ": {"category": "Ø¥Ø´Ø§Ø±Ø©", "subcategory": "Ø¥Ø´Ø§Ø±Ø©_Ù…ÙƒØ§Ù†", "location_type": "far_there"},
            
            # Vocative Particles (Ù†Ø¯Ø§Ø¡)
            "ÙŠØ§": {"category": "Ù†Ø¯Ø§Ø¡", "subcategory": "Ù†Ø¯Ø§Ø¡_Ù‚Ø±ÙŠØ¨", "distance": "neutral"},
            "Ø£ÙŠØ§": {"category": "Ù†Ø¯Ø§Ø¡", "subcategory": "Ù†Ø¯Ø§Ø¡_Ø¨Ø¹ÙŠØ¯", "distance": "far"},
            "Ù‡ÙŠØ§": {"category": "Ù†Ø¯Ø§Ø¡", "subcategory": "Ù†Ø¯Ø§Ø¡_Ø¨Ø¹ÙŠØ¯", "distance": "far"},
            "Ø£ÙŠ": {"category": "Ù†Ø¯Ø§Ø¡", "subcategory": "Ù†Ø¯Ø§Ø¡_Ù‚Ø±ÙŠØ¨", "distance": "near"},
            "ÙˆØ§": {"category": "Ù†Ø¯Ø§Ø¡", "subcategory": "Ù†Ø¯Ø§Ø¡_ØªØ¹Ø¬Ø¨", "emotional_tone": "exclamatory"},
            
            # Relative Particles (Ù…ÙˆØµÙˆÙ„)
            "Ø§Ù„Ø°ÙŠ": {"category": "Ù…ÙˆØµÙˆÙ„", "subcategory": "Ù…ÙˆØµÙˆÙ„_Ø¹Ø§Ù‚Ù„", "gender": "masculine", "number": "singular"},
            "Ø§Ù„ØªÙŠ": {"category": "Ù…ÙˆØµÙˆÙ„", "subcategory": "Ù…ÙˆØµÙˆÙ„_Ø¹Ø§Ù‚Ù„", "gender": "feminine", "number": "singular"},
            "Ø§Ù„Ø°ÙŠÙ†": {"category": "Ù…ÙˆØµÙˆÙ„", "subcategory": "Ù…ÙˆØµÙˆÙ„_Ø¹Ø§Ù‚Ù„", "gender": "masculine", "number": "plural"},
            "Ø§Ù„Ù„Ø°Ø§Ù†": {"category": "Ù…ÙˆØµÙˆÙ„", "subcategory": "Ù…ÙˆØµÙˆÙ„_Ø¹Ø§Ù‚Ù„", "gender": "masculine", "number": "dual"},
            "Ø§Ù„Ù„ØªØ§Ù†": {"category": "Ù…ÙˆØµÙˆÙ„", "subcategory": "Ù…ÙˆØµÙˆÙ„_Ø¹Ø§Ù‚Ù„", "gender": "feminine", "number": "dual"},
            "Ø§Ù„Ù„ÙˆØ§ØªÙŠ": {"category": "Ù…ÙˆØµÙˆÙ„", "subcategory": "Ù…ÙˆØµÙˆÙ„_Ø¹Ø§Ù‚Ù„", "gender": "feminine", "number": "plural"},
            "Ù…Ø§": {"category": "Ù…ÙˆØµÙˆÙ„", "subcategory": "Ù…ÙˆØµÙˆÙ„_ØºÙŠØ±_Ø¹Ø§Ù‚Ù„", "rationality": "non_rational"},
            
            # Personal Pronouns (Ø¶Ù…ÙŠØ±)
            "Ø£Ù†Ø§": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 1, "number": "singular"},
            "Ø£Ù†Øª": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 2, "number": "singular", "gender": "masculine"},
            "Ø£Ù†ØªÙ": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 2, "number": "singular", "gender": "feminine"},
            "Ø£Ù†ØªÙ…": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 2, "number": "plural", "gender": "masculine"},
            "Ø£Ù†ØªÙ†": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 2, "number": "plural", "gender": "feminine"},
            "Ù‡Ùˆ": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 3, "number": "singular", "gender": "masculine"},
            "Ù‡ÙŠ": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 3, "number": "singular", "gender": "feminine"},
            "Ù‡Ù…": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 3, "number": "plural", "gender": "masculine"},
            "Ù‡Ù†": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 3, "number": "plural", "gender": "feminine"},
            "Ù†Ø­Ù†": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ø±ÙØ¹", "person": 1, "number": "plural"},
            
            # Accusative Pronouns
            "Ø¥ÙŠØ§ÙŠ": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 1, "number": "singular"},
            "Ø¥ÙŠØ§Ùƒ": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 2, "number": "singular", "gender": "masculine"},
            "Ø¥ÙŠØ§ÙƒÙ": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 2, "number": "singular", "gender": "feminine"},
            "Ø¥ÙŠØ§Ù‡": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 3, "number": "singular", "gender": "masculine"},
            "Ø¥ÙŠØ§Ù‡Ø§": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 3, "number": "singular", "gender": "feminine"},
            "Ø¥ÙŠØ§Ù†Ø§": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 1, "number": "plural"},
            "Ø¥ÙŠØ§ÙƒÙ…": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 2, "number": "plural", "gender": "masculine"},
            "Ø¥ÙŠØ§ÙƒÙ†": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 2, "number": "plural", "gender": "feminine"},
            "Ø¥ÙŠØ§Ù‡Ù…": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 3, "number": "plural", "gender": "masculine"},
            "Ø¥ÙŠØ§Ù‡Ù†": {"category": "Ø¶Ù…ÙŠØ±", "subcategory": "Ø¶Ù…ÙŠØ±_Ù†ØµØ¨", "person": 3, "number": "plural", "gender": "feminine"}
        }
    
    def classify_and_segregate_text(self, text: str) -> Dict[str, Any]:
        """
        Comprehensive classification and segregation of particles in text
        
        Args:
            text: Arabic text to analyze
            
        Returns:
            Complete classification analysis
        """
        words = text.split()
        analysis = {
            "original_text": text,
            "total_words": len(words),
            "classification_summary": {},
            "segregation_by_category": defaultdict(list),
            "segregation_by_subcategory": defaultdict(list),
            "detailed_analysis": [],
            "statistics": {}
        }
        
        # Analyze each word
        for word in words:
            clean_word = word.strip('ØŸ!ØŒ.')
            word_analysis = self.analyze_word_comprehensive(clean_word)
            
            if word_analysis["is_particle"]:
                analysis["detailed_analysis"].append(word_analysis)
                
                # Segregate by main category
                category = word_analysis["category"]
                analysis["segregation_by_category"][category].append(word_analysis)
                
                # Segregate by subcategory
                subcategory = word_analysis.get("subcategory", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
                analysis["segregation_by_subcategory"][subcategory].append(word_analysis)
        
        # Generate classification summary
        analysis["classification_summary"] = self.generate_classification_summary(analysis["detailed_analysis"])
        
        # Generate statistics
        analysis["statistics"] = self.generate_statistics(analysis)
        
        return analysis
    
    def analyze_word_comprehensive(self, word: str) -> Dict[str, Any]:
        """
        Comprehensive analysis of a single word
        
        Args:
            word: Arabic word to analyze
            
        Returns:
            Detailed word analysis
        """
        # Basic particle analysis
        particle_result = self.particles_engine.analyze(word)
        
        # Enhanced analysis with extended data
        enhanced_analysis = {
            "word": word,
            "is_particle": particle_result['analysis_metadata'].get('is_recognized_particle', False),
            "category": particle_result['category'],
            "phonemes": particle_result['phonemes'],
            "syllabic_units": particle_result['syllabic_units'],
            "morphological_features": particle_result['morphological_features']
        }
        
        # Add extended classification if particle is recognized
        if word in self.extended_particles:
            extended_data = self.extended_particles[word]
            enhanced_analysis.update({
                "subcategory": extended_data.get("subcategory", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"),
                "detailed_features": extended_data,
                "category_description": self.category_definitions.get(
                    enhanced_analysis["category"], {}
                ).get("description", ""),
                "function": self.category_definitions.get(
                    enhanced_analysis["category"], {}
                ).get("function", "")
            })
        
        return enhanced_analysis
    
    def generate_classification_summary(self, detailed_analysis: List[Dict]) -> Dict[str, Any]:
        """Generate summary of particle classifications"""
        summary = {
            "particles_found": len(detailed_analysis),
            "categories_present": set(),
            "subcategories_present": set(),
            "category_counts": defaultdict(int),
            "subcategory_counts": defaultdict(int)
        }
        
        for analysis in detailed_analysis:
            category = analysis["category"]
            subcategory = analysis.get("subcategory", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
            
            summary["categories_present"].add(category)
            summary["subcategories_present"].add(subcategory)
            summary["category_counts"][category] += 1
            summary["subcategory_counts"][subcategory] += 1
        
        # Convert sets to lists for JSON serialization
        summary["categories_present"] = list(summary["categories_present"])
        summary["subcategories_present"] = list(summary["subcategories_present"])
        summary["category_counts"] = dict(summary["category_counts"])
        summary["subcategory_counts"] = dict(summary["subcategory_counts"])
        
        return summary
    
    def generate_statistics(self, analysis: Dict) -> Dict[str, Any]:
        """Generate comprehensive statistics"""
        total_words = analysis["total_words"]
        particles_found = analysis["classification_summary"]["particles_found"]
        
        return {
            "particle_density": (particles_found / total_words * 100) if total_words > 0 else 0,
            "most_common_category": max(
                analysis["classification_summary"]["category_counts"].items(),
                key=lambda x: x[1]
            )[0] if analysis["classification_summary"]["category_counts"] else None,
            "category_diversity": len(analysis["classification_summary"]["categories_present"]),
            "subcategory_diversity": len(analysis["classification_summary"]["subcategories_present"]),
            "average_phonemes_per_particle": sum(
                len(p["phonemes"]) for p in analysis["detailed_analysis"]
            ) / particles_found if particles_found > 0 else 0
        }
    
    def get_all_categories_with_examples(self) -> Dict[str, Any]:
        """Get all categories with their particles and examples"""
        categories_data = {}
        
        for category, definition in self.category_definitions.items():
            particles_in_category = [
                particle for particle, data in self.extended_particles.items()
                if data["category"] == category
            ]
            
            # Group by subcategory
            subcategories = defaultdict(list)
            for particle in particles_in_category:
                subcategory = self.extended_particles[particle].get("subcategory", "ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
                subcategories[subcategory].append(particle)
            
            categories_data[category] = {
                "definition": definition,
                "total_particles": len(particles_in_category),
                "subcategories": dict(subcategories),
                "examples": particles_in_category[:5]  # First 5 as examples
            }
        
        return categories_data

def demonstrate_comprehensive_classification():
    """Demonstrate comprehensive classification and segregation"""
    
    print("ğŸ¯ COMPREHENSIVE ARABIC PARTICLES CLASSIFICATION & SEGREGATION")
    print("=" * 70)
    
    # Initialize analyzer
    analyzer = ComprehensiveParticleAnalyzer()
    
    # Test texts with various particle types
    test_texts = [
        "Ù‡Ù„ ÙƒØªØ¨ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„ÙˆØ§Ø¬Ø¨ ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©ØŸ",  # Interrogative
        "Ø¥Ù† Ø§Ù„Ù„Ù‡ ØºÙÙˆØ± Ø±Ø­ÙŠÙ… ÙˆØ§Ù„Ø°ÙŠ ÙŠØªÙˆØ¨ ÙŠØºÙØ± Ù„Ù‡",  # Conditional + Relative
        "ÙŠØ§ Ø£Ø­Ù…Ø¯ØŒ Ù‡Ø°Ø§ ÙƒØªØ§Ø¨Ùƒ Ø§Ù„Ø°ÙŠ Ù†Ø³ÙŠØªÙ‡ Ø£Ù…Ø³",  # Vocative + Demonstrative + Relative
        "Ù„Ø§ ØªÙ†Ø³ Ø£Ù† ØªØ­Ø¶Ø± Ø§Ù„ÙƒØªØ§Ø¨ Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒÙ†Øª Ù…Ø±ÙŠØ¶Ø§Ù‹",  # Negation + Conditional + Exception
        "Ù…Ø§ Ø¹Ø¯Ø§ Ø£ÙˆÙ„Ø¦Ùƒ Ø§Ù„Ø°ÙŠÙ† Ù„Ù… ÙŠØ£ØªÙˆØ§ØŒ ÙØ¥Ù† Ù‡Ø¤Ù„Ø§Ø¡ Ø­Ø¶Ø±ÙˆØ§"  # Exception + Demonstrative + Relative + Negation
    ]
    
    print("\nğŸ“Š CATEGORY DEFINITIONS:")
    print("-" * 40)
    categories = analyzer.get_all_categories_with_examples()
    for category, data in categories.items():
        print(f"\nğŸ·ï¸ {category} ({data['definition']['name']}):")
        print(f"   Description: {data['definition']['description']}")
        print(f"   Function: {data['definition']['function']}")
        print(f"   Total Particles: {data['total_particles']}")
        print(f"   Examples: {', '.join(data['examples'])}")
        
        print(f"   Subcategories:")
        for subcat, particles in data['subcategories'].items():
            print(f"      â€¢ {subcat}: {', '.join(particles[:3])}...")
    
    print("\n" + "="*70)
    print("ğŸ“ TEXT ANALYSIS EXAMPLES:")
    print("="*70)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ” Analysis {i}: {text}")
        print("-" * 60)
        
        analysis = analyzer.classify_and_segregate_text(text)
        
        print(f"ğŸ“Š Summary:")
        print(f"   Total Words: {analysis['total_words']}")
        print(f"   Particles Found: {analysis['classification_summary']['particles_found']}")
        print(f"   Particle Density: {analysis['statistics']['particle_density']:.1f}%")
        print(f"   Category Diversity: {analysis['statistics']['category_diversity']}")
        
        print(f"\nğŸ·ï¸ Categories Found:")
        for category, count in analysis['classification_summary']['category_counts'].items():
            particles = [p['word'] for p in analysis['segregation_by_category'][category]]
            print(f"   {category} ({count}): {', '.join(particles)}")
        
        print(f"\nğŸ”– Subcategories Found:")
        for subcat, particles_data in analysis['segregation_by_subcategory'].items():
            particles = [p['word'] for p in particles_data]
            print(f"   {subcat}: {', '.join(particles)}")
        
        if analysis['statistics']['most_common_category']:
            print(f"\nğŸ“ˆ Most Common Category: {analysis['statistics']['most_common_category']}")

if __name__ == "__main__":
    try:
        demonstrate_comprehensive_classification()
        
        print("\nâœ… Comprehensive Classification Complete!")
        print("\nğŸ’¡ Available Features:")
        print("   â€¢ Complete particle categorization (8 main categories)")
        print("   â€¢ Subcategory classification (24+ subcategories)")
        print("   â€¢ Morphological feature analysis")
        print("   â€¢ Statistical analysis and diversity metrics")
        print("   â€¢ Text segregation by category/subcategory")
        print("   â€¢ Comprehensive linguistic metadata")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import_data traceback
        traceback.print_exc()
