"""
๐ Arabic Root Database Demo - ุนุฑุถ ุชูุถูุญู ููุงุนุฏุฉ ุจูุงูุงุช ุงูุฌุฐูุฑ ุงูุนุฑุจูุฉ
============================================================================

ุนุฑุถ ุดุงูู ูููุฒุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุทูุฑุฉ ูุน ุฃูุซูุฉ ุนูููุฉ ุนูู:
- ุงูุนูููุงุช ุงูุฃุณุงุณูุฉ CRUD
- ุงูุจุญุซ ุงููุชูุฏู ูุงููููุฑุณ
- ุงูุฅ# The `textwrap` module in Python is used for formatting and wrapping plain text to fit within a
# specified line width. It provides functions like `dedent()` which removes common leading
# whitespace from every line in a string, and `wrap()` which wraps the input text to fit within a
# specified width by breaking lines at word boundaries. In the provided code, `dedent()` is used
# to remove any common leading whitespace from multi-line strings for better readability and
# maintainability.
ุญุตุงุฆูุงุช ูุงูุชุญูููุงุช
- ุงูุฃุฏุงุก ูุงูุชุญุณูู

ุชุทุจูู ุนููู ููุชุทูุจุงุช US-01: RootDatabase with CRUD operations
"""
# pylint: disable=invalid-name,too-few-public-methods,too-many-instance-attributes,line-too-long


import_data sys
import_data time
from pathlib import_data Path

# ุฅุถุงูุฉ ุงููุณุงุฑ ุงูุฌุฐุฑ ูููุดุฑูุน ุฅูู Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from arabic_morphophon.database.enhanced_root_database import_data (
        DatabaseConfig,
        create_enhanced_database,
    )
    from arabic_morphophon.models.roots import_data RootType, create_root

    print("โ ุฌููุน ุงูุงุณุชูุฑุงุฏุงุช ูุฌุญุช")
except ImportError as e:
    print(f"โ๏ธ ุชุนุฐุฑ ุงุณุชูุฑุงุฏ ุงููุญุฏุงุช: {e}")
    import_data traceback

    traceback.print_exc()
    exit(1)

def demo_basic_operations():
    """๐ง ุนุฑุถ ุงูุนูููุงุช ุงูุฃุณุงุณูุฉ"""
    print("\n" + "=" * 60)
    print("๐ง ุนุฑุถ ุงูุนูููุงุช ุงูุฃุณุงุณูุฉ CRUD")
    print("=" * 60)

    # ุฅูุดุงุก ูุงุนุฏุฉ ุจูุงูุงุช ูู ุงูุฐุงูุฑุฉ ููุนุฑุถ
    from arabic_morphophon.database.enhanced_root_database import_data create_memory_database

    with create_memory_database() as db:
        # 1. ุฅูุดุงุก ุฌุฐูุฑ ุฌุฏูุฏุฉ
        print("\n1๏ธโฃ ุฅูุดุงุก ุฌุฐูุฑ ุฌุฏูุฏุฉ:")

        roots_to_add = [
            ("ุฏุฑุณ", "ุงูุชุนููู ูุงูุฏุฑุงุณุฉ"),
            ("ูุชุจ", "ุงููุชุงุจุฉ ูุงูุชุฃููู"),
            ("ูุฑุฃ", "ุงููุฑุงุกุฉ ูุงูุชูุงูุฉ"),
            ("ูุนุฏ", "ุงููุนุฏ ูุงูุงูุชุฒุงู"),
            ("ุณุฃู", "ุงูุณุคุงู ูุงูุงุณุชููุงู"),
        ]

        for root_str, meaning in roots_to_add:
            root = create_root(root_str, meaning)
            if db.create_root(root):
                weakness = root.get_weakness_type() or "ุณุงูู"
                print(f"  โ ุชู ุฅุถุงูุฉ: {root_str} ({weakness}) - {meaning}")
            else:
                print(f"  โ ูุดู ุฅุถุงูุฉ: {root_str}")

        # 2. ูุฑุงุกุฉ ุงูุฌุฐูุฑ
        print(f"\n2๏ธโฃ ูุฑุงุกุฉ ุงูุฌุฐูุฑ (ุงูุนุฏุฏ ุงูุฅุฌูุงูู: {len(db)}):")

        for root_str, _ in roots_to_add[:3]:  # ุนุฑุถ ุฃูู 3 ููุท
            root_result = db.read_root(root_str)
            if root_result is not None:
                print(f"  ๐ {root_result.root_string}: {root_result.semantic_field}")
                print(f"      ุงูููุน: {root_result.root_type.value}")
                print(f"      ุงูุฎุตุงุฆุต: {root_result.get_weakness_type() or 'ุณุงูู'}")
            else:
                print(f"  โ ูู ููุฌุฏ: {root_str}")

        # 3. ุชุญุฏูุซ ุฌุฐุฑ
        print(f"\n3๏ธโฃ ุชุญุฏูุซ ุฌุฐุฑ:")
        root_to_update = db.read_root("ูุชุจ")
        if root_to_update:
            root_to_update.frequency = 95
            root_to_update.semantic_field = "ุงููุชุงุจุฉ ูุงูุชุฏููู ูุงูุชุฃููู"

            if db.update_root("ูุชุจ", root_to_update):
                updated = db.read_root("ูุชุจ")
                if updated:
                    print(f"  โ ุชู ุชุญุฏูุซ 'ูุชุจ': {updated.semantic_field}")
                    print(f"      ุงูุชูุฑุงุฑ ุงูุฌุฏูุฏ: {updated.frequency}")
                else:
                    print(f"  โ๏ธ ุชู ุงูุชุญุฏูุซ ููู ูุดู ูู ุงููุฑุงุกุฉ")
            else:
                print(f"  โ ูุดู ุชุญุฏูุซ 'ูุชุจ'")

        # 4. ุญุฐู ุฌุฐุฑ
        print(f"\n4๏ธโฃ ุญุฐู ุฌุฐุฑ:")
        if db.delete_root("ูุนุฏ"):
            print(f"  โ ุชู ุญุฐู 'ูุนุฏ'")
            print(f"      ุงูุนุฏุฏ ุงูุญุงูู: {len(db)}")
        else:
            print(f"  โ ูุดู ุญุฐู 'ูุนุฏ'")

def get_search_test_data():
    """Get test data for search demonstrations"""
    return [
        ("ูุชุจ", "ุงููุชุงุจุฉ"),
        ("ูุณุจ", "ุงููุณุจ ูุงูุฑุจุญ"),
        ("ูุฐุจ", "ุงููุฐุจ ูุงูุฎุฏุงุน"),
        ("ูุฑุฃ", "ุงููุฑุงุกุฉ"),
        ("ูุงู", "ุงูููู"),
        ("ูุชู", "ุงููุชู"),
        ("ูุนุฏ", "ุงููุนุฏ"),
        ("ูุฌุฏ", "ุงููุฌูุฏ"),
        ("ููุฏ", "ุงูููุงุฏุฉ"),
        ("ุณุฃู", "ุงูุณุคุงู"),
        ("ุณุนุฏ", "ุงูุณุนุงุฏุฉ"),
        ("ุตุจุฑ", "ุงูุตุจุฑ"),
    ]

def demo_advanced_search():
    """๐ ุนุฑุถ ุงูุจุญุซ ุงููุชูุฏู"""
    print("\n" + "=" * 60)
    print("๐ ุนุฑุถ ุงูุจุญุซ ุงููุชูุฏู ูุงููููุฑุณ")
    print("=" * 60)

    from arabic_morphophon.database.enhanced_root_database import_data create_memory_database

    with create_memory_database() as db:
        # ุฅุถุงูุฉ ุจูุงูุงุช ููุจุญุซ
        search_data = get_search_test_data()

        for root_str, meaning in search_data:
            root = create_root(root_str, meaning)
            db.create_root(root)

        # 1. ุงูุจุญุซ ุจุงูููุท
        print(f"\n1๏ธโฃ ุงูุจุญุซ ุจุงูููุท:")

        patterns = ["ู*", "*ุนุฏ", "ู??", "ุณ*"]
        for pattern in patterns:
            results = db.search_by_pattern(pattern)
            print(f"  ๐ ุงูููุท '{pattern}': {len(results)} ูุชูุฌุฉ")
            for root in results[:3]:  # ุฃูู 3 ูุชุงุฆุฌ
                print(f"      - {root.root_string}: {root.semantic_field}")

        # 2. ุงูุจุญุซ ุจุงูุฎุตุงุฆุต
        print(f"\n2๏ธโฃ ุงูุจุญุซ ุจุงูุฎุตุงุฆุต:")

        # ุงูุจุญุซ ุจููุน ุงูุฌุฐุฑ
        trilateral = db.search_by_properties(root_type=RootType.TRILATERAL)
        print(f"  ๐ ุงูุฌุฐูุฑ ุงูุซูุงุซูุฉ: {len(trilateral)}")

        # ุงูุจุญุซ ุจููุน ุงูุฅุนูุงู
        weak_roots = db.search_by_properties(weakness_type="ูุซุงู")
        print(f"  ๐ ุงูุฌุฐูุฑ ุงููุซุงู: {len(weak_roots)}")
        for root in weak_roots:
            print(f"      - {root.root_string} ({root.get_weakness_type()})")

        # 3. ุงูุจุญุซ ุจุงููุฌุงู ุงูุฏูุงูู
        print(f"\n3๏ธโฃ ุงูุจุญุซ ุจุงููุฌุงู ุงูุฏูุงูู:")

        # ุงูุจุญุซ ุงูุฏููู
        reading_roots = db.search_by_semantic_field("ุงููุฑุงุกุฉ")
        print(f"  ๐ ุฌุฐูุฑ ุงููุฑุงุกุฉ: {len(reading_roots)}")

        # ุงูุจุญุซ ุงูุถุจุงุจู
        general_roots = db.search_by_semantic_field("ู", fuzzy=True)
        print(f"  ๐ ุงููุฌุงูุงุช ุงููุญุชููุฉ ุนูู 'ู': {len(general_roots)}")

        # 4. ุงูุจุญุซ ุงููุตู ุงููุงูู
        print(f"\n4๏ธโฃ ุงูุจุญุซ ุงููุตู ุงููุงูู:")

        fts_results = db.fulltext_search("ูุชุงุจ")
        print(f"  ๐ ุงูุจุญุซ ุนู 'ูุชุงุจ': {len(fts_results)} ูุชูุฌุฉ")
        for root in fts_results:
            print(f"      - {root.root_string}: {root.semantic_field}")

def demo_bulk_operations():
    """๐ฆ ุนุฑุถ ุงูุนูููุงุช ุงููุฌูุนุฉ"""
    print("\n" + "=" * 60)
    print("๐ฆ ุนุฑุถ ุงูุนูููุงุช ุงููุฌูุนุฉ ูุงูุชุตุฏูุฑ")
    print("=" * 60)

    import_data json
    import_data tempfile

    from arabic_morphophon.database.enhanced_root_database import_data create_memory_database

    with create_memory_database() as db:
        # 1. ุฅูุดุงุก ููู JSON ููุงุณุชูุฑุงุฏ
        print("\n1๏ธโฃ ุฅูุดุงุก ุจูุงูุงุช ููุงุณุชูุฑุงุฏ ุงููุฌูุน:")

        bulk_data = {
            "roots": [
                {"root": "ุญูุฏ", "semantic_field": "ุงูุญูุฏ ูุงูุซูุงุก"},
                {"root": "ุดูุฑ", "semantic_field": "ุงูุดูุฑ ูุงูุงูุชูุงู"},
                {"root": "ูุฑุญ", "semantic_field": "ุงููุฑุญ ูุงูุณุฑูุฑ"},
                {"root": "ุญุฒู", "semantic_field": "ุงูุญุฒู ูุงูุฃุณู"},
                {"root": "ุฎูู", "semantic_field": "ุงูุฎูู ูุงููุฒุน"},
                {"root": "ุฃูู", "semantic_field": "ุงูุฃูู ูุงูุทูุฃูููุฉ"},
                {"root": "ุญุจุจ", "semantic_field": "ุงูุญุจ ูุงูููุฏุฉ"},
                {"root": "ุจุบุถ", "semantic_field": "ุงูุจุบุถ ูุงููุฑุงููุฉ"},
            ]
        }

        # ุญูุธ ูู ููู ูุคูุช
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", delete=False, encoding="utf-8"
        ) as f:
            json.dump(bulk_data, f, ensure_ascii=False, indent=2)
            temp_file = f.name

        print(f"      ๐ ุชู ุฅูุดุงุก ููู: {Path(temp_file).name}")
        print(f"      ๐ ุนุฏุฏ ุงูุฌุฐูุฑ: {len(bulk_data['roots'])}")

        # 2. ุงูุงุณุชูุฑุงุฏ ุงููุฌูุน
        print(f"\n2๏ธโฃ ุงูุงุณุชูุฑุงุฏ ุงููุฌูุน:")

        begin_time = time.time()
        import_data_stats = db.bulk_import_data_json(temp_file)
        import_data_time = time.time() - begin_time

        print(f"      โ ุชู ุงูุงุณุชูุฑุงุฏ: {import_data_stats['import_dataed']}")
        print(f"      โญ๏ธ ุชู ุงูุชุฎุทู: {import_data_stats['skipped']}")
        print(f"      โ ุฃุฎุทุงุก: {import_data_stats['errors']}")
        print(f"      โฑ๏ธ ููุช ุงูุงุณุชูุฑุงุฏ: {import_data_time:.3f} ุซุงููุฉ")
        print(f"      ๐ ุฅุฌูุงูู ุงูุฌุฐูุฑ ุงูุขู: {len(db)}")

        # 3. ุงูุชุตุฏูุฑ
        print(f"\n3๏ธโฃ ุงูุชุตุฏูุฑ:")

        with tempfile.NamedTemporaryFile(
            mode="w", suffix="_store_data.json", delete=False, encoding="utf-8"
        ) as f:
            store_data_file = f.name

        begin_time = time.time()
        store_data_success = db.store_data_to_json(store_data_file, include_metadata=True)
        store_data_time = time.time() - begin_time

        if store_data_success:
            store_data_size = Path(store_data_file).stat().st_size
            print(f"      โ ุชู ุงูุชุตุฏูุฑ ุฅูู: {Path(store_data_file).name}")
            print(f"      ๐ฆ ุญุฌู ุงูููู: {store_data_size:,} ุจุงูุช")
            print(f"      โฑ๏ธ ููุช ุงูุชุตุฏูุฑ: {store_data_time:.3f} ุซุงููุฉ")

            # ุนุฑุถ ุนููุฉ ูู ุงูููู ุงููุตุฏุฑ
            with open(store_data_file, "r", encoding="utf-8") as f:
                store_dataed_data = json.import_data(f)

            print(f"      ๐ ูุญุชูู ุงูุชุตุฏูุฑ:")
            print(f"        - ุฌุฐูุฑ: {len(store_dataed_data.get('roots', []))}")
            if "metadata" in store_dataed_data:
                metadata = store_dataed_data["metadata"]
                print(
                    f"        - ุชุงุฑูุฎ ุงูุชุตุฏูุฑ: {metadata.get('store_dataed_at', 'ุบูุฑ ูุญุฏุฏ')}"
                )
                print(
                    f"        - ุฅุตุฏุงุฑ ูุงุนุฏุฉ ุงูุจูุงูุงุช: {metadata.get('database_version', 'ุบูุฑ ูุญุฏุฏ')}"
                )
        else:
            print("      โ ูุดู ุงูุชุตุฏูุฑ")

        # ุชูุธูู ุงููููุงุช ุงููุคูุชุฉ
        try:
            Path(temp_file).unlink()
            Path(store_data_file).unlink()
        except:
            pass

def demo_statistics_and_analytics():
    """๐ ุนุฑุถ ุงูุฅุญุตุงุฆูุงุช ูุงูุชุญูููุงุช"""
    print("\n" + "=" * 60)
    print("๐ ุนุฑุถ ุงูุฅุญุตุงุฆูุงุช ูุงูุชุญูููุงุช ุงููุชูุฏูุฉ")
    print("=" * 60)

    from arabic_morphophon.database.enhanced_root_database import_data create_memory_database

    with create_memory_database() as db:
        # ุฅุถุงูุฉ ุจูุงูุงุช ูุชููุนุฉ ููุชุญููู
        diverse_data = [
            # ุฌุฐูุฑ ุณุงููุฉ
            ("ูุชุจ", "ุงููุชุงุจุฉ", 150),
            ("ุฏุฑุณ", "ุงูุฏุฑุงุณุฉ", 120),
            ("ููู", "ุงูููู", 100),
            # ุฌุฐูุฑ ูุนุชูุฉ
            ("ูุนุฏ", "ุงููุนุฏ", 80),  # ูุซุงู
            ("ูุงู", "ุงูููู", 200),  # ุฃุฌูู
            ("ุฏุนุง", "ุงูุฏุนุงุก", 90),  # ูุงูุต
            # ุฌุฐูุฑ ููููุฒุฉ
            ("ุฃูู", "ุงูุฃูู", 110),  # ููููุฒ ุงููุงุก
            ("ุณุฃู", "ุงูุณุคุงู", 85),  # ููููุฒ ุงูุนูู
            ("ูุฑุฃ", "ุงููุฑุงุกุฉ", 130),  # ููููุฒ ุงููุงู
            # ุฌุฐูุฑ ุฑุจุงุนูุฉ
            ("ุฏุญุฑุฌ", "ุงูุฏุญุฑุฌุฉ", 30),
            ("ุฒูุฒู", "ุงูุฒูุฒูุฉ", 25),
            ("ูุณูุณ", "ุงููุณูุณุฉ", 20),
        ]

        print(f"\n๐ฅ ุฅุถุงูุฉ {len(diverse_data)} ุฌุฐุฑ ููุชุญููู...")

        for root_str, meaning, freq in diverse_data:
            root = create_root(root_str, meaning)
            root.frequency = freq
            db.create_root(root)

        # ุฌูุจ ุงูุฅุญุตุงุฆูุงุช ุงูุดุงููุฉ
        print(f"\n๐ ุงูุฅุญุตุงุฆูุงุช ุงูุดุงููุฉ:")

        stats = db.get_comprehensive_statistics()

        # ุฅุญุตุงุฆูุงุช ุฃุณุงุณูุฉ
        if "basic_statistics" in stats:
            basic = stats["basic_statistics"]
            print(f"\n  ๐ข ุงูุฅุญุตุงุฆูุงุช ุงูุฃุณุงุณูุฉ:")
            print(f"    โข ุฅุฌูุงูู ุงูุฌุฐูุฑ: {basic.get('total_roots', 0):,}")
            print(f"    โข ุงูุฌุฐูุฑ ุงูุณุงููุฉ: {basic.get('sound_roots', 0):,}")
            print(f"    โข ุงูุฌุฐูุฑ ุงููุนุชูุฉ: {basic.get('weak_roots', 0):,}")
            print(f"    โข ุงูุฌุฐูุฑ ุงูููููุฒุฉ: {basic.get('hamzated_roots', 0):,}")
            print(f"    โข ูุชูุณุท ุงูุชูุฑุงุฑ: {basic.get('avg_frequency', 0):.1f}")
            print(f"    โข ูุชูุณุท ุงูุซูุฉ: {basic.get('avg_confidence', 0):.2f}")

        # ุชูุฒูุน ุงูุฃููุงุน
        if "type_distribution" in stats:
            type_dist = stats["type_distribution"]
            print(f"\n  ๐ ุชูุฒูุน ุฃููุงุน ุงูุฌุฐูุฑ:")
            for root_type, count in type_dist.items():
                percentage = (count / len(db) * 100) if len(db) > 0 else 0
                print(f"    โข {root_type}: {count} ({percentage:.1f}%)")

        # ุชูุฒูุน ุงููุฌุงูุงุช ุงูุฏูุงููุฉ
        if "semantic_distribution" in stats:
            semantic_dist = stats["semantic_distribution"]
            print(f"\n  ๐ท๏ธ ุฃูู ุงููุฌุงูุงุช ุงูุฏูุงููุฉ:")
            for field, count in list(semantic_dist.items())[:5]:
                print(f"    โข {field}: {count} ุฌุฐุฑ")

        # ุฅุญุตุงุฆูุงุช ุงูุฃุฏุงุก
        if "performance" in stats:
            perf = stats["performance"]
            print(f"\n  โก ุฅุญุตุงุฆูุงุช ุงูุฃุฏุงุก:")
            print(f"    โข ูุณุจุฉ ุฅุตุงุจุฉ ุงููุงุด: {perf.get('cache_hit_ratio', 0):.1%}")
            print(f"    โข ุญุฌู ุงููุงุด: {perf.get('cache_size', 0):,} ุนูุตุฑ")
            print(
                f"    โข ูุชูุณุท ููุช ุงูุงุณุชุนูุงู: {perf.get('avg_query_time', 0):.3f} ุซุงููุฉ"
            )
            print(f"    โข ุฅุฌูุงูู ุงูุงุณุชุนูุงูุงุช: {perf.get('total_queries', 0):,}")

        # ุฅุญุตุงุฆูุงุช ุงูุชุฎุฒูู
        if "storage" in stats:
            storage = stats["storage"]
            print(f"\n  ๐พ ุฅุญุตุงุฆูุงุช ุงูุชุฎุฒูู:")
            print(
                f"    โข ุญุฌู ูุงุนุฏุฉ ุงูุจูุงูุงุช: {storage.get('database_size_mb', 0):.2f} ููุฌุงุจุงูุช"
            )
            print(
                f"    โข ุงุณุชุฎุฏุงู ุฐุงูุฑุฉ ุงููุงุด: {storage.get('cache_memory_usage', 0):,} ุจุงูุช"
            )

def demo_performance_benchmark():
    """โก ุนุฑุถ ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก"""
    print("\n" + "=" * 60)
    print("โก ุงุฎุชุจุงุฑ ุงูุฃุฏุงุก ูุงูุชุญุณูู")
    print("=" * 60)

    import_data random
    import_data string

    from arabic_morphophon.database.enhanced_root_database import_data create_memory_database

    with create_memory_database() as db:
        # 1. ุงุฎุชุจุงุฑ ุณุฑุนุฉ ุงูุฅุฏุฑุงุฌ
        print(f"\n1๏ธโฃ ุงุฎุชุจุงุฑ ุณุฑุนุฉ ุงูุฅุฏุฑุงุฌ:")

        num_inserts = 100
        begin_time = time.time()

        for i in range(num_inserts):
            # ุฅูุดุงุก ุฌุฐุฑ ุนุดูุงุฆู
            letters = [
                "ุจ",
                "ุช",
                "ุซ",
                "ุฌ",
                "ุญ",
                "ุฎ",
                "ุฏ",
                "ุฐ",
                "ุฑ",
                "ุฒ",
                "ุณ",
                "ุด",
                "ุต",
                "ุถ",
                "ุท",
                "ุธ",
                "ุน",
                "ุบ",
                "ู",
                "ู",
                "ู",
                "ู",
                "ู",
                "ู",
                "ู",
                "ู",
                "ู",
            ]

            root_str = "".join(random.choices(letters, k=3))
            meaning = f"ุงุฎุชุจุงุฑ {i+1}"

            try:
                root = create_root(root_str, meaning)
                root.frequency = random.randint(1, 100)
                db.create_root(root)
            except:
                pass  # ุชุฌุงูู ุงูุฃุฎุทุงุก ูู ุงูุจูุงูุงุช ุงูุนุดูุงุฆูุฉ

        insert_time = time.time() - begin_time
        actual_inserts = len(db)

        print(f"    โฑ๏ธ ููุช ุงูุฅุฏุฑุงุฌ: {insert_time:.3f} ุซุงููุฉ")
        print(f"    ๐ ุนุฏุฏ ุงูุฅุฏุฑุงุฌุงุช: {actual_inserts:,}")
        print(f"    ๐ ูุนุฏู ุงูุฅุฏุฑุงุฌ: {actual_inserts/insert_time:.1f} ุฌุฐุฑ/ุซุงููุฉ")

        # 2. ุงุฎุชุจุงุฑ ุณุฑุนุฉ ุงูุจุญุซ
        print(f"\n2๏ธโฃ ุงุฎุชุจุงุฑ ุณุฑุนุฉ ุงูุจุญุซ:")

        search_tests = [
            ("pattern", lambda: db.search_by_pattern("*ุช*")),
            ("semantic", lambda: db.search_by_semantic_field("ุงุฎุชุจุงุฑ", fuzzy=True)),
            (
                "properties",
                lambda: db.search_by_properties(root_type=RootType.TRILATERAL),
            ),
            ("fulltext", lambda: db.fulltext_search("ุฑ")),
        ]

        for test_name, search_func in search_tests:
            # ุชุดุบูู ุงูุจุญุซ ุนุฏุฉ ูุฑุงุช ูููุงุณ ูุชูุณุท ุงูุฃุฏุงุก
            times = []
            results_count = 0

            for _ in range(10):
                begin_time = time.time()
                results = search_func()
                search_time = time.time() - begin_time
                times.append(search_time)
                results_count = len(results)

            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)

            print(f"    ๐ {test_name}:")
            print(f"        ูุชูุณุท ุงูููุช: {avg_time:.4f}s")
            print(f"        ุฃุณุฑุน ููุช: {min_time:.4f}s")
            print(f"        ุฃุจุทุฃ ููุช: {max_time:.4f}s")
            print(f"        ุนุฏุฏ ุงููุชุงุฆุฌ: {results_count}")

        # 3. ุงุฎุชุจุงุฑ ุงููุงุด
        print(f"\n3๏ธโฃ ุงุฎุชุจุงุฑ ุฃุฏุงุก ุงููุงุด:")

        # ูุฑุงุกุฉ ููุณ ุงูุฌุฐูุฑ ุนุฏุฉ ูุฑุงุช
        if test_roots := list(db.list_all_roots()[:10]):
            # ุงููุฑุงุกุฉ ุงูุฃููู (cold cache)
            begin_time = time.time()
            for root in test_roots:
                db.read_root(root.root_string)
            cold_time = time.time() - begin_time

            # ุงููุฑุงุกุฉ ุงูุซุงููุฉ (warm cache)
            begin_time = time.time()
            for root in test_roots:
                db.read_root(root.root_string)
            warm_time = time.time() - begin_time

            speedup = cold_time / warm_time if warm_time > 0 else 0

            print(f"    โ๏ธ ูุฑุงุกุฉ ุจุงุฑุฏุฉ (cold): {cold_time:.4f}s")
            print(f"    ๐ฅ ูุฑุงุกุฉ ุฏุงูุฆุฉ (warm): {warm_time:.4f}s")
            print(f"    ๐ ุชุญุณู ุงูุณุฑุนุฉ: {speedup:.1f}x")

def print_features_list():
    """Print the enhanced features list"""
    print("  โข ุนูููุงุช CRUD ูุชูุฏูุฉ ูุน SQLite")
    print("  โข ุจุญุซ ูุชุทูุฑ ููููุฑุณ")
    print("  โข ุนูููุงุช ูุฌูุนุฉ ููุงุณุชูุฑุงุฏ ูุงูุชุตุฏูุฑ")
    print("  โข ุฅุญุตุงุฆูุงุช ูุชุญูููุงุช ุดุงููุฉ")
    print("  โข ุชุญุณููุงุช ุงูุฃุฏุงุก ูุงููุงุด")
    print("  โข ุฏุนู ุงูุจุญุซ ุงููุตู ุงููุงูู")

def main():
    """๐ ุงูุนุฑุถ ุงูุชูุถูุญู ุงูุฑุฆูุณู"""
    print("๐ ุงูุนุฑุถ ุงูุชูุถูุญู ููุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุทูุฑุฉ ููุฌุฐูุฑ ุงูุนุฑุจูุฉ")
    print("=" * 80)
    print("๐ ุงูููุฒุงุช ุงููุทูุฑุฉ:")
    print_features_list()
    print("=" * 80)

    try:
        # ุชุดุบูู ุฌููุน ุงูุนุฑูุถ ุงูุชูุถูุญูุฉ
        demo_basic_operations()
        demo_advanced_search()
        demo_bulk_operations()
        demo_statistics_and_analytics()
        demo_performance_benchmark()

        print("\n" + "=" * 80)
        print("๐ ุงูุชูู ุงูุนุฑุถ ุงูุชูุถูุญู ุจูุฌุงุญ!")
        print("โ ุฌููุน ููุฒุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช ุชุนูู ุจุดูู ุตุญูุญ")
        print("๐ ุงููุธุงู ุฌุงูุฒ ููุงุณุชุฎุฏุงู ูู ุงูุฅูุชุงุฌ")
        print("=" * 80)

    except Exception as e:
        print(f"\nโ ุฎุทุฃ ูู ุงูุนุฑุถ ุงูุชูุถูุญู: {e}")
        print("๐ ุชุฃูุฏ ูู ุชุซุจูุช ุฌููุน ุงููุชุทูุจุงุช ุจุดูู ุตุญูุญ")

if __name__ == "__main__":
    main()
